Abstract,True Title,Predicted Title,ROUGE Score,BLEU Score,Accuracy
"  Recent studies of pseudo-plane ideal flow (PIF) reveal a ubiquitous presenceof vortex alignment in both homogeneous and stratified fluids, and in bothinertial and rotating reference frames as well. The exact solutions of asteady-state PIF model suggest that stagnation points tend to be verticallyaligned and the concentric structure represents a fixed-point phenomenon of theEuler equations. Exception occurs in the rotating frame when a flow holdsinertial period and skew center becomes possible. Properties of stagnationpoints based on Morse theory are obtained, leading to a topological explanationof vertical alignment via pressure Hessian. The study thus uncovers a newaspect of vortex behavior in ideal fluid that requires vortex center to alignwith the direction of gravity when vortex evolution reaches a laminar end statecharacterized by steady pseudo-plane velocities. Though the phenomenon arisesfrom the constraint of the Euler equations, under specific conditions thetopological theory is applicable to viscous fluid and explains the curvilineartilting of von K\'arm\'an swirling vortex.",Vertical alignment of stagnation points in pseudo-plane ideal flows,Vortex alignment in pseudo-plane ideal flow,0.7058823529411764,0.3081980909598119,0
"  Results of photometric observations of a small sample of selected Main Beltasteroids are presented. The obtained measurements can be used to achieve abetter calibration of the asteroid photometric system $(H, G_1, G_2)$ adoptedby the IAU, and to make comparisons with best-fit curves that can be obtainedusing different photometric systems. The new data have been obtained as a firstfeasibility study of a more extensive project planned for the future, aimed atobtaining a reliable calibration of possible relations between some parameterscharacterizing the phase-magnitude curves and the geometric albedo ofasteroids. This has important potential applications to the analysis ofasteroid photometric data obtained by the Gaia space mission.","New phase-magnitude curves for some Main Belt asteroids, fit of
  different photometric systems and calibration of the albedo - photometry
  relation","The calibration of the asteroid photometric system $(H, G_1, G_{2)",0.18181818181818182,0.10807256086619267,0
"  We investigate the QCD next-to-leading order (NLO) corrections to theproduction of a pair of fermionic dark matter particles associated with a Wboson production through a mediator which couples to standard model particlesvia either a vector or axial-vector coupling at the LHC. We find that the QCDNLO corrections reduce the dependence of the total cross sections on thefactorization and renormalization scales, and the $K$-factors increase with theincrement of the dark matter mass. We also provide the LO and QCD NLO correcteddistributions of the transverse momenta $p_T^\mu$ of final muon and transversemass $M_T$. We find that the LO cross section is significantly changed by theQCD NLO corrections.","Dark matter pair associated with a $W$ boson production at the LHC in
  next-to-leading order QCD","QCD next-to-leading order corrections to the production of fermionic dark matter
",0.2580645161290323,0.30674893150098825,0
"  This paper re-evaluates the security of a chaotic image encryption algorithmcalled MCKBA/HCKBA and finds that it can be broken efficiently with two knownplain-images and the corresponding cipher-images. In addition, it is reportedthat a previously proposed breaking on MCKBA/HCKBA can be further improved byreducing the number of chosen plain-images from four to two. The two attacksare both based on the properties of solving a composite function involving thecarry bit, which is composed of the modulo addition and the bitwise ORoperations. Both rigorous theoretical analysis and detailed experimentalresults are provided.","Breaking a chaotic image encryption algorithm based on modulo addition
  and XOR operation",A Review of a Chaotic Image Encryption Algorithm,0.4761904761904762,0.3182683495906518,0
"  We construct a relativistic potential quark model of $D$, $D_s$, $B$, and$B_s$ mesons in which the light quark motion is described by the Dirac equationwith a scalar-vector interaction and the heavy quark is considered a localsource of the gluon field. The effective interquark interaction is described bya combination of the perturbative one-gluon exchange potential$V_{\mathrm{Coul}}(r)=-\xi/r$ and the long-range Lorentz-scalar andLorentz-vector linear potentials $S_{\mathrm{l.r.}}(r)=(1-\lambda)(\sigmar+V_0)$ and $V_{\mathrm{l.r.}}(r)=\lambda(\sigma r+V_0)$, where$0\leqslant\lambda<1/2$. Within the quasiclassical approximation, we obtainsimple asymptotic formulas for the energy and mass spectra and for the meanradii of $D$, $D_s$, $B$, and $B_s$ mesons, which ensure a high accuracy ofcalculations even for states with the radial quantum number $n_r\sim 1$. Weshow that the fine structure of P-wave states in heavy-light mesons isprimarily sensitive to the choice of two parameters: the strong-couplingconstant $\alpha_s$ and the coefficient $\lambda$ of mixing of the long-rangescalar and vector potentials $S_{\mathrm{l.r.}}(r)$ and $V_{\mathrm{l.r.}}(r)$.The quasiclassical formulas for asymptotic coefficients of wave function atzero and infinity are obtained.","The quasiclassical theory of the Dirac equation with a scalar-vector
  interaction and its applications in the theory of heavy-light mesons",Quark model of heavy-light mesons,0.28571428571428575,0.02799732600332712,0
"  Criteria of measure quantifying quantum coherence, a unique property ofquantum system, are proposed recently. In this paper, we first give anuncertainty-like expression relating the coherence and the entropy of quantumsystem. This finding allows us to discuss the relations between theentanglement and the coherence. Further, we discuss in detail the relationsamong the coherence, the discord and the deficit in the bipartite quantumsystem. We show that, the one-way quantum deficit is equal to the sum betweenquantum discord and the relative entropy of coherence of measured subsystem.",Quantum coherence and correlations in quantum system,Quantum discord and entropy of quantum system,0.5714285714285714,0.5555238068023582,0
"  The decay width and mass of the Ds1(2536)+ meson are measured via the decaychannel Ds1+ -> D*+KS0 using 385 fb^-1 of data recorded with the BABAR detectorin the vicinity of the Y(4S) resonance at the PEP-II asymmetric-energyelectron-positron collider. The result for the decay width is 0.92 +- 0.03(stat) +- 0.04 (syst) MeV. For the mass, a value of 2535.08 +- 0.01 +- 0.15MeV/c^2 is obtained. The mass difference between the Ds1+ and the D*+ ismeasured to be 524.83 +- 0.01 +- 0.04 MeV/c^2, representing a significantimprovement compared to the current world average. The unnatural spin-parityassignment for the Ds1+ meson is confirmed.",Measurement of the mass and width of the Ds1(2536)+ meson,Measurement of the decay width and mass of the Ds1(2536)+ meson,0.7826086956521738,0.37097233136825053,0
"  The updated CDF measurement of the forward-backward asymmetry (FBA) in thetop quark production p{bar p} -> t{bar t} at Tevatron (with the CMS energy 1.96TeV) shows a deviation of 2*sigma from the value predicted by the Standard QCDModel. We present calculation of this quantity in the scenario where coloredunparticle physics contributes to the s-channel of the process, and obtain theregions in the plane of the unparticle parameters lambda and dU which give thevalues of the FBA and of the total t{bar t} production cross section compatiblewith the present measurements.",Forward-backward asymmetry of top quark in unparticle physics,"Measurement of forward-backward asymmetry in the top quark production
  p{",0.5,0.4854917717073234,0
"  Observations of star-forming regions by the current and upcoming generationof submillimeter polarimeters will shed new light on the evolution of magneticfields over the cloud-to-core size scales involved in the early stages of thestar formation process. Recent wide-area and high-sensitivity polarizationobservations have drawn attention to the challenges of modeling magnetic fieldstructure of star forming regions, due to variations in dust polarizationproperties in the interstellar medium. However, these observations also for thefirst time provide sufficient information to begin to break the degeneracybetween polarization efficiency variations and depolarization due to magneticfield sub-beam structure, and thus to accurately infer magnetic fieldproperties in the star-forming interstellar medium. In this article we discusssubmillimeter and far-infrared polarization observations of star-formingregions made with single-dish instruments. We summarize past, present andforthcoming single-dish instrumentation, and discuss techniques which have beendeveloped or proposed to interpret polarization observations, both in order toinfer the morphology and strength of the magnetic field, and in order todetermine the environments in which dust polarization observations reliablytrace the magnetic field. We review recent polarimetric observations ofmolecular clouds, filaments, and starless and protostellar cores, and discusshow the application of the full range of modern analysis techniques to recentobservations will advance our understanding of the role played by the magneticfield in the early stages of star formation.","Submillimeter and Far-Infrared Polarimetric Observations of Magnetic
  Fields in Star-Forming Regions",Polarimetric and Far-Infrared Polarimetric Observations of Star-Forming,0.7272727272727274,0.3633728926524737,0
  Mind uploading speculation and debate often concludes that a proceduredescribed as gradual in-place replacement preserves personal identity while aprocedure described as destructive scan-and-copy produces some other identityin the target substrate such that personal identity is lost along with thebiological brain. This paper demonstrates a chain of reasoning that establishesmetaphysical equivalence between these two methods in terms of preservingpersonal identity.,"The Fallacy of Favoring Gradual Replacement Mind Uploading Over
  Scan-and-Copy",A chain of reasoning for preserving personal identity,0.1,0.4630777161991027,0
"  Quantum computers promise significant speedups in solving problemsintractable for conventional computers but, despite recent progress, remainlimited in scaling and availability. Therefore, quantum software and hardwaredevelopment heavily rely on simulation that runs on conventional computers.Most such approaches perform strong simulation in that they explicitly computeamplitudes of quantum states. However, such information is not directlyobservable from a physical quantum computer because quantum measurementsproduce random samples from probability distributions defined by thoseamplitudes. In this work, we focus on weak simulation that aims to produceoutputs which are statistically indistinguishable from those of error-freequantum computers. We develop algorithms for weak simulation based on quantumstate representation in terms of decision diagrams. We compare them to usingstate-vector arrays and binary search on prefix sums to perform sampling.Empirical validation shows, for the first time, that this enables mimicking ofphysical quantum computers of significant scale.",Just Like the Real Thing: Fast Weak Simulation of Quantum Computation,Weak simulation for error-free quantum computers,0.4444444444444444,0.27768352844338134,0
"  We construct an SU(4) spectral divisor and its factorization of types (3,1)and (2,2) based on the construction proposed in [1]. We calculate the chiralspectra of flipped SU(5) GUTs by using the spectral divisor construction. Theresults agree with those from the analysis of semi-local spectral covers. Ourcomputations provide an example for the validity of the spectral divisorconstruction and suggest that the standard heterotic formulae are applicable tothe case of F-theory on an elliptically fibered Calabi-Yau fourfold with noheterotic dual.",On Global Flipped SU(5) GUTs in F-theory,Spectral divisor construction and the heterotic formulae of F-theory,0.2105263157894737,0.5773502691896257,0
"  We ask what new states may lie at or below the TeV scale, with sizableflavour-dependent couplings to light quarks, putting them within reach ofhadron colliders via resonant production, or in association with Standard Modelstates. In particular, we focus on the compatibility of such states withstringent flavour-changing neutral current and electric-dipole momentconstraints. We argue that the broadest and most theoretically plausibleflavour structure of the new couplings is that they are hierarchical, as areStandard Model Yukawa couplings, although the hierarchical pattern may well bedifferent. We point out that, without the need for any more elaborate orrestrictive structure, new scalars with ""diquark"" couplings to standard quarksare particularly immune to existing constraints, and that such scalars mayarise within a variety of theoretical paradigms. In particular, there can besubstantial couplings to a pair of light quarks or to one light and one heavyquark. For example, the latter possibility may provide a flavour-safeinterpretation of the asymmetry in top quark production observed at theTevatron. We thereby motivate searches for diquark scalars at the Tevatron andLHC, and argue that their discovery represents one of our best chances for newinsight into the Flavour Puzzle of the Standard Model.",Flavourful Production at Hadron Colliders,Flavour-dependent couplings to light quarks,0.1818181818181818,0.0,0
"  This paper investigates some indicators of financial development in selectcountries with currency board systems and raises some questions about theconnection between financial development and growth in currency board systems.Most of those cases are long past episodes of what we would now call emergingmarkets. However, the paper also looks at Hong Kong, the currency board systemthat is one of the world's largest and most advanced financial markets. Theglobal financial crisis of 2008 09 created doubts about the efficiency offinancial markets in advanced economies, including in Hong Kong, and unsettledthe previous consensus that a large financial sector would be more stable thana smaller one.","Financial Deepening and Economic Growth in Select Emerging Markets with
  Currency Board Systems: Theory and Evidence",Financial Development in Central and Eastern Countries,0.26086956521739124,0.2236800154620159,0
"  We report a detailed analysis of the optical realization [1, 3, 2, 4] of theanalogue algorithm described in the first paper of this series [5] for thesimultaneous factorization of an exponential number of integers. Such ananalogue procedure, which scales exponentially in the context of first orderinterference, opens up the horizon to polynomial scaling by exploitingmulti-particle quantum interference.","Analogue algorithm for parallel factorization of an exponential number
  of large integers II. Optical implementation","Optical realization of the simultaneous factorization algorithm for the
  time-dependent factorization of",0.28571428571428575,0.427639889086126,0
"  The microscopic approach was developed for obtaining of the free energy of asuperconductor with help direct calculation of the vacuum amplitude. Thefunctional of free energy of the spatially inhomogeneous superconductor in amagnetic field was obtained with help the developed approach. The obtainedfunctional is generalization of Ginzburg-Landau functionals for anytemperature, for arbitrary spatial variations of the order parameter and forthe nonlocality of the order parameter and the magnetic response. Moreover thenonlocality of the magnetic response is the consequence of the orderparameter's nonlocality. The extremals of this functional are considered in theexplicit form in the low-temperature limit and in the high-temperature limit atthe condition of slowness of spatial variations of the order parameter.",Nonlocal free energy of a spatially inhomogeneous superconductor,"Microscopic approach for the free energy of superconductor in amagnetic
  field",0.4210526315789474,0.2998221389342337,0
"  We study the reflection of magnons from a D5-brane in the framework of theAdS/CFT correspondence. We consider two possible orientations of the D5-branewith respect to the reference vacuum state, namely vacuum states aligned along""vertical"" and ""horizontal"" directions. We show that the reflections are of theachiral type. We also show that the reflection matrices satisfy the boundaryYang-Baxter equations for both orientations. In the horizontal case thereflection matrix can be interpreted in terms of a bulk S-matrix, S(p, -p), andfactorizability of boundary scattering therefore follows from that of bulkscattering. Finally, we solve the nested coordinate Bethe ansatz for the systemin the vertical case to find the Bethe equations. In the horizontal case, theBethe equations are of the same form as those for the closed string.",Integrable achiral D5-brane reflections and asymptotic Bethe equations,Reflection of magnons from a D5-brane,0.25,0.45782273986766686,0
"  A general calculational method is applied to investigate symmetry relationsamong divergent amplitudes in a free fermion model. A very traditional work onthis subject is revisited. A systematic study of one, two and three pointfunctions associated to scalar, pseudoscalar, vector and axial-vector densitiesis performed. The divergent content of the amplitudes are left in terms of fivebasic objects (external momentum independent). No specific assumptions about aregulator is adopted in the calculations. All ambiguities and symmetryviolating terms are shown to be associated with only three combinations of thebasic divergent objects. Our final results can be mapped in the correspondingDimensional Regularization calculations (in cases where this technique could beapplied) or in those of Gertsein and Jackiw which we will show in detail. Theresults emerging from our general approach allow us to extract, in a naturalway, a set of reasonable conditions (e.g. crucial for QED consistency) thatcould lead us to obtain all Ward Identities satisfied. Consequently, weconclude that the traditional approach used to justify the famous triangularanomalies in perturbative calculations could be questionable. An alternativepoint of view, dismissed of ambiguities, which lead to a correct description ofthe associated phenomenology, is pointed out.",Anomalies in Ward Identities for Three-Point Functions Revisited,"Symmetry relations among divergent amplitudes in free fermion
  models",0.1111111111111111,0.5773502691896257,0
"  Saliency computation has become a popular research field for manyapplications due to the useful information provided by saliency maps. For asaliency map, local relations around the salient regions in multi-channelperspective should be taken into consideration by aiming uniformity on theregion of interest as an internal approach. And, irrelevant salient regionshave to be avoided as much as possible. Most of the works achieve thesecriteria with external processing modules; however, these can be accomplishedduring the conspicuity map fusion process. Therefore, in this paper, a newmodel is proposed for saliency/conspicuity map fusion with two concepts: a)input image transformation relying on the principal component analysis (PCA),and b) saliency conspicuity map fusion with multi-channel pulsed coupled neuralnetwork (m-PCNN). Experimental results, which are evaluated by precision,recall, F-measure, and area under curve (AUC), support the reliability of theproposed method by enhancing the saliency computation.","Saliency Fusion in Eigenvector Space with Multi-Channel Pulse Coupled
  Neural Network","Saliency/Conspicuity Map Fusion with Multi-Channel Pulsed Coupled Neural
",0.7272727272727272,0.44677880536150705,0
"  This paper proposes a technique for automatic face recognition usingintegrated multiple feature sets extracted from the significant blocks of agradient image. We discuss about the use of novel morphological, localdirectional pattern (LDP) and gray-level co-occurrence matrix GLCM basedfeature extraction technique to recognize human faces. Firstly, the newmorphological features i.e., features based on number of runs of pixels in fourdirections (N,NE,E,NW) are extracted, together with the GLCM based statisticalfeatures and LDP features that are less sensitive to the noise andnon-monotonic illumination changes, are extracted from the significant blocksof the gradient image. Then these features are concatenated together. Weintegrate the above mentioned methods to take full advantage of the threeapproaches. Extraction of the significant blocks from the absolute gradientimage and hence from the original image to extract pertinent information withthe idea of dimension reduction forms the basis of the work. The efficiency ofour method is demonstrated by the experiment on 1100 images from the FRAV2Dface database, 2200 images from the FERET database, where the images vary inpose, expression, illumination and scale and 400 images from the ORL facedatabase, where the images slightly vary in pose. Our method has shown 90.3%,93% and 98.75% recognition accuracy for the FRAV2D, FERET and the ORL databaserespectively.","An adaptive block based integrated LDP,GLCM,and Morphological features
  for Face Recognition",Automatic Face Recognition using GLCM Based Features,0.2,0.26380128150117166,0
"  The study of variations in solar activity is important for understanding theunderlying mechanism of solar activity and for predicting the level of activityin view of the activity impact on space weather and global climate. Here wehave used the amplitudes (the peak values of the 13-month smoothedinternational sunspot number) of Solar Cycles 1-24 to predict the relativeamplitudes of the solar cycles during the rising phase of the upcomingGleissberg cycle. We fitted a cosine function to the amplitudes and times ofthe solar cycles after subtracting a linear fit of the amplitudes. The bestcosine fit shows overall properties (periods, maxima, minima, etc.) ofGleissberg cycles, but with large uncertainties. We obtain a pattern of therising phase of the upcoming Gleissberg cycle, but there is considerableambiguity. Using the epochs of violations of the Gnevyshev-Ohl rule (G-O rule)and the `tentative inverse G-O rule' of solar cycles during the period1610-2015, and also using the epochs where the orbital angular momentum of theSun is steeply decreased during the period 1600-2099, we infer that Solar Cycle25 will be weaker than Cycle 24. Cycles 25 and 26 will have almost samestrength, and their epochs are at the minimum between the current and upcomingGleissberg cycles. In addition, Cycle 27 is expected to be stronger than Cycle26 and weaker than Cycle 28, and Cycle 29 is expected to be stronger than bothCycles 28 and 30. The maximum of Cycle 29 is expected to represent the nextGleissberg maximum. Our analysis also suggests a much lower value (30-40) forthe maximum amplitude of the upcoming Cycle 25.",Will Solar Cycles 25 and 26 Be Weaker than Cycle 24 ?,"The relative amplitudes of solar cycles during the rising phase of
  the upcoming Gleissberg",0.16,0.0,0
  This research presents a model of a complex dynamic object running on amulti-core system. Discretization and numerical integration for multibodymodels of vehicle rail elements in the vertical longitudinal plane fluctuationsis considered. The implemented model and solution of the motion differentialequations allow estimating the basic processes occurring in the system withvarious external influences. Hence the developed programming model can be usedfor performing analysis and comparing new vehicle designs.  Keywords-dynamic model; multi-core system; SMP system; rolling stock.,"Parallel implementation of a vehicle rail dynamical model for multi-core
  systems",A Dynamic Model of a Multi-Core System with Dynamic Rail Elements,0.5,0.36720562698935927,0
"  We present fully dynamic simulations of heavy ion collisions at RHIC energieswithin the perturbative QCD-based partonic transport model BAMPS, focusing onthe simultaneous investigation of jet-quenching and elliptic flow. The modelconsistently features elastic and inelastic 2 -> 3 processes, the latter beingbased on the Gunion-Bertsch matrix element. We discuss first attempts to extendthe model to include light quark degrees of freedom and study the energy lossof high energy gluons and quarks in a static partonic medium. The differencebetween gluons and quarks in inelastic processes is found to be weaker thanexpected from color factors, due to a self-quenching effect associated with acut-off modeling the LPM effect.",Jets and flow within a pQCD-based partonic transport model,Dynamic simulations of heavy ion collisions at RHIC energies,0.0,0.0,0
"  We propose a method called ideal regression for approximating an arbitrarysystem of polynomial equations by a system of a particular type. Usingtechniques from approximate computational algebraic geometry, we show how wecan solve ideal regression directly without resorting to numericaloptimization. Ideal regression is useful whenever the solution to a learningproblem can be described by a system of polynomial equations. As an example, wedemonstrate how to formulate Stationary Subspace Analysis (SSA), a sourceseparation problem, in terms of ideal regression, which also yields aconsistent estimator for SSA. We then compare this estimator in simulationswith previous optimization-based approaches for SSA.",Regression for sets of polynomial equations,Optimal Regression for Stationary Subspace Analysis,0.3333333333333333,0.5081327481546147,0
"  Accurate and robust segmentation of abdominal organs on CT is essential formany clinical applications such as computer-aided diagnosis and computer-aidedsurgery. But this task is challenging due to the weak boundaries of organs, thecomplexity of the background, and the variable sizes of different organs. Toaddress these challenges, we introduce a novel framework for multi-organsegmentation by using organ-attention networks with reverse connections(OAN-RCs) which are applied to 2D views, of the 3D CT volume, and outputestimates which are combined by statistical fusion exploiting structuralsimilarity. OAN is a two-stage deep convolutional network, where deep networkfeatures from the first stage are combined with the original image, in a secondstage, to reduce the complex background and enhance the discriminativeinformation for the target organs. RCs are added to the first stage to give thelower layers semantic information thereby enabling them to adapt to the sizesof different organs. Our networks are trained on 2D views enabling us to useholistic information and allowing efficient computation. To compensate for thelimited cross-sectional information of the original 3D volumetric CT,multi-sectional images are reconstructed from the three different 2D viewdirections. Then we combine the segmentation results from the different viewsusing statistical fusion, with a novel term relating the structural similarityof the 2D views to the original 3D structure. To train the network and evaluateresults, 13 structures were manually annotated by four human raters andconfirmed by a senior expert on 236 normal cases. We tested our algorithm andcomputed Dice-Sorensen similarity coefficients and surface distances forevaluating our estimates of the 13 structures. Our experiments show that theproposed approach outperforms 2D- and 3D-patch based state-of-the-art methods.","Abdominal multi-organ segmentation with organ-attention networks and
  statistical fusion",A Deep Convolutional Network for 3D CT Segmentation,0.10526315789473685,0.0,0
"  A density dependent relativistic mean-field model is determined to reproducethe components of the nucleon self-energy at low densities. This model is usedto investigate spinodal instabilities in isospin asymmetric nuclear matter atfinite temperatures. The inhomogeneous density distributions in the spinodalregion are investigated through calculations in a cubic Wigner-Seitz cell.Compared to results obtained in phenomenological calculations the spinodalregion is large, i.e. the spinodal region at zero temperature can reachdensities above 0.12 fm$^{-3}$. The predicted spinodal region is concentratedaround isospin symmetric nuclear matter and the critical temperature isconsiderably lower than in the previous microscopic based investigation withina non-relativistic Brueckner-Hartree-Fock approach.","Spinodal Instabilities in Asymmetric Nuclear Matter Based on Realistic
  $NN$ Interactions","Spinodal instabilities in isospin asymmetric nuclear matter at finite
  temperature",0.5714285714285713,0.6051012508914458,0
"  The effect of the quantum feedback on the tightness of the variance-baseduncertainty, the possibility of using quantum feedback to prepare the statewith a better tightness, and the relationship between the tightness of theuncertainty and the mixedness of the system are studied. It is found that thetightness of Schrodinger-Robertson uncertainty (SUR) relation has a strictliner relationship with the mixedness of the system. As for the Robertsonuncertainty relation (RUR), we find that the tightness can be enhanced bytuning the feedback at the beginning of the evolution. In addition, we deducethat the tightness of RUR has an inverse relationship with the mixedness andthe relationship turns into a strict linear one when the system reach thesteady state.","The effects of different quantum feedback types on the tightness of the
  variance-based uncertainty",Quantum feedback and the Robertson uncertainty relation,0.36363636363636365,0.29765372490051634,0
"  The fact that classical mathematical proofs of simply existential statementscan be read as programs was established by Goedel and Kreisel half a centuryago. But the possibility of extracting useful computational content fromclassical proofs was taken seriously only from the 1990s on when it wasdiscovered that proof interpretations based on Goedel's and Kreisel's ideas canprovide new nontrivial algorithms and numerical results, and the Curry-Howardcorrespondence can be extended to classical logic via programming concepts suchas continuations and control operators.  The workshop series ""Classical Logic and Computation"" aims to support afruitful exchange of ideas between the various lines of research oncomputational aspects of classical logic. This volume contains the abstracts ofthe invited lectures and the accepted contributed papers of the third CL&Cworkshop which was held jointly with the workshop ""Program Extraction andConstructive Mathematics"" at the University of Brno in August 21-22, 2010, as asatellite of CSL and MFCS. The workshops were held in honour of HelmutSchwichtenberg who became ""professor emeritus"" in September 2010.  The topics of the papers include the foundations, optimizations andapplications of proof interpretations such as Hilbert's epsilon substitutionmethod, Goedel's functional interpretation, learning based realizability andnegative translations as well as special calculi and theories capturingcomputational and complexity-theoretic aspects of classical logic such as thelambda-mu-calculus, applicative theories, sequent-calculi, resolution andcut-elimination","Proceedings Third International Workshop on Classical Logic and
  Computation","Proceedings Third Workshop on Computational aspects of Classical
  Logic and Computation",0.7999999999999999,0.31702331385234306,0
"  In the present paper, we consider the following magnetic nonlinear Choquardequation $$ \left\{  \begin{array}{ll}  & (-i \nabla+A(x))^2u + \mu g(x)u = \lambda u + (|x|^{-\alpha} *|u|^{2^*_\alpha})|u|^{2^*_\alpha-2}u ,\; u>0 \;\text{in} \; \mathbb{ R}^n ,  & u \in H^1(\mathbb{R}^n, \mathbb{ C})  \end{array} \right\}.$$ where $n \geq 4$, $2^*_\alpha=\frac{2n-\alpha}{n-2}$, $\lambda>0$, $\mu \in \mathbb{ R}$ is a parameter,$\alpha \in (0,n)$, $A(x): \mathbb{R}^n \rightarrow \mathbb{ R}^n$ is amagnetic vector potential and $g(x)$ is a real valued potential function on$\mathbb{R}^n$. Using variational methods, we establish the existence of leastenergy solution under some suitable conditions. Moreover, the concentrationbehavior of solutions is also studied as $\mu \rightarrow +\infty$.","On Concentration of least energy solutions for magnetic critical
  Choquard equations",On the magnetic nonlinear Choquard equation,0.4705882352941177,0.3654520756092885,0
"  In video prediction tasks, one major challenge is to capture the multi-modalnature of future contents and dynamics. In this work, we propose a simple yeteffective framework that can efficiently predict plausible future states. Thekey insight is that the potential distribution of a sequence could beapproximated with analogous ones in a repertoire of training pool, namely,expert examples. By further incorporating a novel optimization scheme into thetraining procedure, plausible predictions can be sampled efficiently fromdistribution constructed from the retrieved examples. Meanwhile, our methodcould be seamlessly integrated with existing stochastic predictive models;significant enhancement is observed with comprehensive experiments in bothquantitative and qualitative aspects. We also demonstrate the generalizationability to predict the motion of unseen class, i.e., without access tocorresponding data during training phase.",Video Prediction via Example Guidance,Efficient Prediction of Future States from Video,0.16666666666666666,0.7311104457090247,0
"  The analysis of ring images produced by muons in an Imaging AtmosphericCherenkov Telescope (IACT) provides a powerful and precise method to calibratethe IACT optical throughput and monitor its optical point-spread function(PSF). First proposed by the Whipple collaboration in the early 90's, thismethod has been refined by the so-called second generation of IACT experiments:H.E.S.S., MAGIC and VERITAS. We review here the progress made with theseinstruments and investigate the applicability of the method as the primarythroughput calibration method for the different telescope types forming thefuture Cherenkov Telescope Array (CTA). We find several additional systematiceffects not yet taken into account by previous authors and propose several newanalytical methods to include these in the analysis. Slight modifications inhardware and analysis need to be made to ensure that such a calibration worksas accurately as required for the CTA. We derive analytic estimates for theexpected muon data rates for optical throughput calibration, camera pixelflat-fielding and monitoring of the optical PSF. The achievable statistical andsystematic uncertainties of the method are also assessed.","Using Muon Rings for the Calibration of the Cherenkov Telescope Array: A
  Systematic Review of the Method and its Potential Accuracy","Theoretical and analytical aspects of the optical throughput calibration
  method for the Cherenkov",0.23529411764705882,0.314976994006728,0
"  [Context and motivation] Internet of Things (IoT) is becoming commonthroughout everyday lives. However, the interaction is often different fromwhen using e.g. computers and other smart devices. Furthermore, an IoT deviceis often dependent on several other systems, heavily impacting the userexperience (UX). Finally, the domain is changing rapidly and is driven bytechnological innovation.  [Question/problem] In this qualitative study, we explore how companies elicitUX requirements in the context of IoT. A key part of contemporary IoTdevelopment is also data-driven approaches. Thus, these are also considered inthe study.  [Principal idea / Results] There is a knowledge gap around data-drivenmethodologies, there are examples of companies that collect large amount ofdata but do not always know how to utilize it. Furthermore, many of thecompanies struggle to handle the larger system context, where their productsand the UX they control are only one part of the complete IoT ecosystem.  [Contribution] We provide qualitative empirical data from IoT developingcompanies. Based on our findings, we identify challenges for the companies andareas for future work.","An exploratory study on how Internet of Things developing companies
  handle User Experience Requirements","A qualitative study on the impact of IoT on the UX
  of companies",0.29629629629629634,0.37053273356129773,0
"  Zero-range effective interactions are commonly used in nuclear physics todescribe a many-body system in the mean-field framework. If they are employedin beyond- mean-field models, an artificial ultraviolet divergence is generatedby the zero-range of the interaction. We analyze this problem in symmetricnuclear matter with the t0-t3 Skyrme model. In this case, the second-orderenergy correction diverges linearly with the momentum cutoff. After that, weextend the work to the case of nuclear matter with the full Skyrme interaction.A strong divergence related to the velocity-dependent terms of the interactionis obtained. Moreover, a global fit can be simultaneously performed for bothsymmetric and nuclear matter with different neutron-to-proton ratios. Theseresults pave the way for applications to finite nuclei in the framework ofbeyond mean-field theories.","A beyond-mean-field example with zero-range effective interactions in
  infinite nuclear matter",Neutron-to-proton divergence in symmetric nuclear matter,0.2727272727272727,0.24439253249722204,0
"  Quantum amplifier is an essential device in quantum information processing.As in the classical (non-quantum) case, its characteristic uncertainty needs tobe suppressed by feedback, and in fact such a control theory for a singlequantum amplifier has recently been developed. This letter extends this resultto the case of cascaded quantum amplifier. In particular, we consider two typesof structures: the case where controlled amplifiers are connected in series,and the case where a single feedback control is applied to the cascadedamplifier. Then, we prove that the latter is better in the sense of sensitivityto the uncertainty. A detailed numerical simulation is given to show actualperformance of these two feedback schemes.",Sensitivity Analysis of Cascaded Quantum Feedback Amplifier,Control of cascaded quantum amplifiers,0.6666666666666666,0.4482700320176827,0
"  The adaptive BDDC method is extended to the selection of face constraints inthree dimensions. A new implementation of the BDDC method is presented based ona global formulation without an explicit coarse problem, with massiveparallelism provided by a multifrontal solver. Constraints are implemented by aprojection and sparsity of the projected operator is preserved by a generalizedchange of variables. The effectiveness of the method is illustrated on severalengineering problems.",Adaptive BDDC in Three Dimensions,Adaptive BDDC method for face constraints in three dimensions,0.7142857142857143,0.45180100180492244,0
"  We present various results on multiplying cycles in the symmetric group. Ourfirst result is a generalisation of the following theorem of Boccara (1980):the number of ways of writing an odd permutation in the symmetric group on $n$symbols as a product of an $n$-cycle and an $n-1$-cycle is independent of thepermutation chosen. We give a number of different approaches of ourgeneralisation. One partial proof uses an inductive method which we also applyto other problems. In particular, we give a formula for the distribution of thenumber of cycles over all products of cycles of fixed lengths. Anotherapplication is related to the recent notion of separation probabilities forpermutations introduced by Bernardi, Du, Morales and Stanley (2014).","On products of long cycles: short cycle dependence and separation
  probabilities",On multiplying cycles in the symmetric group,0.2222222222222222,0.34718201116725705,0
"  Saliency computation has become a popular research field for manyapplications due to the useful information provided by saliency maps. For asaliency map, local relations around the salient regions in multi-channelperspective should be taken into consideration by aiming uniformity on theregion of interest as an internal approach. And, irrelevant salient regionshave to be avoided as much as possible. Most of the works achieve thesecriteria with external processing modules; however, these can be accomplishedduring the conspicuity map fusion process. Therefore, in this paper, a newmodel is proposed for saliency/conspicuity map fusion with two concepts: a)input image transformation relying on the principal component analysis (PCA),and b) saliency conspicuity map fusion with multi-channel pulsed coupled neuralnetwork (m-PCNN). Experimental results, which are evaluated by precision,recall, F-measure, and area under curve (AUC), support the reliability of theproposed method by enhancing the saliency computation.","Saliency Fusion in Eigenvector Space with Multi-Channel Pulse Coupled
  Neural Network","Saliency/Conspicuity Map Fusion with Multi-Channel Pulsed Coupled Neural
",0.7272727272727272,0.44677880536150705,0
"  While there exists a wide variety of Low Dynamic Range (LDR) quality metrics,only a limited number of metrics are designed specifically for the High DynamicRange (HDR) content. With the introduction of HDR video compressionstandardization effort by international standardization bodies, the need for anefficient video quality metric for HDR applications has become more pronounced.The objective of this study is to compare the performance of the existingfull-reference LDR and HDR video quality metrics on HDR content and identifythe most effective one for HDR applications. To this end, a new HDR videodataset is created, which consists of representative indoor and outdoor videosequences with different brightness, motion levels and different representingtypes of distortions. The quality of each distorted video in this dataset isevaluated both subjectively and objectively. The correlation between thesubjective and objective results confirm that VIF quality metric outperformsall to ther tested metrics in the presence of the tested types of distortions.","Evaluating the Performance of Existing Full-Reference Quality Metrics on
  High Dynamic Range (HDR) Video Content","Comparison of Low Dynamic Range and High Dynamic Range Video Quality
  Metrics",0.35714285714285715,0.2765907936016651,0
  We construct families of prime ideals in polynomial rings for which thenumber of associated primes of the second power (or higher powers) isexponential in the number of variables in the ring. We give a lower bound onthe Ananyan-Hochster constant for the number of associated primes.,Many associated primes of powers of primes,Prime ideals in polynomial rings,0.16666666666666666,0.0,0
"  Recently, virtual reality, augmented reality, robotics, autonomous driving etal attract much attention of both academic and industrial community, in whichimage based camera localization is a key task. However, there has not been acomplete review on image-based camera localization. It is urgent to map thistopic to help people enter the field quickly. In this paper, an overview ofimage based camera localization is presented. A new and complete kind ofclassifications for image based camera localization is provided and the relatedtechniques are introduced. Trends for the future development are alsodiscussed. It will be useful to not only researchers but also engineers andother people interested.",Image Based Camera Localization: an Overview,Image Based Camera Localization,0.8,0.42888194248035344,0
"  Using molecular simulation to aid in the analysis of neutron reflectometrymeasurements is commonplace. However, reflectometry is a tool to probelarge-scale structures, and therefore the use of all-atom simulation may beirrelevant. This work presents the first direct comparison between thereflectometry profiles obtained from different all-atom and coarse-grainedmolecular dynamics simulations. These are compared with a traditional modellayer structure analysis method to determine the minimum simulation resolutionrequired to accurately reproduce experimental data. We find that systematiclimits reduce the efficacy of the MARTINI potential model, while the Bergerunited-atom and Slipids all-atom potential models agree similarly well with theexperimental data. The model layer structure gives the best agreement, however,the higher resolution simulation-dependent methods produce an agreement that iscomparable. Finally, we use the atomistic simulation to advise on possibleimprovements that may be offered to the model layer structures, creating a morerealistic monolayer model.","Assessing molecular simulation for the analysis of lipid monolayer
  reflectometry","Comparison of molecular simulation and all-atom models for neutron
  reflectometry analysis",0.3636363636363636,0.4832697830906221,0
  The question of Lorentz invariance for finite N approximations ofrelativistic membranes is addressed. We find that one of the classicalmanifestations of Lorentz-invariance is not possible for NxN matrices (at leastwhen N=2 or 3). How the symmetry is restored in the large N limit is studiednumerically.,Lorentz-invariant membranes and finite matrix approximations,Lorentz invariance for finite N approximations of relativistic membranes,0.5,0.7598356856515925,0
"  Self-assembly is the autonomous organization of components into patterns orstructures: an essential ingredient of biology and a desired route to complexorganization. At equilibrium, the structure is encoded through specificinteractions, at an unfavorable entropic cost for the system. An alternativeapproach, widely used by Nature, uses energy input to bypass the entropybottleneck and develop features otherwise impossible at equilibrium.Dissipative building blocks that inject energy locally were made available byrecent advance in colloidal science but have not been used to controlself-assembly. Here we show the robust formation of self-powered rotors anddynamical superstructures from active particles and harness non-equilibriumphoretic phenomena to tailor interactions and direct self-assembly. We use aphotoactive component that consumes fuel, hematite, to devise phototacticmicroswimmers that form self-spinning microgears following spatiotemporal lightpatterns. The gears are coupled via their chemical clouds and constitute theelementary bricks of synchronized superstructures, which autonomously regulatetheir dynamics. The results are quantitatively rationalized on the basis of astochastic description of diffusio-phoretic oscillators dynamically coupled bychemical gradients to form directional interactions. Our findings demonstratethat non-equilibrium phenomena can be harnessed to shape interactions andprogram hierarchical constructions. It lays the groundwork for theself-assembly of dynamical architectures and synchronized micro-machinery.",Targeted Assembly and Synchronization of Self-Spinning Microgears,Self-Assembly of Dynamical Structures from Active Particles,0.25,0.6147881529512643,0
"  We study abduction in First Order Horn logic theories where all atoms can beabduced and we are looking for preferred solutions with respect to threeobjective functions: cardinality minimality, coherence, and weighted abduction.We represent this reasoning problem in Answer Set Programming (ASP), in orderto obtain a flexible framework for experimenting with global constraints andobjective functions, and to test the boundaries of what is possible with ASP.Realizing this problem in ASP is challenging as it requires value invention andequivalence between certain constants, because the Unique Names Assumption doesnot hold in general. To permit reasoning in cyclic theories, we formallydescribe fine-grained variations of limiting Skolemization. We identify termequivalence as a main instantiation bottleneck, and improve the efficiency ofour approach with on-demand constraints that were used to eliminate the samebottleneck in state-of-the-art solvers. We evaluate our approach experimentallyon the ACCEL benchmark for plan recognition in Natural Language Understanding.Our encodings are publicly available, modular, and our approach is moreefficient than state-of-the-art solvers on the ACCEL benchmark.","Modeling Variations of First-Order Horn Abduction in Answer Set
  Programming",An Approach to Abduction in First Order Horn Logic,0.3,0.4042892997911646,0
"  We systematically analyze all possible supersymmetry multiplets that includethe supersymmetry current and the energy-momentum tensor in various dimensions,focusing on N=1 in four dimensions. The most general such multiplet is theS-multiplet, which includes 16 bosonic and 16 fermionic operators. In specialsituations it can be decomposed, leading to smaller multiplets with 12+12 oreven 8+8 operators. Physically, these multiplets give rise to different branecharges in the supersymmetry algebra. The S-multiplet is needed when thealgebra contains both string and domain wall charges. In lower dimensions (orin four-dimensional N=2 theories) the algebra can include space-filling branecharges, which are associated with partial supersymmetry breaking. Thisphenomenon is physically distinct from ordinary spontaneous supersymmetrybreaking. Our analysis leads to new results about the dynamics ofsupersymmetric field theories. These include constraints on the existence ofcertain charged branes and the absence of magnetic charges in U(1) gaugetheories with a Fayet-Iliopoulos term.",Supercurrents and Brane Currents in Diverse Dimensions,Supersymmetry Multiplets in N=1 and N=2,0.13333333333333333,0.6431870218238024,0
"  The WZW form of open superstring field theory has linearized gaugeinvariances associated with the BRST operator Q and the zero mode eta_0 of thepicture minus-one fermionic superconformal ghost. We discuss gauge fixing ofthe free theory in a simple class of gauges using the Faddeev-Popov method. Wefind that the world-sheet ghost number of ghost and antighost string fieldsranges over all integers, except one, and at any fixed ghost number, only afinite number of picture numbers appear. We calculate the propagators in avariety of gauges and determine the field-antifield content and the free masteraction in the Batalin-Vilkovisky formalism. Unlike the case of bosonic stringfield theory, the resulting master action is not simply related to the originalgauge-invariant action by relaxing the constraint on the ghost and picturenumbers.","Open superstring field theory I: gauge fixing, ghost structure, and
  propagator",Gauge fixing of open superstring field theory,0.4444444444444444,0.23217460403031903,0
"  We lay out the extension of range-separated density-functional theory to afour-component relativistic frame-work using a Dirac-Coulomb-Breit Hamiltonianin the no-pair approximation. This formalism combines a wave-function methodfor the long-range part of the electron-electron interaction with adensity(-current) functionalfor the short-range part of the interaction. Weconstruct for this formalism a short-range exchange local-densityapproximationbased on calculations on a relativistic homogeneous electron gas with amodified Coulomb-Breitelectron-electron interaction. More specifically, weprovide the relativistic short-range Coulomb and Breit ex-change energies perparticle of the relativistic homogeneous electron gas in the form of Pad eapproximantswhich are systematically improvable to arbitrary accuracy. Thesequantities, as well as the associated effectiveCoulomb-Breit exchange hole,show the important impact of relativity on short-range exchange effects forhighdensities.","Four-component relativistic range-separated density-functional theory:
  Short-range exchange local-density approximation",Short-range exchange in relativistic homogeneous electron gas,0.2727272727272727,0.3884935863283276,0
"  We combine K-Nearest Neighbors (KNN) with genetic algorithm (GA) forphotometric redshift estimation of quasars, short for GeneticKNN, which is aweighted KNN approach supported by GA. This approach has two improvementscompared to KNN: one is the feature weighted by GA; another is that thepredicted redshift is not the redshift average of K neighbors but the weightedaverage of median and mean of redshifts for K neighbors, i.e. $p\timesz_{median} + (1-p)\times z_{mean}$. Based on the SDSS and SDSS-WISE quasarsamples, we explore the performance of GeneticKNN for photometric redshiftestimation, comparing with the other six traditional machine learning methods,i.e. Least absolute shrinkage and selection operator (LASSO), support vectorregression (SVR), Multi Layer Perceptrons (MLP), XGBoost, KNN and randomforest. KNN and random forest show their superiority. Considering the easyimplementation of KNN, we make improvement on KNN as GeneticKNN and applyGeneticKNN on photometric redshift estimation of quasars. Finally theperformance of GeneticKNN is better than that of LASSO, SVR, MLP, XGBoost, KNNand random forest for all cases. Moreover the accuracy is better with theadditional WISE magnitudes for the same method.","GeneticKNN: A Weighted KNN Approach Supported by Genetic Algorithm for
  Photometric Redshift Estimation of Quasars",Genetic KNN for Photometric Redshift Estimation of Quasars,0.608695652173913,0.3047721770063185,0
"  Several works have shown unconditional hardness (via integrality gaps) ofcomputing equilibria using strong hierarchies of convex relaxations. Suchresults however only apply to the problem of computing equilibria that optimizea certain objective function and not to the (arguably more fundamental) task offinding \emph{any} equilibrium.  We present an algorithmic model based on the sum-of-squares (SoS) hierarchythat allows escaping this inherent limitation of integrality gaps. In thismodel, algorithms access the input game only through a relaxed solution to thenatural SoS relaxation for computing equilibria. They can then adaptivelyconstruct a list of candidate solutions and invoke a verification oracle tocheck if any candidate on the list is a solution. This model captures mostwell-studied approximation algorithms such as those for Max-Cut, Sparsest Cut,and Unique-Games.  The state-of-the-art algorithms for computing exact and approximateequilibria in two-player, n-strategy games are captured in this model andrequire that at least one of i) size (~ running time) of the SoS relaxation orii) the size of the list of candidates, be at least $2^{\Omega(n)}$ and$n^{\Omega(\log{(n)})}$ respectively. Our main result shows a lower bound thatmatches these upper bound up to constant factors in the exponent.  This can be interpreted as an unconditional confirmation, in our restrictedalgorithmic framework, of Rubinstein's recent conditional hardness \cite{Rub}for computing approximate equilibria.  Our proof strategy involves constructing a family of games that all share acommon sum-of-squares solution but every (approximate) equilibrium of one gameis far from every (approximate) equilibrium of any other game in the family.","Sum-of-Squares meets Nash: Optimal Lower Bounds for Finding any
  Equilibrium",Unconditional Hardness for Computing Equilibria,0.11764705882352941,0.24601580968354606,0
"  Based on the superconvergent approximation at some point (depending on thefractional order $\alpha$, but not belonging to the mesh points) forGr\""{u}nwald discretization to fractional derivative, we develop a series ofhigh order quasi-compact schemes for space fractional diffusion equations.Because of the quasi-compactness of the derived schemes, no points beyond thedomain are used for all the high order schemes including second order, thirdorder, fourth order, and even higher order schemes; moreover, the algebraicequations for all the high order schemes have the completely same matrixstructure. The stability and convergence analysis for some typical schemes aremade; the techniques of treating the nonhomogeneous boundary conditions areintroduced; and extensive numerical experiments are performed to confirm thetheoretical analysis or verify the convergence orders.","A Series of High Order Quasi-Compact Schemes for Space Fractional
  Diffusion Equations Based on the Superconvergent Approximations for
  Fractional Derivatives",High order quasi-compact schemes for space fractional diffusion equations,0.6451612903225806,0.20225185092507977,0
"  'Evolutionary rescue' is the potential for evolution to enable populationpersistence in a changing environment. Even with eventual rescue, evolutionarytime lags can cause the population size to temporarily fall below a thresholdsusceptible to extinction. To reduce extinction risk given human-driven globalchange, conservation management can enhance populations through actions such ascaptive breeding. To quantify the optimal timing of, and indicators forengaging in, investment in temporary enhancement to enable evolutionary rescue,we construct a model of coupled demographic-genetic dynamics given a movingoptimum. We assume 'decelerating change', as might be relevant to climatechange, where the rate of environmental change initially exceeds a rate whereevolutionary rescue is possible, but eventually slows. We analyze the optimalcontrol path of an intervention to avoid the population size falling below athreshold susceptible to extinction, minimizing costs. We find that the optimalpath of intervention initially increases as the population declines, thendeclines and ceases when the population growth rate becomes positive, whichlags the stabilization in environmental change. In other words, the optimalstrategy involves increasing investment even in the face of a decliningpopulation, and positive population growth could serve as a signal to end theintervention. In addition, a greater carrying capacity relative to the initialpopulation size decreases the optimal intervention. Therefore, a one-timeaction to increase carrying capacity, such as habitat restoration, can reducethe amount and duration of longer-term investment in population enhancement,even if the population is initially lower than and declining away from the newcarrying capacity.",Optimal Investment to Enable Evolutionary Rescue,"Optimal conservation management for adaptive species: a moving optimal
  strategy",0.125,0.5623413251903491,0
"  VANET (Vehicular Ad-hoc Network) is a new technology which has taken enormousattention in the recent years. Vehicular ad hoc network is formed by cars whichare called nodes; allow them to communicate with one another without using anyfixed road side unit. It has some unique characteristics which make itdifferent from other ad hoc network as well as difficult to define any exactmobility model and routing protocols because of their high mobility andchanging mobility pattern. Hence performance of routing protocols can vary withthe various parameters such as speed, pause time, node density and trafficscenarios. In this research paper, the performance of two on-demand routingprotocols AODV & DSR has been analyzed by means of packet delivery ratio, losspacket ratio & average end-to-end delay with varying pause time, speed time andnode density under TCP & CBR connection.","Performance Evaluation of AODV & DSR with Varying Pause Time & Speed
  Time Over TCP & CBR Connections in VANET","Performance Analysis of On-Demand Routing Protocols under TCP & CBR
  Connections",0.35714285714285715,0.11456777556561246,0
"  Phosphorene, a monolayer of black phosphorus (BP), is an elementaltwo-dimensional material with interesting physical properties, such as highcharge carrier mobility and exotic anisotropic in-plane properties. Tofundamentally understand these various physical properties, it is criticallyimportant to conduct an atomic-scale structural investigation of phosphorene,particularly regarding various defects and preferred edge configurations.However, it has been challenging to investigate mono- and few-layer phosphorenebecause of technical difficulties arising in the preparation of a high-qualitysample and damages induced during the characterization process. Here, wesuccessfully fabricate high-quality monolayer phosphorene using a controlledthinning process with transmission electron microscopy, and subsequentlyperform atomic-resolution imaging. Graphene protection suppresses thee-beam-induced damage to multi-layer BP and one-side graphene protectionfacilitates the layer-by-layer thinning of the samples, rendering high-qualitymonolayer and bilayer regions. We also observe the formation of atomic-scalecrystalline edges predominantly aligned along the zigzag and (101)terminations, which is originated from edge kinetics under e-beam-inducedsputtering process. Our study demonstrates a new method to image and preciselymanipulate the thickness and edge configurations of air-sensitivetwo-dimensional materials.","Fabrication and Imaging of Monolayer Phosphorene with Preferred Edge
  Configurations via Graphene-Assisted Layer-by-Layer Thinning","Optimizing atomic-resolution imaging of mono- and few-layer phosphorene
 ",0.22222222222222224,0.33401359264888447,0
"  We propose a Raman quantum memory scheme that uses several atomic ensemblesto store and retrieve the multimode highly entangled state of an opticalquantum frequency comb, such as the one produced by parametric down-conversionof a pump frequency comb. We analyse the efficiency and the fidelity of such aquantum memory. Results show that our proposal may be helpful to multimodeinformation processing using the different frequency bands of an opticalfrequency comb.",Atomic quantum memory for multimode frequency combs,A Raman quantum memory scheme using atomic ensemblesto store,0.25,0.408248290463863,0
"  Zero-range effective interactions are commonly used in nuclear physics todescribe a many-body system in the mean-field framework. If they are employedin beyond- mean-field models, an artificial ultraviolet divergence is generatedby the zero-range of the interaction. We analyze this problem in symmetricnuclear matter with the t0-t3 Skyrme model. In this case, the second-orderenergy correction diverges linearly with the momentum cutoff. After that, weextend the work to the case of nuclear matter with the full Skyrme interaction.A strong divergence related to the velocity-dependent terms of the interactionis obtained. Moreover, a global fit can be simultaneously performed for bothsymmetric and nuclear matter with different neutron-to-proton ratios. Theseresults pave the way for applications to finite nuclei in the framework ofbeyond mean-field theories.","A beyond-mean-field example with zero-range effective interactions in
  infinite nuclear matter",Neutron-to-proton divergence in symmetric nuclear matter,0.2727272727272727,0.24439253249722204,0
"  We present a two-parameter family of exactly solvable quantum many-bodysystems in one spatial dimension containing the Lieb-Liniger model ofinteracting bosons as a particular case. The principal building block of thisconstruction is the previously-introduced (arXiv:1712.09375) family oftwo-particle scattering matrices. We discuss an $SL(2)$ transformationconnecting the models within this family and make a correspondence withgeneralized point interactions. The Bethe equations for the ground state arediscussed with a special emphasis on ""non-interacting modes"" connected by themodular subgroup of $SL(2)$. The bound state solutions are discussed and areconjectured to follow some correlated version of the string hypothesis. Theexcitation spectrum of the new models in this family is derived in analogy tothe Lieb-Liniger model and we show that for certain choices of parameters aspectrum inversion occurs such that the Umklapp solutions become the new groundstate.",Something interacting and solvable in 1d,Two-parameter quantum many-bodysystems with Lieb-Liniger model,0.0,0.0,0
"  The fundamental aim of this paper is to describe q-Analogue of p-adic loggamma functions with weight alpha and beta. Moreover, we give relationshipbetween p-adic q-log gamma funtions with weight ({\alpha}, {\beta}) andq-extension of Genocchi numbers with weight alpha and beta and modified q Eulernumbers with weight {\alpha}","q Analogue of p adic log gamma functions associated with modified q
  extension of Genocchi numbers with weight alpha and beta",Q-Analogue of p-adic loggamma functions with weight alpha and beta,0.6666666666666667,0.14223148886922268,0
"  Convolutional Neural Networks (CNNs) have revolutionized the research incomputer vision, due to their ability to capture complex patterns, resulting inhigh inference accuracies. However, the increasingly complex nature of theseneural networks means that they are particularly suited for server computerswith powerful GPUs. We envision that deep learning applications will beeventually and widely deployed on mobile devices, e.g., smartphones,self-driving cars, and drones. Therefore, in this paper, we aim to understandthe resource requirements (time, memory) of CNNs on mobile devices. First, bydeploying several popular CNNs on mobile CPUs and GPUs, we measure and analyzethe performance and resource usage for every layer of the CNNs. Our findingspoint out the potential ways of optimizing the performance on mobile devices.Second, we model the resource requirements of the different CNN computations.Finally, based on the measurement, pro ling, and modeling, we build andevaluate our modeling tool, Augur, which takes a CNN configuration (descriptor)as the input and estimates the compute time and resource usage of the CNN, togive insights about whether and how e ciently a CNN can be run on a givenmobile platform. In doing so Augur tackles several challenges: (i) how toovercome pro ling and measurement overhead; (ii) how to capture the variance indifferent mobile platforms with different processors, memory, and cache sizes;and (iii) how to account for the variance in the number, type and size oflayers of the different CNN configurations.","Modeling the Resource Requirements of Convolutional Neural Networks on
  Mobile Devices","Augur: A Modeling Tool for Mobile Machine Learning on
  Mobile Devices",0.36363636363636365,0.2998221389342337,0
"  Glacial cycles redistribute water between oceans and continents causingpressure changes in the upper mantle, with consequences for melting of Earth'sinterior. Using Plio-Pleistocene sea-level variations as a forcing function,theoretical models of mid-ocean ridge dynamics that include melt transportpredict temporal variations in crustal thickness of hundreds of meters. Newbathymetry from the Australian-Antarctic ridge shows significant spectralenergy near the Milankovitch periods of 23, 41, and 100 ky, consistent withmodel predictions. These results suggest that abyssal hills, one of the mostcommon bathymetric features on Earth, record the magmatic response to changesin sea level. The models and data support a link between glacial cycles at thesurface and mantle melting at depth, recorded in the bathymetric fabric of thesea floor.",Glacial cycles drive variations in the production of oceanic crust,"Magmatic response to melting in the upper mantle: glacial cycles at
  depth and mantle",0.16666666666666666,0.35831291876413535,0
"  In this paper we prove semiclassical resolvent estimates for operators withnormally hyperbolic trapping which are lossless relative to non-trappingestimates but take place in weaker function spaces. In particular, we obtainnon-trapping estimates in standard $L^2$ spaces for the resolvent sandwichedbetween operators which localize away from the trapped set $\Gamma$ in a ratherweak sense, namely whose principal symbols vanish on $\Gamma$.",Non-trapping estimates near normally hyperbolic trapping,"Semiclassical resolvent estimates for operators with normally hyperbolic
  trapping",0.5,0.3549481056010053,0
"  Following Bayer and Macr\`{i}, we study the birational geometry of singularmoduli spaces $M$ of sheaves on a K3 surface $X$ which admit symplecticresolutions. More precisely, we use the Bayer-Macr\`{i} map from the space ofBridgeland stability conditions $\mathrm{Stab}(X)$ to the cone of movabledivisors on $M$ to relate wall-crossing in $\mathrm{Stab}(X)$ to birationaltransformations of $M$. We give a complete classification of walls in$\mathrm{Stab}(X)$ and show that every birational model of $M$ obtained byperforming a finite sequence of flops from $M$ appears as a moduli space ofBridgeland semistable objects on $X$. An essential ingredient of our proof isan isometry between the orthogonal complement of a Mukai vector inside thealgebraic Mukai lattice of $X$ and the N\'{e}ron-Severi lattice of $M$ whichgeneralises results of Yoshioka, as well as Perego and Rapagnetta. Moreover,this allows us to conclude that the symplectic resolution of $M$ is deformationequivalent to the 10-dimensional irreducible holomorphic symplectic manifoldfound by O'Grady.",Birational Geometry of Singular Moduli Spaces of O'Grady Type,Bridgeland semistable objects on K3 surfaces,0.0,0.0,0
"  In order to ensure efficient flow of goods in an automated warehouse and toguarantee its continuous distribution to/from picking stations in an effectiveway, decisions about which goods will be delivered to which particular pickingstation by which robot and by which path and in which time have to be madebased on the current state of the warehouse. This task involves solution of twosuproblems: (1) task allocation in which an assignment of robots to goods theyhave to deliver at a particular time is found and (2) planning ofcollision-free trajectories for particular robots (given their actual and goalpositions). The trajectory planning problem is addressed in this paper takinginto account specifics of automated warehouses. First, assignments of allrobots are not known in advance, they are instead presented to the algorithmgradually one by one. Moreover, we do not optimize a makespan, but a throughput- the sum of individual robot plan costs. We introduce a novel approach to thisproblem which is based on the context-aware route planning algorithm [1]. Theperformed experimental results show that the proposed approach has a lower failrate and produces results of higher quality than the original algorithm. Thisis redeemed by higher computational complexity which is nevertheless low enoughfor real-time planning.",Context-Aware Route Planning for Automated Warehouses,Context-Aware Route Planning for Automated Warehouse,1.0,0.7598356856515925,0
"  A time-dependent Hermite-Galerkin spectral method (THGSM) is investigated inthis paper for the nonlinear convection-diffusion equations in the unboundeddomains. The time-dependent scaling factor and translating factor areintroduced in the definition of the generalized Hermite functions (GHF). As aconsequence, the THGSM based on these GHF has many advantages, not only intheorethical proofs, but also in numerical implementations. The stability andspectral convergence of our proposed method have been established in thispaper. The Korteweg-de Vries-Burgers (KdVB) equation and its special cases,including the heat equation and the Burgers' equation, as the examples, havebeen numerically solved by our method. The numerical results are presented, andit surpasses the existing methods in accuracy. Our theoretical proof of thespectral convergence has been supported by the numerical results.",Time-dependent Hermite-Galerkin spectral method and its applications,"Time-dependent Hermite-Galerkin spectral method for the nonlinear
  convection",0.631578947368421,0.345720784641941,0
"  In this work we calculate the corrections to the amputated Green's functionsof 4-fermion operators, in 1-loop Lattice Perturbation theory. One of the novelaspects of our calculations is that they are carried out to O(a^2) (a: latticespacing). We employ the Wilson/clover action for massless fermions (alsoapplicable for the twisted mass action in the chiral limit) and a family ofSymanzik improved actions for gluons. Our calculations have been carried out ina general covariant gauge. Results have been obtained for several popularchoices of values for the Symanzik coefficients. While our Green's functioncalculations regard any pointlike 4-fermion operators which do not mix withlower dimension ones, we pay particular attention to DF=2 operators, bothParity Conserving and Parity Violating (F: flavour). We compute theperturbative renormalization constants for a complete basis of 4-fermionoperators and we study their mixing pattern. For some of the actions consideredhere, even O(a^0) results did not exist in the literature to date. Thecorrection terms which we calculate are essential ingredients for minimizingthe lattice artifacts which are present in non-perturbative evaluations ofrenormalization constants with the RI'-MOM method. Our perturbative results,for the matrix elements of DF=2 operators and for the correspondingrenormalization matrices, depend on a large number of parameters: couplingconstant, number of colors, lattice spacing, external momentum, cloverparameter, Symanzik coefficients, gauge parameter. To make these results mosteasily accessible, we have included them in the distribution package of thispaper, as an ASCII file named: 4-fermi.m; the file is best perused asMathematica input. The main results of this work have been applied to improvenon-perturbative estimates of the B_K-parameter in N_F=2 twisted mass latticeQCD.","Perturbative renormalization factors and O(a^2) corrections for lattice
  4-fermion operators with improved fermion/gluon actions",Reductions to Green's functions in 1-loop Lattice Perturbation theory,0.06896551724137931,0.0,0
"  Direct and unequivocal detection of gravitational waves represents a greatchallenge of contemporary physics and astrophysics. A worldwide effort iscurrently operating towards this direction, building ever sensitive detectors,improving the modelling of gravitational wave sources and employing ever moresophisticated and powerful data analysis techniques. In this paper we reviewthe current status of LIGO and Virgo ground based interferometric detectors andsome data analysis tools used in the continuous wave searches to extract thefaint gravitational signals from the interferometric noise data. Moreover wediscuss also relevant results from recent continuous wave searches.","Searching for continuous gravitational wave signals using LIGO and Virgo
  detectors","LIGO and Virgo ground based interferometric detectors and data analysis
  tools for",0.34782608695652173,0.29502343631964045,0
"  We explore the possibility to construct higher-twist parton distributions ina nucleon at some low reference scale from convolution integrals of thelight-cone wave functions (WFs). To this end we introduce simple models for thefour-particle nucleon WFs involving three valence quarks and a gluon with totalorbital momentum zero, and estimate their normalization (WF at the origin)using QCD sum rules. We demonstrate that these WFs provide one with areasonable description of both polarized and unpolarized gluon parton densitiesat large values of Bjorken variable x > 0.5. Twist-three parton distributionsare then constructed as convolution integrals of qqqg and usual three-quarkWFs. The cases of the polarized structure function g_2(x,Q^2) and singletransverse spin asymmetries are considered in detail. We find that theso-called gluon-pole contribution to twist-three distributions relevant forsingle spin asymmetry vanishes in this model, but is generated perturbativelyat higher scales by the evolution, in the spirit of GRV parton distributions.",Higher twist parton distributions from light-cone wave functions,Higher-twist parton distributions in three-particle nucleon WFs,0.4444444444444444,0.40495158902656925,0
"  As the education fees are becoming more expensive, more students apply forscholarships. Consequently, hundreds and even thousands of applications need tobe handled by the sponsor. To solve the problems, some alternatives based onseveral attributes (criteria) need to be selected. In order to make a decisionon such fuzzy problems, Fuzzy Multiple Attribute Decision Making (FMDAM) can beapplied. In this study, Unified Modeling Language (UML) in FMADM with TOPSISand Weighted Product (WP) methods is applied to select the candidates foracademic and non-academic scholarships at Universitas Islam Negeri SunanKalijaga. Data used were a crisp and fuzzy data. The results show that TOPSISand Weighted Product FMADM methods can be used to select the most suitablecandidates to receive the scholarships since the preference values applied inthis method can show applicants with the highest eligibility","A Fuzzy Topsis Multiple-Attribute Decision Making for Scholarship
  Selection",Fuzzy Multiple Attribute Decision Making in FMADM with TOPSIS and Weighted,0.47619047619047616,0.4063798282013443,0
  The design of a magnetic field source that can switch from a high field to alow field configuration by rotation by $90^\circ$ of a set of iron pieces isinvestigated using topology optimization. A Halbach cylinder is considered asthe magnetic field source and iron inserts are placed in the air gap of theHalbach cylinder. The ideal shape of these iron inserts is determined asfunction of the field generated by the Halbach cylinder and as function of thesize of the iron segments. The topology optimized structures are parabolicshaped pieces and have a difference in flux density between the high and lowpositions that is on average 1.29 times higher than optimized regular polepieces. The maximum increase is a factor of 2.08 times higher than the regularpole pieces.,A topology optimized switchable permanent magnet system,"Topology optimized iron insert structures for a magnetic field source
  switching",0.33333333333333326,0.5491004867761125,0
"  Motivated by a recent conjecture concerning the expressiveness of declarativenetworking, we propose a formal computation model for ""eventually consistent""distributed querying, based on relational transducers. A tight link has beenconjectured between coordination-freeness of computations, and monotonicity ofthe queries expressed by such computations. Indeed, we propose a formaldefinition of coordination-freeness and confirm that the class of monotonequeries is captured by coordination-free transducer networks.Coordination-freeness is a semantic property, but the syntactic class that wedefine of ""oblivious"" transducers also captures the same class of monotonequeries. Transducer networks that are not coordination-free are much morepowerful.",Relational transducers for declarative networking,"Constraining the monotonequeries of distributed querying via
  relational transducers",0.2857142857142857,0.5773502691896257,0
"  The pygmy dipole resonances (PDR) for even-even nuclei in 8=<Z=<40 arestudied performing a systematic calculation of the random-phase approximationwith the Skyrme functional of SkM*. The calculation is fully self-consistentand does not assume any symmetry in the nuclear shape of the ground state. Inevery isotopic chain, the PDR emerges by showing a peak of the E1 strength atenergies less than 10 MeV. The E1 strength of the PDR strongly depends on theposition of the Fermi level and shows a clear correlation with the occupationof the orbits with the orbital angular momenta less than 3\hbar (l =< 2). Wealso found a strong correlation between the isotopic dependence of the neutronskin thickness and the pygmy dipole strength. The fraction of the energyweighted strength exhausted by the PDR and the neutron skin thickness show alinear correlation with the universal rate of about 0.2/fm.",Emergence of pygmy dipole resonances: Magic numbers and neutron skins,Pygmy dipole resonances in 8=<Z=<40,0.3529411764705882,0.24601580968354606,0
"  This paper addresses the problem of motion synchronization (or averaging) anddescribes a simple, closed-form solution based on a spectral decomposition,which does not consider rotation and translation separately but works straightin SE(3), the manifold of rigid motions. Besides its theoretical interest,being the first closed form solution in SE(3), experimental results show thatit compares favourably with the state of the art both in terms of precision andspeed.",Spectral Motion Synchronization in SE(3),A simple closed form solution for motion synchronization,0.28571428571428575,0.0,0
"  We briefly discuss the notion of the Lagrange multiplier for a linearconstraint in the Hilbert space setting, and we prove that the pressure $p$appearing in the stationary Stokes equations is the Lagrange multiplier of theconstraint $\mathrm{div}\, u =0$.",The Lagrange multiplier and the stationary Stokes equations,The Lagrange multiplier for a linear constraint in the Hilbert space setting,0.4,0.2790159393585827,0
"  A bar-and-joint framework is a finite set of points together with specifieddistances between selected pairs. In rigidity theory we seek to understand whenthe remaining pairwise distances are also fixed. If there exists a pair ofpoints which move relative to one another while maintaining the given distanceconstraints, the framework is flexible; otherwise, it is rigid.  Counting conditions due to Maxwell give a necessary combinatorial criterionfor generic minimal bar-and-joint rigidity in all dimensions. Laman showed thatthese conditions are also sufficient for frameworks in R^2. However, theflexible ""double banana"" shows that Maxwell's conditions are not sufficient toguarantee rigidity in R^3. We present a generalization of the double banana toa family of hyperbananas. In dimensions 3 and higher, these are(infinitesimally) flexible, providing counterexamples to the naturalgeneralization of Laman's theorem.",Hyperbanana Graphs,Flexible bar-and-joint frameworks,0.0,0.0,0
"  In this paper we recall a simple formulation of the stationary electrovacuumtheory in terms of the famous complex Ernst potentials, a pair of functionswhich allows one to generate new exact solutions from known ones by means ofthe so-called nonlinear hidden symmetries of Lie-Backlund type. This formalismturned out to be very useful to perform a complete classification of all 4Dsolutions which present two spacetime symmetries or possess two Killingvectors. Curiously enough, the Ernst formalism can be extended and applied tostationary General Relativity as well as the effective heterotic string theoryreduced down to three spatial dimensions by means of a (real) matrixgeneralization of the Ernst potentials. Thus, in this theory one can also makeuse of nonlinear matrix hidden symmetries in order to generate new exactsolutions from seed ones. Due to the explicit independence of the matrix Ernstpotential formalism of the original theory (prior to dimensional reduction) onthe dimension D, in the case when the theory initially has D>=5, one cangenerate new solutions like charged black holes, black rings and black Saturns,among others, starting from uncharged field configurations.","Nonlinear hidden symmetries in General Relativity and String Theory: a
  matrix generalization of the Ernst potentials",On the complex Ernst potentials of the stationary electrovacuum theory,0.23076923076923075,0.2996644194795595,0
"  Primordial stars formed in the early universe are thought to be hosted bycompact dark matter (DM) halos. If DM consists of Weakly Interacting MassiveParticles (WIMPs), such stars may be powered by DM annihilation during theearly phases of their evolutions. We study the pre-main sequence evolutions ofthe primordial star using a detailed stellar evolution code under theassumption that the annihilation of adiabatically contracted WIMPs DM withinthe star provides a sufficient energy to sustain the stellar equilibrium. Wefollow the evolution of accreting stars using several gas mass accretion ratesderived from cosmological simulations. We show that the stellar mass becomesvery large, up to 900 - 1000 M_sun when the star reaches the main-sequencephase for a reasonable set of model parameters such as DM particle mass and theannihilation cross section. During the dark star phase, the star expands over athousand solar-radii, while the surface temperature remains below 10^4 K. Theenergy generated by nuclear reactions is not dominant during this phase. Wealso study models with different gas mass accretion rates and the DM particlemasses. All our models for different DM particle masses pass the dark starphase. The final mass of the dark stars is essentially unchanged for DM mass ofm_DM <= 10 GeV. Gravitational collapse of the massive dark stars will leavemassive black holes with mass as large as 1000 M_sun in the early universe.","Evolution of Primordial Stars Powered by Dark Matter Annihilation up to
  the Main-Sequence Stage",Cosmological simulations of the early universe with compact dark matter,0.24,0.4482700320176827,0
"  We construct bi-local interpolating field operators for baryons consisting ofthree quarks with two flavors, assuming good isospin symmetry. We use therestrictions following from the Pauli principle to derive relations/identitiesamong the baryon operators with identical quantum numbers. Such relations thatfollow from the combined spatial, Dirac, color, and isospin Fierztransformations may be called the (total/complete) Fierz identities. Theserelations reduce the number of independent baryon operators with any given spinand isospin. We also study the Abelian and non-Abelian chiral transformationproperties of these fields and place them into baryon chiral multiplets. Thuswe derive the independent baryon interpolating fields with given values of spin(Lorentz group representation), chiral symmetry ($U_L(2) \times U_R(2)$ grouprepresentation) and isospin appropriate for the first angular excited states ofthe nucleon.",Bi-local baryon interpolating fields with two flavours,Bi-local interpolating fields for baryons with two flavors,0.7058823529411765,0.6500593260343691,0
"  We study a continuous dynamics for a class of Petri nets which allows therouting at non-free choice places to be determined by priorities rules. We showthat this dynamics can be written in terms of policies which identify thebottleneck places. We characterize the stationary solutions, and show that theycoincide with the stationary solutions of the discrete dynamics of this classof Petri nets. We provide numerical experiments on a case study of an emergencycall center, indicating that pathologies of discrete models (oscillationsaround a limit different from the stationary limit) vanish by passing tocontinuous Petri nets.","Stationary solutions of discrete and continuous Petri nets with
  priorities",Continuous Petri nets with priorities rules,0.625,0.2608840516436559,0
"  Multi Layer Capacitors MLCs are considered as the most promising refrigerantelements to design and develop electrocaloric cooling devices. Recently, theheat transfer of these MLCs has been considered. However, the heat exchangewith the surrounding environment has been poorly, if not, addressed. In thiswork, we measure by infrared thermography the temperature change versus time infour different heat exchange configurations. Depending on the configurations,Newtonian and non-Newtonian regimes with their corresponding Biot number aredetermined allowing to provide useful thermal characteristics. Indeed, in caseof large area thermal pad contacts, heat transfer coefficients up to 3400 W m-2K-1 are obtained showing that the standard MLCs already reach the needs fordesigning efficient prototypes. We also determine the ideal Brayton coolingpower in case of thick wires contact which varies between 3.4 mW and 9.8 mW foroperating frequencies varying from 0.25 Hz to 1 Hz. While only heat conductionis considered here, our work provides some design rules for improving heatexchanges in future devices.",Large heat flux in electrocaloric multilayer capacitors,Thermal Properties of Multi Layer Capacitors MLCs,0.14285714285714285,0.0,0
"  We propose a method to construct the stochastic integral simultaneously undera non-dominated family of probability measures. Path-by-path, and withoutreferring to a probability measure, we construct a sequence ofLebesgue-Stieltjes integrals whose medial limit coincides with the usualstochastic integral under essentially any probability measure such that theintegrator is a semimartingale. This method applies to any predictableintegrand.",Pathwise Construction of Stochastic Integrals,Stochastic Integrals under Non-Dominated Probability Measures,0.3333333333333333,0.5081327481546147,0
"  The highway vehicular ad hoc networks, where vehicles are wirelesslyinter-connected, rely on the multi-hop transmissions for end-to-endcommunications. This, however, is severely challenged by the unreliablewireless connections, signal attenuation and channel contentions in the dynamicvehicular environment. To overcome the network dynamics, selecting appropriaterelays for end-to-end connections is important. Different from the previousefforts (\emph{e.g.}, clustering and cooperative downloading), this paperexplores the existence of stable vehicles and propose building a stablemulti-hop transmission backbone network in the highway vehicular ad hocnetwork. Our work is composed of three parts. Firstly, by analyzing thereal-world vehicle traffic traces, we observe that the large-size vehicles,\emph{e.g.}, trucks, are typically stable with low variations of mobility andstable channel condition of low signal attenuation; this makes theirinter-connections stable in both connection time and transmission rate.Secondly, by exploring the stable vehicles, we propose a distributed protocolto build a multi-hop backbone link for end-to-end transmissions, accordinglyforming a two-tier network architecture in highway vehicular ad hoc networks.Lastly, to show the resulting data performance, we develop a queueing analysismodel to evaluate the end-to-end transmission delay and throughput.  Using extensive simulations, we show that the proposed transmission backbonecan significantly improve the reliability of multi-hop data transmissions withhigher throughput, less transmission interruptions and end-to-end delay.","Building Transmission Backbone for Highway Vehicular Networks: Framework
  and Analysis",Stable Transmission Bands in the HVAC Network,0.23529411764705882,0.4004970149398301,0
"  We build on a recent paper by Grinstein, Redi and Villadoro, where a see-sawlike mechanism for quark masses was derived in the context of spontaneouslybroken gauged flavour symmetries. The see-saw mechanism is induced by heavyDirac fermions which are added to the Standard Model spectrum in order torender the flavour symmetries anomaly-free. In this letter we report on theembedding of these fermions into multiplets of an SU(5) grand unified theoryand discuss a number of interesting consequences.",See-Saw Masses for Quarks and Leptons in SU(5),A note on the embedding of heavy Dirac fermions into SU(5) grand,0.17391304347826086,0.537284965911771,0
"  Measurements of luminosity obtained using the ATLAS detector during earlyrunning of the Large Hadron Collider (LHC) at sqrt(s) = 7 TeV are presented.The luminosity is independently determined using several detectors and multiplealgorithms, each having different acceptances, systematic uncertainties andsensitivity to background. The ratios of the luminosities obtained from thesemethods are monitored as a function of time and of mu, the average number ofinelastic interactions per bunch crossing. Residual time- and mu-dependencebetween the methods is less than 2% for 0<mu<2.5. Absolute luminositycalibrations, performed using beam separation scans, have a common systematicuncertainty of +/-11, dominated by the measurement of the LHC beam currents.After calibration, the luminosities obtained from the different methods differby at most +/-2%. The visible cross sections measured using the beam scans arecompared to predictions obtained with the PYTHIA and PHOJET event generatorsand the ATLAS detector simulation.","Luminosity Determination in pp Collisions at sqrt(s)=7 TeV Using the
  ATLAS Detector at the LHC","Measurements of Luminosity Using the ATLAS Detector during Early
  Run at sqrt",0.41379310344827586,0.18272496802322832,0
"  Recently, virtual reality, augmented reality, robotics, autonomous driving etal attract much attention of both academic and industrial community, in whichimage based camera localization is a key task. However, there has not been acomplete review on image-based camera localization. It is urgent to map thistopic to help people enter the field quickly. In this paper, an overview ofimage based camera localization is presented. A new and complete kind ofclassifications for image based camera localization is provided and the relatedtechniques are introduced. Trends for the future development are alsodiscussed. It will be useful to not only researchers but also engineers andother people interested.",Image Based Camera Localization: an Overview,Image Based Camera Localization,0.8,0.42888194248035344,0
"  We report on an orbital-angular-momentum-enhanced scheme for angulardisplacement estimation based on two-mode squeezed vacuum and parity detection.The sub-Heisenberg-limited sensitivity for angular displacement estimation isobtained in an ideal situation. Several realistic factors are also considered,including photon loss, dark counts, response-time delay, and thermal photonnoise. Our results indicate that the effects of the realistic factors on thesensitivity can be offset by raising orbital angular momentum quantum number$\ell$. This reflects that the robustness and the practicability of the systemcan be improved via raising $\ell$ without changing mean photon number $N$.","Orbital-angular-momentum-enhanced estimation of sub-Heisenberg-limited
  angular displacement with two-mode squeezed vacuum and parity detection",Orbital-angular-momentum-enhanced angulard displacement estimation,0.3846153846153846,0.09808503052286431,0
"  Object proposals are an ensemble of bounding boxes with high potential tocontain objects. In order to determine a small set of proposals with a highrecall, a common scheme is extracting multiple features followed by a rankingalgorithm which however, incurs two major challenges: {\bf 1)} The rankingmodel often imposes pairwise constraints between each proposal, rendering theproblem away from an efficient training/testing phase; {\bf 2)} Linear kernelsare utilized due to the computational and memory bottleneck of training akernelized model.  In this paper, we remedy these two issues by suggesting a {\em kernelizedpartial ranking model}. In particular, we demonstrate that {\bf i)} our partialranking model reduces the number of constraints from $O(n^2)$ to $O(nk)$ where$n$ is the number of all potential proposals for an image but we are onlyinterested in top-$k$ of them that has the largest overlap with the groundtruth; {\bf ii)} we permit non-linear kernels in our model which is oftensuperior to the linear classifier in terms of accuracy. For the sake ofmitigating the computational and memory issues, we introduce a consistentweighted sampling~(CWS) paradigm that approximates the non-linear kernel aswell as facilitates an efficient learning. In fact, as we will show, training alinear CWS model amounts to learning a kernelized model. Extensive experimentsdemonstrate that equipped with the non-linear kernel and the partial rankingalgorithm, recall at top-$k$ proposals can be substantially improved.",Object Proposal with Kernelized Partial Ranking,A Kernelized Partial Ranking Model for Object Proposals,0.42857142857142855,0.392814650900513,0
"  We investigate the light-front zero-mode contribution to the weak transitionform factors between pseudoscalar and vector mesons using a covariant fermionfield theory model in $(3+1)$ dimensions. In particular, we discuss the formfactors $a_-(q^2)$ and $f(q^2)$ which have been suspected to have the zero-modecontribution in the $q^+=0$ frame. While the zero-mode contribution inprinciple depends on the form of the vector meson vertex $\Gamma^\mu=\gamma^\mu- (2k-P_V)^\mu/D$, the form factor $f(q^2)$ is found to be free from the zeromode if the denominator $D$ contains the term proportional to the light-frontlongitudinal momentum fraction factor $(1/x)^n$ of the struck quark with thepower $n>0$. Although the form factor $a_-(q^2)$ is not free from the zeromode, the zero-mode contribution comes only either from the simple vertex$\Gamma^\mu=\gamma^\mu$ term or from the other term just with a constant $D$(i.e. $n=0$), but not with the momentum-dependent denominator (i.e. $D\sim(1/x)^n$ with $n>0$). We identify the zero-mode contribution to $a_-(q^2)$ andincorporate it as a convolution of the zero-mode operator with the initial andfinal state light-front wave functions. The covariance (i.e. frameindependence) of our model has been checked by performing the light-frontcalculations both in the $q^+=0$ and $q^+\neq 0$ frames. We present ournumerical result for the $B\to\rho$ transition for an explicit demonstration ofour findings.","Light-front dynamic analysis of transition form factors in the process
  of $P\to V\ell\nu_{\ell}$","Light-front zero-mode contribution to the weak transition form factors
  in $(3+",0.3870967741935484,0.21648693746244407,0
"  We present Nopol, an approach for automatically repairing buggy if conditionsand missing preconditions. As input, it takes a program and a test suite whichcontains passing test cases modeling the expected behavior of the program andat least one failing test case embodying the bug to be repaired. It consists ofcollecting data from multiple instrumented test suite executions, transformingthis data into a Satisfiability Modulo Theory (SMT) problem, and translatingthe SMT result -- if there exists one -- into a source code patch. Nopolrepairs object oriented code and allows the patches to contain nullness checksas well as specific method calls.","Automatic Repair of Buggy If Conditions and Missing Preconditions with
  SMT",Nopol: Automated Repair of Buggy Programs,0.3529411764705882,0.20550880449169096,0
"  Many existing data mining algorithms use feature values directly in theirmodel, making them sensitive to units/scales used to measure/represent data.Pre-processing of data based on rank transformation has been suggested as apotential solution to overcome this issue. However, the resulting data afterpre-processing with rank transformation is uniformly distributed, which may notbe very useful in many data mining applications. In this paper, we present abetter and effective alternative based on ranks over multiple sub-samples ofdata. We call the proposed pre-processing technique as ARES | Average Rank overan Ensemble of Sub-samples. Our empirical results of widely used data miningalgorithms for classification and anomaly detection in a wide range of datasets suggest that ARES results in more consistent task specific? outcome acrossvarious algorithms and data sets. In addition to this, it results in better orcompetitive outcome most of the time compared to the most widely used min-maxnormalisation and the traditional rank transformation.","A Novel Data Pre-processing Technique: Making Data Mining Robust to
  Different Units and Scales of Measurement",A New Approach for Data Mining Based on Rank Transformation,0.22222222222222224,0.2345000810620359,0
"  The study of nonmodal amplification of distributed body forces in channelflows of viscoelastic fluids has provided useful insights into the mechanismsthat may govern the initial stages of transition to elastic turbulence.However, distributed body forces are not easy to implement in experiments andso there is a need to examine amplification of localized body forces. In thiswork, we use the linearized governing equations to examine such amplificationin Poiseuille flow of FENE-CR fluids. We first identify the wall-normallocation at which the impulsive excitations experience the largestamplification and then analyze the kinetic energy of the fluctuations and theresulting flow structures. For both a Newtonian fluid at high Reynolds numbersand a viscoelastic fluid at low Reynolds numbers, the largest amplificationoccurs for disturbances that are located near the channel wall. Our analysis ofthe energy evolution shows that a localized body force in the spanwisedirection has the largest impact and that the streamwise velocity component ismost affected. For viscoelastic fluids we observe the development of vorticalstructures away from the source of impulsive excitation. This feature is lessprominent in Newtonian fluids and it may provide a mechanism for triggering theinitial stages of transition to elastic turbulence.","Amplification of localized body forces in channel flows of viscoelastic
  fluids","Nonmodal Amplification of Distributed Body Forces in Poiseuille Flow of
 ",0.6666666666666666,0.41545589177443254,0
"  Research has been devoted in the past few years to relevance feedback as aneffective solution to improve performance of information retrieval systems.Relevance feedback refers to an interactive process that helps to improve theretrieval performance. In this paper we propose the use of relevance feedbackto improve document image retrieval System (DIRS) performance. This papercompares a variety of strategies for positive and negative feedback. Inaddition, feature subspace is extracted and updated during the feedback processusing a Principal Component Analysis (PCA) technique and based on user'sfeedback. That is, in addition to reducing the dimensionality of featurespaces, a proper subspace for each type of features is obtained in the feedbackprocess to further improve the retrieval accuracy. Experiments show that usingrelevance Feedback in DIR achieves better performance than common DIR.",PCA-Based Relevance Feedback in Document Image Retrieval,Relevance Feedback for Document Image Retrieval System,0.6666666666666666,0.5169731539571706,0
"  Several tensor eigenpair definitions have been put forth in the past decade,but these can all be unified under generalized tensor eigenpair framework,introduced by Chang, Pearson, and Zhang (2009). Given mth-order, n-dimensionalreal-valued symmetric tensors A and B, the goal is to find $\lambda \in R$ and$x \in R^n$, $x \neq 0$, such that $Ax^{m-1} = \lambda Bx^{m-1}$. Differentchoices for B yield different versions of the tensor eigenvalue problem. Wepresent our generalized eigenproblem adaptive power method (GEAP) method forsolving the problem, which is an extension of the shifted symmetrichigher-order power method (SS-HOPM) for finding Z-eigenpairs. A major drawbackof SS-HOPM was that its performance depended in choosing an appropriate shift,but our GEAP method also includes an adaptive method for choosing the shiftautomatically.","An Adaptive Shifted Power Method for Computing Generalized Tensor
  Eigenpairs","Generalized tensor eigenpair framework for solving the
  shifted symmetrichigher",0.3157894736842105,0.6143868746168435,0
"  Outcome-driven studies designed to evaluate potential effects of games andapps designed to promote healthy eating and exercising remain limited eithertargeting design or usability factors while omitting out health-based outcomesaltogether, or tend to be too narrowly focuses on behavioral outcomes within ashort periods of time thereby less likely to influence longitudinal factorsthat can help sustain healthy habits. In this paper we argue for a unifiedapproach to tackle behavioral change through focusing on both health outcomesand cognitive precursors, such as players' attitudes and behaviors aroundhealthy eating and exercising, motivation stage and knowledge and awarenessabout nutrition or physical activity. Key findings from a 3-month long gameplay study, with 47 female participants indicate that there are clear shifts inplayers' perceptions about health and knowledge about eating. This paperextends our current understandings about approaches for evaluating health gamesand presents a unified approach to assess effectiveness of game-based healthinterventions through combining health-based outcomes and shifts in players'cognitive precursors.","Investigating behavior change indicators and cognitive measures in
  persuasive health games",A Unified Approach to Evaluating Behavioral Change in Health Games,0.47619047619047616,0.5088274727401554,0
"  Customer slowdown describes the phenomenon that a customer's servicerequirement increases with experienced delay. In healthcare settings, there issubstantial empirical evidence for slowdown, particularly when a patient'sdelay exceeds a certain threshold. For such threshold slowdown situations, wedesign and analyze a many-server system that leads to a two-dimensional Markovprocess. Analysis of this system leads to insights into the potentiallydetrimental effects of slowdown, especially in heavy-traffic conditions. Wequantify the consequences of underprovisioning due to neglecting slowdown,demonstrate the presence of a subtle bistable system behavior, and discuss indetail the snowball effect: A delayed customer has an increased servicerequirement, causing longer delays for other customers, who in turn due toslowdown might require longer service times.",The snowball effect of customer slowdown in critical many-server systems,A Few-Server System for Customer Slowdown,0.2222222222222222,0.0,0
"  In this paper, we generalize the Kirchhoff-Sobolev parametrix of Klainermanand Rodnianski to systems of tensor wave equations with additional first-orderterms. We also present a different derivation, which better highlights thatsuch representation formulas are supported entirely on past null cones. Thisgeneralization is a key component for extending Klainerman and Rodnianski'sbreakdown criterion result for Einstein-vacuum spacetimes to Einstein-Maxwelland Einstein-Yang-Mills spacetimes.","A Generalized Representation Formula for Systems of Tensor Wave
  Equations",Kirchhoff-Sobolev parametrization for tensor wave equations with,0.4444444444444445,0.4004970149398301,0
"  The geometric flow theory and its applications turned into one of the mostintensively developing branches of modern geometry. Here, a brief introductionto Finslerian Ricci flow and their self-similar solutions known as Riccisolitons are given and some recent results are presented. They are ageneralization of Einstein metrics and are previously developed by the presentauthors for Finsler manifolds. In the present work, it is shown that a completeshrinking Ricci soliton Finsler manifold has a finite fundamental group.",Complete Ricci solitons on Finsler manifolds,Finslerian Ricci flow and their self-similar solutions,0.14285714285714288,0.6147881529512643,0
"  The concentration of measure phenomena were discovered as the mathematicalbackground of statistical mechanics at the end of the XIX - beginning of the XXcentury and were then explored in mathematics of the XX-XXI centuries. At thebeginning of the XXI century, it became clear that the proper utilisation ofthese phenomena in machine learning might transform the curse of dimensionalityinto the blessing of dimensionality.  This paper summarises recently discovered phenomena of measure concentrationwhich drastically simplify some machine learning problems in high dimension,and allow us to correct legacy artificial intelligence systems. The classicalconcentration of measure theorems state that i.i.d. random points areconcentrated in a thin layer near a surface (a sphere or equators of a sphere,an average or median level set of energy or another Lipschitz function, etc.).  The new stochastic separation theorems describe the thin structure of thesethin layers: the random points are not only concentrated in a thin layer butare all linearly separable from the rest of the set, even for exponentiallylarge random sets. The linear functionals for separation of points can beselected in the form of the linear Fisher's discriminant.  All artificial intelligence systems make errors. Non-destructive correctionrequires separation of the situations (samples) with errors from the samplescorresponding to correct behaviour by a simple and robust classifier. Thestochastic separation theorems provide us by such classifiers and anon-iterative (one-shot) procedure for learning.","Blessing of dimensionality: mathematical foundations of the statistical
  physics of data",Stochastic separation of measure phenomena in machine learning,0.10526315789473685,0.40866465020165643,0
  A form of the Laplace transform is reviewed as a paradigm for an entire classof fractional functional transforms. Various of its properties are discussed.Such transformations should be useful in application to differential/integralequations or problems in non-extensive statistical mechanics.,Fractional Laplace Transforms - A Perspective,Laplace Transform: A Paradigm for Fractional Functional Transformations,0.4615384615384615,0.7825422900366437,0
  We study a functorial construction from the category of monoids to thecategory of set-operads and we give some combinatorial examples ofapplications.,"Construction d'op\'erades ensemblistes \`a partir de mono\""ides",Functorial construction of set-operads,0.13333333333333333,0.0,0
"  We completely characterize the boundedness on $L^p$ spaces and on Wieneramalgam spaces of the short-time Fourier transform (STFT) and of a specialclass of pseudodifferential operators, called localization operators.Precisely, a well-known STFT boundedness result on $L^p$ spaces is proved to besharp. Then, sufficient conditions for the STFT to be bounded on the Wieneramalgam spaces $W(L^p,L^q)$ are given and their sharpness is shown.Localization operators are treated similarly. Using different techniques fromthose employed in the literature, we relax the known sufficient boundednessconditions for localization operators on $L^p$ spaces and prove the optimalityof our results. More generally, we prove sufficient and necessary conditionsfor such operators to be bounded on Wiener amalgam spaces.","Sharp Continuity Results for the Short-Time Fourier Transform and for
  Localization Operators",Boundedness of localization operators on Wieneramalgam spaces,0.2,0.0,0
  We study the self-normalized sums of independent random variables from theperspective of the Malliavin calculus. We give the chaotic expansion for themand we prove a Berry-Ess\'een bound with respect to several distances.,Malliavin Calculus and Self Normalized Sums,"Self-normalized sums of independent random variables from the
  Malliavin calculus",0.3529411764705882,0.5623413251903491,0
"  The microscopic approach was developed for obtaining of the free energy of asuperconductor with help direct calculation of the vacuum amplitude. Thefunctional of free energy of the spatially inhomogeneous superconductor in amagnetic field was obtained with help the developed approach. The obtainedfunctional is generalization of Ginzburg-Landau functionals for anytemperature, for arbitrary spatial variations of the order parameter and forthe nonlocality of the order parameter and the magnetic response. Moreover thenonlocality of the magnetic response is the consequence of the orderparameter's nonlocality. The extremals of this functional are considered in theexplicit form in the low-temperature limit and in the high-temperature limit atthe condition of slowness of spatial variations of the order parameter.",Nonlocal free energy of a spatially inhomogeneous superconductor,"Microscopic approach for the free energy of superconductor in amagnetic
  field",0.4210526315789474,0.2998221389342337,0
"  One of the key goals of exoplanet science is the atmospheric characterisationof super-Earths. Atmospheric abundances provide insight on the formation andevolution of those planets and help to put our own rocky planets in context.Observations on 55 Cancri e point towards a N-dominated atmosphere. In thispaper we explore this possibility, showing which will be the most abundantgases and observable species in emission and transmission spectroscopy of suchan atmosphere. We use analytical arguments and observed parameters to estimatethe possible thermal profile of the atmosphere and test three different extremepossibilities. The chemistry is calculated using equilibrium calculations andadopting Titan's elemental abundances as a potential N-dominated atmosphericcomposition. We also test the effect of different N/O ratios in the atmosphere.Emission and transmission spectra are computed and showed with a resolutionrelevant to future missions suitable to observe super-Earths (e.g. JWST,ARIEL). We find that even though N$_2$ is the most abundant molecule in theatmosphere followed by H$_2$ and CO, the transmission spectra shows strongfeatures of NH3 and HCN, and CO and HCN dominate emission spectra. We also showthat a decrease in the N/O ratio leads to stronger H2O, CO and CO2 and weakerNH3 and HCN features. A larger N/O is also more consistent with observations.Our exploration of a N-atmosphere for 55 Cancri e serve as a guide tounderstand such atmospheres and provide a reference for future observations.","Observability of molecular species in a nitrogen dominated atmosphere
  for 55 Cancri e",The N-dominated Atmosphere of 55 Cancri e,0.4761904761904762,0.1874844529888581,0
"  We construct Eberlein almost periodic functions $ f_j : J \to H$ so that  $||f_1(\cdot)||$ is not ergodic and thus not Eberlein almost periodic and$||f_2(.)||$ is Eberlein almost periodic, but $f_1$ and $f_2$ are not pseudoalmost periodic, the Parseval equation for them fails, where $J=\r_+$ or $\r$and $H$ is a Hilbert space. This answers several questions posed by Zhang andLiu [18].",Eberlein almost periodic functions that are not pseudo almost periodic,Almost periodic functions,0.4615384615384615,0.07368276169123442,0
"  This paper takes a comprehensive view on the protocol stacks that are underdebate for a future Internet of Things (IoT). It addresses the holisticquestion of which solution is beneficial for common IoT use cases. We deployNDN and the two popular IP-based application protocols, CoAP and MQTT, in itsdifferent variants on a large-scale IoT testbed in single- and multi-hopscenarios. We analyze the use cases of scheduled periodic and unscheduledtraffic under varying loads. Our findings indicate that (a) NDN admits the mostresource-friendly deployment on nodes, and (b) shows superior robustness andresilience in multi-hop scenarios, while (c) the IP protocols operate at lessoverhead and higher speed in single-hop deployments. Most strikingly we findthat NDN-based protocols are in significantly better flow balance than theUDP-based IP protocols and require less corrective actions.","NDN, CoAP, and MQTT: A Comparative Measurement Study in the IoT",NDA: A Comprehensive Survey of Protocol Stacks for the Internet of Things,0.17391304347826086,0.6389431042462724,0
"  A bar-and-joint framework is a finite set of points together with specifieddistances between selected pairs. In rigidity theory we seek to understand whenthe remaining pairwise distances are also fixed. If there exists a pair ofpoints which move relative to one another while maintaining the given distanceconstraints, the framework is flexible; otherwise, it is rigid.  Counting conditions due to Maxwell give a necessary combinatorial criterionfor generic minimal bar-and-joint rigidity in all dimensions. Laman showed thatthese conditions are also sufficient for frameworks in R^2. However, theflexible ""double banana"" shows that Maxwell's conditions are not sufficient toguarantee rigidity in R^3. We present a generalization of the double banana toa family of hyperbananas. In dimensions 3 and higher, these are(infinitesimally) flexible, providing counterexamples to the naturalgeneralization of Laman's theorem.",Hyperbanana Graphs,Flexible bar-and-joint frameworks,0.0,0.0,0
"  The supervisory control theory of fuzzy discrete event systems (FDESs) forfuzzy language equivalence has been developed. However, in a way, languageequivalence has limited expressiveness. So if the given specification can notbe expressed by language equivalence, then the control for language equivalencedoes not work. In this paper, we further establish the supervisory controltheory of FDESs for fuzzy simulation equivalence whose expressiveness isstronger than that of fuzzy language equivalence. First, we formalize thenotions of fuzzy simulation and fuzzy simulation equivalence between two FDESs.Then we present a method for deciding whether there is a fuzzy simulation ornot. In addition, we also show several basic properties of fuzzy simulationrelations. Afterwards, we put forward the notion of fuzzy simulation-basedcontrollability, and particularly show that it serves as a necessary andsufficient condition for the existence of the fuzzy supervisors of FDESs.Moreover, we study the ""range"" control problem of FDESs. Some examples aregiven to illustrate the main results obtained.","Supervisory Control of Fuzzy Discrete Event Systems for Simulation
  Equivalence","Supervisory Control Theory of Fuzzy Discrete Event Systems for
  Language Equivalence",0.8571428571428572,0.5348259312838877,0
"  The polytropic gas model is investigated as an interacting dark energyscenario. The cosmological implications of the model including the evolution ofEoS parameter $w_{\Lambda}$, energy density $\Omega_{\Lambda}$ and decelerationparameter $q$ are investigated. We show that, depending on the parameter ofmodel, the interacting polytropic gas can behave as a quintessence or phantomdark energy. In this model, the phantom divide is crossed from below to up. Theevolution of $q$ in the context of polytropic gas dark energy model representsthe decelerated phase at the early time and accelerated phase later. Thesingularity of this model is also discussed. Eventually, we establish thecorrespondence between interacting polytropic gas model with tachyon, K-essenceand dilaton scalar fields. The potential and the dynamics of these scalar fieldmodels are reconstructed according to the evolution of interacting polytropicgas.","Cosmological implications of interacting polytropic gas dark energy
  model in non-flat universe",Quintessence and phantom dark energy in interacting polytropic gas model,0.34782608695652173,0.3383473685716838,0
"  In this article, we state and prove a general criterion allowing us to showthat some groups are hyperbolically elementary, meaning that every isometricaction of one of these groups on a Gromov-hyperbolic space either fixes a pointat infinity or has bounded orbits. Also, we show how such a hyperbolic rigidityleads to fixed-point properties on finite-dimensional CAT(0) cube complexes. Asan application, we prove that Thompson's group $V$ is hyperbolicallyelementary, and we deduce that it satisfies Property $(FW_{\infty})$, ie.,every isometric action of $V$ on a finite-dimensional CAT(0) cube complex fixesa point. It provides the first example of a (finitely presented) group actingproperly on an infinite-dimensional CAT(0) cube complex such that all itsactions on finite-dimensional CAT(0) cube complexes have global fixed points.",Hyperbolic and cubical rigidities of Thompson's group V,On the hyperbolicity of groups acting on finite-dimensional CAT(0) cube complexes,0.27272727272727276,0.5491004867761125,0
"  We introduce a few-shot learning framework for error detection. We show thatdata augmentation (a form of weak supervision) is key to training high-quality,ML-based error detection models that require minimal human involvement. Ourframework consists of two parts: (1) an expressive model to learn richrepresentations that capture the inherent syntactic and semantic heterogeneityof errors; and (2) a data augmentation model that, given a small seed of cleanrecords, uses dataset-specific transformations to automatically generateadditional training data. Our key insight is to learn data augmentationpolicies from the noisy input dataset in a weakly supervised manner. We showthat our framework detects errors with an average precision of ~94% and anaverage recall of ~93% across a diverse array of datasets that exhibitdifferent types and amounts of errors. We compare our approach to acomprehensive collection of error detection methods, ranging from traditionalrule-based methods to ensemble-based and active learning approaches. We showthat data augmentation yields an average improvement of 20 F1 points while itrequires access to 3x fewer labeled examples compared to other ML approaches.",HoloDetect: Few-Shot Learning for Error Detection,A Few-Shot Learning Framework for Error Detection,0.7999999999999999,0.5169731539571706,0
"  We discuss how mathematical semantics has evolved, and suggest some newdirections for future work. As an example, we discuss some recent work onencapsulating model comparison games as comonads, in the context of finitemodel theory.",Whither Semantics?,Mathematical semantics and comonads,0.3333333333333333,0.0,0
"  Sufficient data presence is one of the key preconditions for applying metricsin practice. Based on both Altmetric.com data and Mendeley data collected up to2019, this paper presents a state-of-the-art analysis of the presence of 12kinds of altmetric events for nearly 12.3 million Web of Science publicationspublished between 2012 and 2018. Results show that even though an upward trendof data presence can be observed over time, except for Mendeley readers andTwitter mentions, the overall presence of most altmetric data is still low. Themajority of altmetric events go to publications in the fields of Biomedical andHealth Sciences, Social Sciences and Humanities, and Life and Earth Sciences.As to research topics, the level of attention received by research topicsvaries across altmetric data, and specific altmetric data show differentpreferences for research topics, on the basis of which a framework foridentifying hot research topics is proposed and applied to detect researchtopics with higher levels of attention garnered on certain altmetric datasource. Twitter mentions and policy document citations were selected as twoexamples to identify hot research topics of interest of Twitter users andpolicy-makers, respectively, shedding light on the potential of altmetric datain monitoring research trends of specific social attention.","An extensive analysis of the presence of altmetric data for Web of
  Science publications across subject fields and research topics",The presence of altmetric events in Web of Science publications,0.5333333333333333,0.13976396370981378,0
"  Fuel moisture has a major influence on the behavior of wildland fires and isan important underlying factor in fire risk assessment. We propose a method toassimilate dead fuel moisture content observations from remote automatedweather stations (RAWS) into a time-lag fuel moisture model. RAWS are spatiallysparse and a mechanism is needed to estimate fuel moisture content at locationspotentially distant from observational stations. This is arranged using a trendsurface model (TSM), which allows us to account for the effects of topographyand atmospheric state on the spatial variability of fuel moisture content. Ateach location of interest, the TSM provides a pseudo-observation, which isassimilated via Kalman filtering. The method is tested with the time-lag fuelmoisture model in the coupled weather-fire code WRF-SFIRE on 10-hr fuelmoisture content observations from Colorado RAWS in 2013. We show usingleave-one-out testing that the TSM compares favorably with inverse squareddistance interpolation as used in the Wildland Fire Assessment System. Finally,we demonstrate that the data assimilation method is able to improve fuelmoisture content estimates in unobserved fuel classes.","Data assimilation of dead fuel moisture observations from remote
  automated weather stations","A Time-Lag Fuel Moisture Model for Wildland Wildland Fire Risk
 ",0.17391304347826086,0.0,0
  The fundamental step in measuring the robustness of a system is the synthesisof the so called Process Map.This is generally based on the user raw datamaterial.Process Maps are of fundamental importance towards the understandingof the nature of a system in that they indicate which variables are causallyrelated and which are particularly important.This paper represent the systemMap or business structure map to understand business criteria studying thevarious aspects of the company.The business structure map or knowledge map orProcess map are used to increase the growth of the company by giving someuseful measures according to the business criteria.This paper also deals withthe different company strategy to reduce the risk factors.Process Map ishelpful for building such knowledge successfully.Making decisions from such mapin a highly complex situation requires more knowledge and resources.,A Mining Method to Create Knowledge Map by Analysing the Data Resource,"A Business Structure Map or Knowledge Map for the Robustness of a
  Company",0.32,0.4001601601922499,0
"  We present microscopic coupled-cluster calculations of the spectroscopicfactors for proton removal from the closed-shell oxygen isotopes$^{14,16,22,24,28}$O with the chiral nucleon-nucleon interaction atnext-to-next-to-next-to-leading order. We include coupling-to-continuum degreesof freedom by using a Hartree-Fock basis built from a Woods-Saxonsingle-particle basis. This basis treats bound and continuum states on an equalfooting. We find a significant quenching of spectroscopic factors in theneutron-rich oxygen isotopes, pointing to enhanced many-body correlationsinduced by strong coupling to the scattering continuum above the neutronemission thresholds.",Quenching of spectroscopic factors for proton removal in oxygen isotopes,Spectroscopic factors in closed-shell oxygen isotopes,0.588235294117647,0.31024517040537297,0
"  In the last two decades, number of Higher Education Institutions (HEI) growsin leaps and bounds. This causes a cut throat competition among theseinstitutions while attracting the student get admission in these institutions.To make reach up to the students institution makes effort of advertisement.Similarly developing and developed both type of institution launch severalservices also to attract students. Most of the institutions are opened in selffinance mode. So all time they feel short hand in expenditure. Now a day anumber of advertisement methods are available. So it is difficult for aninstitution to make advertisement through all modes and launch all services atthe same time due to different constraints. In this paper we use support andconfidence method to find out the best way of advertisement.",Data Mining Application to Attract Students in HEI,"A Survey on the Use of Support and Confidence Method to Make
  Advertisements in Higher",0.1739130434782609,0.6042750794713536,0
"  A historical review of spin- and angle-resolved photoemission on topologicalmaterials is presented, aimed at readers who are new to the field or who wishto obtain an overview of the activities in the field. The main focus lies ontopological insulators, but also Weyl and other semimetals will be discussed.Further it will be explained why the measured spin polarisation from a spinpolarised state should always add up to 100% and how spin interference effectsinfluence the measured spin texture.",Spin- and angle-resolved photoemission on topological materials,Spin- and Angle-Resolved Photoemission on Topological Materials,1.0,0.5169731539571706,0
"  The lightest supersymmetric particle (LSP) is a natural candidate for thecold dark matter of the universe. In this Letter we discuss how to test themechanism responsible for the LSP stability at the LHC. We note that ifR-parity is conserved dynamically one should expect a Higgs boson which decaysmainly into two right-handed neutrinos (a ""leptonic"" Higgs) or into twosfermions. The first case could exhibit spectacular lepton number violatingsignals with four secondary vertices due to the long-lived nature ofright-handed neutrinos. These signals, together with the standard channels forthe discovery of SUSY, could help to establish the underlying theory at the TeVscale.",Testing the Mechanism for the LSP Stability at the LHC,LSP decays at the LHC,0.5333333333333333,0.22230037854975046,0
"  We present branching fraction and CP asymmetry measurements as well asangular studies of B to phi phi K decays using 464 x 10^6 BBbar eventscollected by the BaBar experiment. The branching fractions are measured in thephi phi invariant mass range below the eta_c resonance (m_phiphi <2.85 GeV). Wefind  B(B+ to phi phi K+) = (5.6 +/- 0.5 +/- 0.3) x 10^-6 and  B(B0 to phi phi K0) = (4.5 +/- 0.8 +/- 0.3) x 10^-6, where the firstuncertaintiy is statistical and the second systematic. The measured direct CPasymmetries for the B+- decays are  A_CP = -0.10 +/- 0.08 +/- 0.02 below the eta_c threshold and  A_CP = 0.09 +/- 0.10 +?- 0.02 in the eta_c resonance region (m_phiphi in[2.94,3.02] GeV). Angular distributions are consistent with J^P = 0- in theeta_c resonance region and favor J^P = 0+ below the eta_c resonance.","Measurements of branching fractions and CP asymmetries and studies of
  angular distributions for B to phi phi K decays",B branching fraction and CP asymmetry measurements of B to phi phi K decays,0.7272727272727273,0.2911163665895025,0
"  Prompted by the level of accuracy now being achieved in tests of theunitarity of the CKM matrix, we consider the possible modification of the Fermimatrix element for the $\beta$-decay of a neutron, including possible in-mediumand isospin violating corrections. While the nuclear modifications lead to verysmall corrections once the Behrends-Sirlin-Ademollo-Gatto theorem is respected,the effect of the $u-d$ mass difference on the conclusion concerning $V_{ud}$is no longer insignificant. Indeed, we suggest that the correction to the valueof $|V_{ud}|^2 \, + \, |V_{us}|^2 \, + \, |V_{ub}|^2$ is at the level of$10^{-4}$.",Fermi matrix element with isospin breaking,Nuclear modifications of the Fermimatrix element for the $\beta$-decay,0.125,0.5773502691896257,0
"  In this paper, online convex optimization is applied to the problem ofcontrolling linear dynamical systems. An algorithm similar to online gradientdescent, which can handle time-varying and unknown cost functions, is proposed.Then, performance guarantees are derived in terms of regret analysis. We showthat the proposed control scheme achieves sublinear regret if the variation ofthe cost functions is sublinear. In addition, as a special case, the systemconverges to the optimal equilibrium if the cost functions are invariant aftersome finite time. Finally, the performance of the resulting closed loop isillustrated by numerical simulations.",Online Gradient Descent for Linear Dynamical Systems,Online Convex Optimization for Linear Dynamics,0.6153846153846153,0.4760116549244004,0
"  We study the Oliker-Prussner method exploiting its geometric nature. Wederive discrete stability and continuous dependence estimates in the max-normby using a discrete Alexandroff estimate and the Brunn-Minkowski inequality. Weshow that the method is exact for all convex quadratic polynomials provided theunderlying set of nodes is translation invariant within the domain; nodes stillconform to the domain boundary. This gives a suitable notion of operatorconsistency which, combined with stability, leads to pointwise rates ofconvergence for classical and non-classical solutions of the Monge-Amp\`{e}reequation.","Pointwise rates of convergence for the Oliker-Prussner method for the
  Monge-Amp\`{e}re equation",On the Oliker-Prussner method for convex quadratic polynomials,0.39999999999999997,0.20969025558524573,0
"  This paper takes a comprehensive view on the protocol stacks that are underdebate for a future Internet of Things (IoT). It addresses the holisticquestion of which solution is beneficial for common IoT use cases. We deployNDN and the two popular IP-based application protocols, CoAP and MQTT, in itsdifferent variants on a large-scale IoT testbed in single- and multi-hopscenarios. We analyze the use cases of scheduled periodic and unscheduledtraffic under varying loads. Our findings indicate that (a) NDN admits the mostresource-friendly deployment on nodes, and (b) shows superior robustness andresilience in multi-hop scenarios, while (c) the IP protocols operate at lessoverhead and higher speed in single-hop deployments. Most strikingly we findthat NDN-based protocols are in significantly better flow balance than theUDP-based IP protocols and require less corrective actions.","NDN, CoAP, and MQTT: A Comparative Measurement Study in the IoT",NDA: A Comprehensive Survey of Protocol Stacks for the Internet of Things,0.17391304347826086,0.6389431042462724,0
"  This paper deals with existence and multiplicity of positive solutions to thefollowing class of nonlocal equations with critical nonlinearity:\begin{equation}  \tag{$\mathcal E$}  (-\Delta)^s u = a(x) |u|^{2^*_s-2}u+f(x)\;\;\text{in}\;\mathbb{R}^{N}, \quad  u \in \dot{H}^s(\mathbb{R}^{N}), \end{equation} where $s \in (0,1)$, $N>2s$,$2_s^*:=\frac{2N}{N-2s}$, $0< a\in L^\infty(\mathbb{R}^{N})$ and $f$ is anonnegative nontrivial functional in the dual space of $\dot{H}^s$. We proveexistence of a positive solution whose energy is negative. Further, under theadditional assumption that $a$ is a continuous function, $a(x)\geq 1$ in$\mathbb{R}^{N}$, $a(x)\to 1$ as $|x|\to\infty$ and$\|f\|_{\dot{H}^s(\mathbb{R}^{N})'}$ is small enough (but $f\not\equiv 0$), weestablish existence of at least two positive solutions to ($\mathcal E$).","On multiplicity of positive solutions for nonlocal equations with
  critical nonlinearity","On the multiplicity of positive solutions to nonlocal equations with
  critical nonlinearity",0.8695652173913043,0.5452469119630863,0
"  We extract the total width of the top quark, Gamma_t, from the partial decaywidth Gamma(t -> W b) measured using the t-channel cross section for single topquark production and from the branching fraction B(t -> W b) measured in ttbarevents using up to 2.3 fb^-1 of integrated luminosity collected by the D0Collaboration at the Tevatron ppbar Collider. The result is Gamma_t = 1.99+0.69 -0.55 GeV, which translates to a top-quark lifetime of tau_t = (3.3 +1.3-0.9) x 10^-25 s. Assuming a high mass fourth generation b' quark and unitarityof the four-generation quark-mixing matrix, we set the first upper limit on|Vtb'| < 0.63 at 95% C.L.",Determination of the width of the top quark,The top quark lifetime of tau_t = (3.3 +1.3,0.3157894736842105,0.45180100180492244,0
"  Associated to a Mukai flop X ---> X' is on the one hand a sequence ofequivalences D(X) -> D(X'), due to Kawamata and Namikawa, and on the other handa sequence of autoequivalences of D(X), due to Huybrechts and Thomas. We workout a complete picture of the relationship between the two. We do the same forstandard flops, relating Bondal and Orlov's derived equivalences to sphericaltwists, extending a well-known story for the Atiyah flop to higher dimensions.",Mukai flops and P-twists,On the relationship between Mukai flops and Orlov's equivalences,0.4,0.3303164318013807,0
"  Quantum pseudo-telepathy games are good examples of explaining thestrangeness of quantum mechanics and demonstrating the advantage of quantumresources over classical resources. Most of the quantum pseudo-telepathy gamesare common interest games, nevertheless conflicting interest games are morewidely used to model real world situations. Recently Pappa et al. (Phys. Rev.Lett. 114, 020401, 2015) proposed the first two-party conflicting interest gamewhere quantum advice enhances social optimality. In the present paper we givetwo new three-party conflicting interest games and show that quantum advice canenhance social optimality in a three-party setting. The first game we proposeis based on the famous GHZ game which is a common interest game. The secondgame we propose is related to the Svetlichny inequality which demonstratesquantum mechanics cannot be explained by the local hidden variable model in athree-party setting.","Quantum advice enhances social optimality in three-party conflicting
  interest games",Three-Party Confusion Interest Games,0.5000000000000001,0.0,0
"  In this paper, a new network-transmission-based (NTB) algorithm is proposedfor human activity recognition in videos. The proposed NTB algorithm models theentire scene as an error-free network. In this network, each node correspondsto a patch of the scene and each edge represents the activity correlationbetween the corresponding patches. Based on this network, we further modelpeople in the scene as packages while human activities can be modeled as theprocess of package transmission in the network. By analyzing these specific""package transmission"" processes, various activities can be effectivelydetected. The implementation of our NTB algorithm into abnormal activitydetection and group activity recognition are described in detail in the paper.Experimental results demonstrate the effectiveness of our proposed algorithm.",A new network-based algorithm for human activity recognition in video,Network-Transmission-Based Algorithm for Human Activity Recognition in Video,0.8571428571428572,0.5506953149031838,0
"  We compute the expected value of powers of the geometric condition number ofrandom tensor rank decompositions. It is shown in particular that the expectedvalue of the condition number of $n_1\times n_2 \times 2$ tensors with a randomrank-$r$ decomposition, given by factor matrices with independent andidentically distributed standard normal entries, is infinite. This entails thatit is expected and probable that such a rank-$r$ decomposition is sensitive toperturbations of the tensor. Moreover, it provides concrete further evidencethat tensor decomposition can be a challenging problem, also from the numericalpoint of view. On the other hand, we provide strong theoretical and empiricalevidence that tensors of size $n_1~\times~n_2~\times~n_3$ with all $n_1,n_2,n_3\ge 3$ have a finite average condition number. This suggests there exists a gapin the expected sensitivity of tensors between those of format $n_1\times n_2\times 2$ and other order-3 tensors. For establishing these results, we showthat a natural weighted distance from a tensor rank decomposition to the locusof ill-posed decompositions with an infinite geometric condition number isbounded from below by the inverse of this condition number. That is, we proveone inequality towards a so-called condition number theorem for the tensor rankdecomposition.",On the average condition number of tensor rank decompositions,"The expected value of powers of the geometric condition number of tensor
  rank decompositions",0.6086956521739131,0.363622704650007,0
"  In this paper we construct a model that satisfies the theoretical requisitesof high energy soft interactions, based on two ingredients:(i) the results ofN=4 SYM, which at present is a unique theory that allows one to deal with alarge coupling constant; and (ii) the requirement of matching with high energyQCD. In accordance with these ideas, we assume that the soft Pomeron interceptis rather large, and the slope of the Pomeron trajectory is equal to zero. Wederive analytical formulae that sum both enhanced and semi-enhanced diagramsfor elastic and diffractive amplitudes. We fit the available experimental data,and predict the valuefor cross sections at the energies accessible at the LHC.The main corrections to the model are studied and evaluated.",N=4 SYM and QCD motivated approach to soft interactions at high energies,High Energy Soft Interactions,0.23529411764705882,0.0,0
"  Measurements of luminosity obtained using the ATLAS detector during earlyrunning of the Large Hadron Collider (LHC) at sqrt(s) = 7 TeV are presented.The luminosity is independently determined using several detectors and multiplealgorithms, each having different acceptances, systematic uncertainties andsensitivity to background. The ratios of the luminosities obtained from thesemethods are monitored as a function of time and of mu, the average number ofinelastic interactions per bunch crossing. Residual time- and mu-dependencebetween the methods is less than 2% for 0<mu<2.5. Absolute luminositycalibrations, performed using beam separation scans, have a common systematicuncertainty of +/-11, dominated by the measurement of the LHC beam currents.After calibration, the luminosities obtained from the different methods differby at most +/-2%. The visible cross sections measured using the beam scans arecompared to predictions obtained with the PYTHIA and PHOJET event generatorsand the ATLAS detector simulation.","Luminosity Determination in pp Collisions at sqrt(s)=7 TeV Using the
  ATLAS Detector at the LHC","Measurements of Luminosity Using the ATLAS Detector during Early
  Run at sqrt",0.41379310344827586,0.18272496802322832,0
"  We prove that, without any assumption on lower density bound or codimension,any 1-dimensional stationary varifold on any Riemannian manifold admits uniquetangent behaviour everywhere.",Unique tangent behavior for 1-dimensional stationary varifolds,Uniquetangent behaviour of stationary varifolds on Riemannian manifolds,0.25,0.43472087194499137,0
"  We open the paper with introductory considerations describing the motivationsof our long-term research plan targeting gravitomagnetism, illustrating thefluid-dynamics numerical test case selected for that purpose, that is, aperfect-gas sphere contained in a solid shell located in empty spacesufficiently away from other masses, and defining the main objective of thisstudy: the determination of the gravitofluid-static field required as initialfield ($t=0$) in forthcoming fluid-dynamics calculations. The determination ofthe gravitofluid-static field requires the solution of the isothermal-sphereLane-Emden equation. We do not follow the habitual approach of the literaturebased on the prescription of the central density as boundary condition; weimpose the gravitational field at the solid-shell internal wall. As thediscourse develops, we point out differences and similarities between theliterature's and our approach. We show that the nondimensional formulation ofthe problem hinges on a unique physical characteristic number that we callgravitational number because it gauges the self-gravity effects on the gas'fluid statics. We illustrate and discuss numerical results; some peculiarities,such as gravitational-number upper bound and multiple solutions, lead us toinvestigate the thermodynamics of the physical system, particularly entropy andenergy, and preliminarily explore whether or not thermodynamic-stabilityreasons could provide justification for either selection or exclusion ofmultiple solutions. We close the paper with a summary of the present study inwhich we draw conclusions and describe future work.",Fluid statics of a self-gravitating perfect-gas isothermal sphere,Gravitational number and self-gravity in a perfect-gas sphere,0.4000000000000001,0.7825422900366437,0
  Starting from first principles and general assumptions Newton's law ofgravitation is shown to arise naturally and unavoidably in a theory in whichspace is emergent through a holographic scenario. Gravity is explained as anentropic force caused by changes in the information associated with thepositions of material bodies. A relativistic generalization of the presentedarguments directly leads to the Einstein equations. When space is emergent evenNewton's law of inertia needs to be explained. The equivalence principle leadsus to conclude that it is actually this law of inertia whose origin isentropic.,On the Origin of Gravity and the Laws of Newton,Newton's law of gravity and emergent gravity,0.33333333333333326,0.476273899703797,0
"  It is possible to extract values for critical couplings and gamma_string inmatrix models by deriving a renormalization group equation for the variation ofthe of the free energy as the size N of the matrices in the theory is varied.In this paper we derive a ``renormalization group equation'' for the Pennermodel by direct differentiation of the partition function and show that itreproduces the correct values of the critical coupling and gamma_string and isconsistent with the logarithmic corrections present for g=0,1.",A Remark on the Renormalization Group Equation for the Penner Model,Renormalization Group Equations for the Penner Model,0.7777777777777778,0.27610369103579485,0
"  Massive multiple-input multiple-output (MIMO) and non-orthogonal multipleaccess (NOMA) are two key techniques for enabling massive connectivity infuture wireless networks. A massive MIMO-NOMA system can deliver remarkablespectral improvements and low communication latency. Nevertheless, theuncontrollable stochastic behavior of the wireless channels can still degradeits performance. In this context, intelligent reflecting surface (IRS) hasarisen as a promising technology for smartly overcoming the harmful effects ofthe wireless environment. The disruptive IRS concept of controlling thepropagation channels via software can provide attractive performance gains tothe communication networks, including higher data rates, improved userfairness, and, possibly, higher energy efficiency. In this article, in contrastto the existing literature, we demonstrate the main roles of IRSs in MIMO-NOMAsystems. Specifically, we identify and perform a comprehensive discussion ofthe main performance gains that can be achieved in IRS-assisted massiveMIMO-NOMA (IRS-NOMA) networks. We outline exciting futuristic use casescenarios for IRS-NOMA and expose the main related challenges and futureresearch directions. Furthermore, throughout the article, we support ourin-depth discussions with representative numerical results.","What Role Do Intelligent Reflecting Surfaces Play in Multi-Antenna
  Non-Orthogonal Multiple Access?",Intelligent Reflecting Surface in Massive MIMO-NOMA Networks,0.36363636363636365,0.25307989573458556,0
"  An extraordinary focusing property of a parabolic mirror for ultracoldneutrons in the presence of the gravitational field was first reported by A.Steyerl and co-authors. It was shown that all neutrons emitted from the focusof the mirror will be reflected back upon the same focus point passing, inbetween, a point of return in the gravitational field. The present note offersa complementary geometric proof of this feature and discusses someimplications.","A unique focusing property of a parabolic mirror for neutrons in the
  gravitational field: geometric proof","A geometric proof of the focusing property of a parabolic mirror for
  ultracold neut",0.5333333333333333,0.4361910814559407,0
"  This paper focuses on an essential task of the enhanced NodeB eNodeB elementin LTE architecture, the Radio Resource Manager RRM, which aims to accept orreject requests for connection to the network based on some constraints andensuring optimal distribution of radio resources between Users Equipments UEs.Its main functionalities include Admission Control AC and Packet Scheduling PS.This paper will center mainly on the PS part of the RRM task, which performsthe radio resource allocation in both uplink and downlink directions. Severalapproaches and algorithms have been proposed in the literature to address thisneed ie : allocate resources efficiently, the diversity and multitude ofalgorithms is related to the factors considered for the optimal management ofradio resource, specifically, the traffic type and the QoS Quality of Servicerequested by the UE. In this article, an art's state of the radio resourceallocation strategies and a detailed study of several scheduling algorithmsproposed for LTE (uplink and downlink) are made. Therefore, we offer ourevaluation and criticism.",Survey On Scheduling And Radio Resources Allocation In Lte,A Review of Radio Resource Allocation Strategies for LTE,0.4444444444444444,0.6865890479690392,0
"  The integration of the coupling effects of intrinsic wettability and surfacecharge in a nanochannel can cause non-intuitive behavior in the electrokineticenergy conversion processes. We demonstrate that in a nanofluidic device theenergy conversion efficiencies may get amplified with an increase in surfacecharge density, not perpetually, but only over a narrow regime of low surfacecharges, and may get significantly attenuated to reach a plateau beyond athreshold surface charging condition. This results from the complex interplaybetween fluid structuration and ionic transport within a charged interfaciallayer. We explain the corresponding findings from our molecular dynamicssimulations with the aid of a simple modified continuum based theory. Weattribute our findings to the four-way integration of surface charge,interfacial slip, ionic transport, and the water molecule structuration. Theconsequent complex non-linear nature of the energy transfer characteristics maybear far-ranging scientific and technological implications towards design,synthesis and operation of nano-batteries which can supply power at scales ofthe range molecular dimensions.",Electrokinetic Pumping And Energy Conversion At Nanoscales,"Molecular dynamics of the interaction of surface charge, interfaciallayer
  and water",0.1111111111111111,0.0,0
"  The growing need for low-latency access to computing resources has motivatedthe introduction of edge computing, where resources are strategically placed atthe access networks. Unfortunately, edge computing infrastructures like fogsand cloudlets have limited scalability and may be prohibitively expensive toinstall given the vast edge of the Internet. In this paper, we presentOpportunistic Edge Computing (OEC), a new computing paradigm that provides aframework to create scalable infrastructures at the edge using end-usercontributed resources. One of the goals of OEC is to place resources wherethere is high demand for them by incentivizing people to share their resources.This paper defines the OEC paradigm and the involved stakeholders and putsforward a management framework to build, manage and monitor scalable edgeinfrastructures. It also highlights the key differences between the OECcomputing models and the existing computing models and shed the light on earlyworks on the topic. The paper also presents preliminary experimental resultsthat highlight the benefits and the limitations of OEC compared to the regularcloud computing deployment and the Fog deployment. It finally summarizes keyresearch directions pertaining to resource management in OEC environments.","Opportunistic Edge Computing: Concepts, Opportunities and Research
  Challenges","Opportunistic Edge Computing: A New Computing Paradigm for Scalable Edge
  Computing",0.3157894736842105,0.27901593935858265,0
  We discuss the dynamics of the Dirac fermions in the general stronggravitational and electromagnetic fields. We derive the general Hermitian DiracHamiltonian and transform it to the Foldy-Wouthuysen representation for thespatially isotropic metric. The quantum operator equations of motion areobtained and the semiclassical limit is analyzed. The comparison of the quantummechanical and classical equations shows their complete agreement. The helicitydynamics in strong fields is discussed. Squaring the covariant Dirac equationexplicitly shows a similarity of the interactions of electromagnetic andgravitational fields with a charged and spinning particle.,Dirac fermions in strong gravitational fields,Dynamics of the Dirac fermions in strong fields,0.7142857142857143,0.3655552228545123,0
"  A search for the non-resonant production of Higgs boson pairs in the$HH\rightarrow b\bar{b}\tau^+\tau^-$ channel is performed using 140 fb$^{-1}$of proton-proton collisions at a centre-of-mass energy of $13$ TeV recorded bythe ATLAS detector at the CERN Large Hadron Collider. The analysis strategy isoptimised to probe anomalous values of the Higgs boson self-coupling modifier$\kappa_\lambda$ and of the quartic $HHVV$ ($V = W,Z$) coupling modifier$\kappa_{2V}$. No significant excess above the expected background fromStandard Model processes is observed. An observed (expected) upper limit$\mu_{HH}<5.9$ $(3.3)$ is set at 95% confidence-level on the Higgs boson pairproduction cross-section normalised to its Standard Model prediction. Thecoupling modifiers are constrained to an observed (expected) 95% confidenceinterval of $-3.1 < \kappa_\lambda < 9.0$ ($-2.5 < \kappa_\lambda < 9.3$) and$-0.5 < \kappa_{2V} < 2.7$ ($-0.2 < \kappa_{2V} < 2.4$), assuming all otherHiggs boson couplings are fixed to the Standard Model prediction. The resultsare also interpreted in the context of effective field theories via constraintson anomalous Higgs boson couplings and Higgs boson pair productioncross-sections assuming different kinematic benchmark scenarios.","Search for the non-resonant production of Higgs boson pairs via gluon
  fusion and vector-boson fusion in the $b\bar{b}\tau^+\tau^-$ final state in
  proton-proton collisions at $\sqrt{s} = 13$ TeV with the ATLAS detector","Search for non-resonant production of Higgs boson pairs in the
  b",0.47058823529411764,0.08458257039177179,0
"  In this paper, a new network-transmission-based (NTB) algorithm is proposedfor human activity recognition in videos. The proposed NTB algorithm models theentire scene as an error-free network. In this network, each node correspondsto a patch of the scene and each edge represents the activity correlationbetween the corresponding patches. Based on this network, we further modelpeople in the scene as packages while human activities can be modeled as theprocess of package transmission in the network. By analyzing these specific""package transmission"" processes, various activities can be effectivelydetected. The implementation of our NTB algorithm into abnormal activitydetection and group activity recognition are described in detail in the paper.Experimental results demonstrate the effectiveness of our proposed algorithm.",A new network-based algorithm for human activity recognition in video,Network-Transmission-Based Algorithm for Human Activity Recognition in Video,0.8571428571428572,0.5506953149031838,0
"  The sub-arcsec bright points (BP) associated with the small scale magneticfields in the lower solar atmosphere are advected by the evolution of thephotospheric granules. We measure various quantities related to the horizontalmotions of the BPs observed in two wavelengths, including the velocityauto-correlation function. A 1 hr time sequence of wideband H$\alpha$observations conducted at the \textit{Swedish 1-m Solar Telescope}(\textit{SST}), and a 4 hr \textit{Hinode} \textit{G}-band time sequenceobserved with the Solar Optical telescope are used in this work. We follow 97\textit{SST} and 212 \textit{Hinode} BPs with 3800 and 1950 individual velocitymeasurements respectively. For its high cadence of 5 s as compared to 30 s for\textit{Hinode} data, we emphasize more on the results from \textit{SST} data.The BP positional uncertainty achieved by \textit{SST} is as low as 3 km. Theposition errors contribute 0.75 km$^2$ s$^{-2}$ to the variance of the observedvelocities. The \textit{raw} and \textit{corrected} velocity measurements inboth directions, i.e., $(v_x,v_y)$, have Gaussian distributions with standarddeviations of $(1.32,1.22)$ and $(1.00, 0.86)$ km s$^{-1}$ respectively. The BPmotions have correlation times of about $22 - 30$ s. We construct the powerspectrum of the horizontal motions as a function of frequency, a quantity thatis useful and relevant to the studies of generation of Alfv\'en waves.Photospheric turbulent diffusion at time scales less than 200 s is found tosatisfy a power law with an index of 1.59.","Dynamics of the solar magnetic bright points derived from their
  horizontal motions","The horizontal motions of sub-arcsec bright points observed by the
  Swedish 1-m",0.23076923076923075,0.5491004867761125,0
"  Modern pattern recognition methods are based on convolutional networks sincethey are able to learn complex patterns that benefit the classification.However, convolutional networks are computationally expensive and require aconsiderable amount of memory, which limits their deployment on low-power andresource-constrained systems. To handle these problems, recent approaches haveproposed pruning strategies that find and remove unimportant neurons (i.e.,filters) in these networks. Despite achieving remarkable results, existingpruning approaches are ineffective since the accuracy of the original networkis degraded. In this work, we propose a novel approach to efficiently removefilters from convolutional networks. Our approach estimates the filterimportance based on its relationship with the class label on a low-dimensionalspace. This relationship is computed using Partial Least Squares (PLS) andVariable Importance in Projection (VIP). Our method is able to reduce up to 67%of the floating point operations (FLOPs) without penalizing the networkaccuracy. With a negligible drop in accuracy, we can reduce up to 90% of FLOPs.Additionally, sometimes the method is even able to improve the accuracycompared to original, unpruned, network. We show that employing PLS+VIP as thecriterion for detecting the filters to be removed is better than recent featureselection techniques, which have been employed by state-of-the-art pruningmethods. Finally, we show that the proposed method achieves the highest FLOPsreduction and the smallest drop in accuracy when compared to state-of-the-artpruning approaches. Codes are available at:https://github.com/arturjordao/PruningNeuralNetworks",Pruning Deep Neural Networks using Partial Least Squares,Efficient Filters Removal in Convolutional Networks,0.14285714285714288,0.45782273986766686,0
"  Floating offshore wind turbines are a novel technology, which has reached,with the first wind farm in operation, an advanced state of development. Thequestion of how floating wind systems can be optimized to operate smoothly inharsh wind and wave conditions is the subject of the present work. Anintegrated optimization was conducted, where the hull shape of asemi-submersible, as well as the wind turbine controller were varied with thegoal of finding a cost-efficient design, which does not respond to wind andwave excitations, resulting in small structural fatigue and extreme loads. Theoptimum design was found to have a remarkably low tower-base fatigue loadresponse and small rotor fore-aft amplitudes. Further investigations showedthat the reason for the good dynamic behavior is a particularly favorableresponse to first-order wave loads: The floating wind turbine rotates inpitch-direction about a point close to the rotor hub and the rotor fore-aftmotion is almost unaffected by the wave excitation. As a result, the powerproduction and the blade loads are not influenced by the waves. A comparableeffect was so far known for Tension Leg Platforms but not for semi-submersiblewind turbines. The methodology builds on a low-order simulation model, coupledto a parametric panel code model, a detailed viscous drag model and anindividually tuned blade pitch controller. The results are confirmed by thehigher-fidelity model FAST. A new indicator to express the optimal behaviorthrough a single design criterion has been developed.","Semi-Submersible Wind Turbine Hull Shape Design for a Favorable System
  Response Behavior","Optimization of a floating offshore wind turbine for low-frequency
  wind and wave exc",0.22222222222222224,0.6262844962765469,0
"  Recent approaches have achieved great success in image generation fromstructured inputs, e.g., semantic segmentation, scene graph or layout. Althoughthese methods allow specification of objects and their locations atimage-level, they lack the fidelity and semantic control to specify visualappearance of these objects at an instance-level. To address this limitation,we propose a new image generation method that enables instance-level attributecontrol. Specifically, the input to our attribute-guided generative model is atuple that contains: (1) object bounding boxes, (2) object categories and (3)an (optional) set of attributes for each object. The output is a generatedimage where the requested objects are in the desired locations and haveprescribed attributes. Several losses work collaboratively to encourageaccurate, consistent and diverse image generation. Experiments on Visual Genomedataset demonstrate our model's capacity to control object-level attributes ingenerated images, and validate plausibility of disentangled object-attributerepresentation in the image generation from layout task. Also, the generatedimages from our model have higher resolution, object classification accuracyand consistency, as compared to the previous state-of-the-art.",Attribute-guided image generation from layout,Image Generation from Object-Level Attributes,0.5,0.668740304976422,0
"  Recent advances on overfitting Bayesian mixture models provide a solid andstraightforward approach for inferring the underlying number of clusters andmodel parameters in heterogeneous datasets. The applicability of such aframework in clustering correlated high dimensional data is demonstrated. Forthis purpose an overfitting mixture of factor analyzers is introduced, assumingthat the number of factors is fixed. A Markov chain Monte Carlo (MCMC) samplercombined with a prior parallel tempering scheme is used to estimate theposterior distribution of model parameters. The optimal number of factors isestimated using information criteria. Identifiability issues related to thelabel switching problem are dealt by post-processing the simulated MCMC sampleby relabelling algorithms. The method is benchmarked against state-of-the-artsoftware for maximum likelihood estimation of mixtures of factor analyzersusing an extensive simulation study. Finally, the applicability of the methodis illustrated in publicly available data.","Overfitting Bayesian Mixtures of Factor Analyzers with an Unknown Number
  of Components","A Markov chain Monte Carlo sampler for clustering correlated high dimensional
  data",0.0,0.0,0
"  The production potential of the excited neutrinos at the FCC-basedelectron-hadron colliders, namely the ERL60$\otimes$FCC with $\sqrt{s}=3.46$TeV, the ILC$\otimes$FCC with $\sqrt{s}=10$ TeV, and the PWFA-LC$\otimes$FCCwith $\sqrt{s}=31.6$ TeV, has been analyzed. The branching ratios of theexcited neutrinos have been calculated for the different decay channels andshown that the dominant channel is $\nu^{\star}\rightarrow eW^{+}$. We havecalculated the production cross sections with the process of$ep\rightarrow\nu^{\star}q\rightarrow eW^{+}q$ and the decay widths of theexcited neutrinos with the process of $\nu^{\star}\rightarrow eW^{+}$. Thesignals and corresponding backgrounds are studied in detail to obtainaccessible mass limits. It is shown that the discovery limits obtained on themass of the excited neutrino are $2452$ GeV for $L_{int}=100$ $fb^{-1}$, $5635$GeV for $L_{int}=10$ $fb^{-1}$ ($6460$ GeV for $L_{int}=100$ $fb^{-1}$), and$10200$ GeV for $L_{int}=1$ $fb^{-1}$ ($13960$ GeV for $L_{int}=10$ $fb^{-1}$),for the center-of-mass energies of $3.46$, $10$, and $31.6$ TeV, respectively.","Excited neutrino search potential of the FCC-based electron-hadron
  colliders","Production potential of the excited neutrinos at the FCC-based
  Electron-Had",0.5217391304347826,0.35930411196308426,0
"  Spintronics is aimed at active controlling and manipulating the spin degreesof freedom in semiconductor devices. A promising way to achieve this goal is tomake use of the tunable Rashba effect that relies on the spin-orbit interaction(SOI) in a two-dimensional (2D) electron system immersed in aninversion-asymmetric environment. The SOI induced spin-splitting of the2D-electron state provides a basis for many theoretically proposed spintronicdevices. However, the lack of semiconductors with large Rashba effect hindersrealization of these devices in actual practice. Here we report on a giantRashba-type spin splitting in 2D electron systems which reside attellurium-terminated surfaces of bismuth tellurohalides. Among thesesemiconductors, BiTeCl stands out for its isotropic metallic surface-state bandwith the Gamma-point energy lying deep inside the bulk band gap. The giantspin-splitting of this band ensures a substantial spin asymmetry of theinelastic mean free path of quasiparticles with different spin orientations.","Ideal two-dimensional electron systems with a giant Rashba-type spin
  splitting in real materials: surfaces of bismuth tellurohalides",Giant Rashba-type spin splitting in bismuth tellurohalides,0.5925925925925926,0.11717090906676965,0
"  Let r be an integer, f(n) a function, and H a graph. Introduced by Erd\H{o}s,Hajnal, S\'{o}s, and Szemer\'edi, the r-Ramsey-Tur\'{a}n number of H, RT_r(n,H, f(n)), is defined to be the maximum number of edges in an n-vertex, H-freegraph G with \alpha_r(G) <= f(n) where \alpha_r(G) denotes the K_r-independencenumber of G. In this note, using isoperimetric properties of the highdimensional unit sphere, we construct graphs providing lower bounds forRT_r(n,K_{r+s},o(n)) for every 2 <= s <= r. These constructions are sharp foran infinite family of pairs of r and s. The only previous sharp constructionwas by Bollob\'as and Erd\Hos for r = s = 2.",Some Exact Ramsey-Tur\'an Numbers,Sharp constructions for the r-Ramsey-Tur\'{a}n number of graphs,0.3333333333333333,0.0,0
"  Cellular or dendritic microstructures that result as a function of additivemanufacturing solidification conditions in a Ni-based melt pool are simulatedin the present work using three-dimensional phase-field simulations. Amacroscopic thermal model is used to obtain the temperature gradient $G$ andthe solidification velocity $V$ which are provided as inputs to the phase-fieldmodel. We extract the cell spacings, cell core compositions, and cell tip aswell as mushy zone temperatures from the simulated microstructures as afunction of $V$. Cell spacings are compared with different scaling laws thatcorrelate to the solidification conditions and approximated by $G^{-m}V^{-n}$.Cell core compositions are compared with the analytical solutions of a dendritegrowth theory and found to be in good agreement. Through analysis of the mushyzone, we extract a characteristic bridging plane, where the primary $\gamma$phase coalesces across the intercellular liquid channels at a $\gamma$ fractionbetween 0.6 and 0.7. The temperature and the $\gamma$ fraction in this planeare found to decrease with increasing $V$. The simulated microstructuralfeatures are significant as they can be used as inputs for the simulation ofsubsequent heat treatment processes.","Simulation and analysis of ${\gamma}$-Ni cellular growth during laser
  powder deposition of Ni-based superalloys","Simulation of cellular or dendritic microstructures in Ni-based melt
  pools",0.3703703703703703,0.5330859115179258,0
"  During plastic deformation of granular materials due to loading, thestress-strain and strength characteristics of sand grains are influenced withgrain size, their distribution and packing. Also the macroscopic behaviour ofgranular materials changes with the variation of microscopic behaviour.Particle size is one of the important properties which plays a dominant role onthe stress, strain and strength responses of granular materials. Alteration ofgrain size results in the change of void ratio as well as particle effectivecontact area revolutionized and the load distribution mechanism of particle toparticle contact. To evaluate the effect of particle size, a series of directshear tests were performed considering uniform particles of eight samples(0.075, 0.15, 0.212, 0.300, 0.600, 1.18, 1.72 and 2.76 mm) and graded particlesof two samples (0.075-1.18 mm and 0.075-2.36 mm). Three types of normal loads(0.05, 0.10 and 0.15 kN) were selected for each test. For uniform particles,particles retained on individual sieve size were considered and in gradedparticles combination of each uniform particle pondered. A theoretical approachwas also proposed to correlate the particle size and macroscopic response. Fromthe experimental results, it was observed that for each set of normal load withthe increase of particle size ,angle of internal friction as well as maximumhorizontal shear stress increases for uniform sands and a similar response wasnoticed in graded sands but the larger the gradation the higher the shearstrength. Maximum horizontal shear and angle of internal friction with respectto particle size is also influenced by normal stress. Experimental results havegood agreement with the theoretical approach.",Effect of Particle Size on the Shear Strength Behavior of Sands,Particle size and macroscopic response of granular materials,0.3157894736842105,0.4859869096699081,0
"  We generalize unitarity bounds on operator dimensions in conformal fieldtheory to field theories with spacetime dependent couplings. Below the energyscale of spacetime variation of the couplings, their evolution can stronglyaffect the physics, effectively shifting the infrared operator scaling andunitarity bounds determined from correlation functions in the theory. Weanalyze this explicitly for large-$N$ double-trace flows, and connect these toUV complete field theories. One motivating class of examples comes from ourprevious work on FRW holography, where this effect explains the range offlavors allowed in the dual, time dependent, field theory.",Unitarity bounds and RG flows in time dependent quantum field theory,Unitarity bounds on operator dimensions in conformal field theory,0.5,0.4888290318657942,0
"  This paper presents a gender classification schema based on onlinehandwriting. Using samples acquired with a digital tablet that captures thedynamics of the writing, it classifies the writer as a male or a female. Themethod proposed is allographic, regarding strokes as the structural units ofhandwriting. Strokes performed while the writing device is not exerting anypressure on the writing surface, pen-up (in-air) strokes, are also taken intoaccount. The method is also text-dependent meaning that training and testing isdone with exactly the same text. Text-dependency allows classification beperformed with very small amounts of text. Experimentation, performed withsamples from the BiosecurID database, yields results that fall in the range ofthe classification averages expected from human judges. With only fourrepetitions of a single uppercase word, the average rate of well classifiedwriters is 68%; with sixteen words, the rate rises to an average 72.6%.Statistical analysis reveals that the aforementioned rates are highlysignificant. In order to explore the classification potential of the pen-upstrokes, these are also considered. Although in this case results are notconclusive, an outstanding average of 74% of well classified writers isobtained when information from pen-up strokes is combined with information frompen-down ones.","Gender classification by means of online uppercase handwriting: A
  text-dependent allographic approach",Gender Classification of Handwritten Writers Using Pen-up Strokes,0.27272727272727276,0.42888194248035344,0
"  The increasing popular interest in personal telemetry, also called theQuantified Self or ""lifelogging"", has induced a popularity surge for wearablepersonal fitness trackers. Fitness trackers automatically collect sensor dataabout the user throughout the day, and integrate it into social networkaccounts. Solution providers have to strike a balance between many constraints,leading to a design process that often puts security in the back seat. Case inpoint, we reverse engineered and identified security vulnerabilities in FitbitUltra and Gammon Forerunner 610, two popular and representative fitness trackerproducts. We introduce FitBite and GarMax, tools to launch efficient attacksagainst Fitbit and Garmin.  We devise SensCrypt, a protocol for secure data storage and communication,for use by makers of affordable and lightweight personal trackers. SensCryptthwarts not only the attacks we introduced, but also defends against powerfulJTAG Read attacks. We have built Sens.io, an Arduino Uno based trackerplatform, of similar capabilities but at a fraction of the cost of currentsolutions. On Sens.io, SensCrypt imposes a negligible write overhead andsignificantly reduces the end-to-end sync overhead of Fitbit and Garmin.",Secure Management of Low Power Fitness Trackers,Sens.io: A Secure Personal Tracking Platform for Fitbit Ultra and Gammon Forerunner,0.1,0.537284965911771,0
"  This paper aims to make a graph representing an essential skeleton of acharacter from an image that includes a machine printed or a handwrittencharacter using growing neural gas (GNG) method and relative network graph(RNG) algorithm. The visual system in our brain can recognize printedcharacters and handwritten characters easily, robustly, and precisely. How doesour brain robustly recognize characters? The visual processing in our brainuses the essential features of an object, such as crosses and corners. Thesefeatures will be helpful for character recognition by a computer. However,extraction of the features is difficult. If the skeleton of a character isrepresented as a graph, we can more easily extract the features. To extract theskeleton of a character as a graph from an image, this paper proposes the newapproach using GNG and RNG algorithm. I achieved to extract skeleton graphsfrom images including distorted, noisy, and handwritten characters.","Extract an essential skeleton of a character as a graph from a character
  image",An Image-based Image-Based Synthesis of a Character,0.34782608695652173,0.17185045819660794,0
"  Six-dimensional supergravity theories with N=(1,0) supersymmetry must satisfyanomaly equations. These equations come from demanding the cancellation ofgravitational, gauge and mixed anomalies. The anomaly equations haveimplications for the geometrical data of Calabi-Yau threefolds, since F-theorycompactified on an elliptically fibered Calabi-Yau threefold with a sectiongenerates a consistent six-dimensional N=(1,0) supergravity theory. In thispaper, we show that the anomaly equations can be summarized by threeintersection theory identities. In the process we also identify the geometriccounterpart of the anomaly coefficients---in particular, those of the abeliangauge groups---that govern the low-energy dynamics of the theory. We discussthe results in the context of investigating string universality in sixdimensions.",Anomaly Equations and Intersection Theory,Three Intersection Theory Identities in Six-Dimensional Supergravity,0.3076923076923077,0.4671379777282001,0
"  The evaporation of black holes into apparently thermal radiation poses aserious conundrum for theoretical physics: at face value, it appears that inthe presence of a black hole quantum evolution is non-unitary and destroysinformation. This information loss paradox has its seed in the presence of ahorizon causally separating the interior and asymptotic regions in a black holespacetime. A quantitative resolution of the paradox could take several forms:(a) a precise argument that the underlying quantum theory is unitary, and thatinformation loss must be an artifact of approximations in the derivation ofblack hole evaporation, (b) an explicit construction showing how informationcan be recovered by the asymptotic observer, (c) a demonstration that thecausal disconnection of the black hole interior from infinity is an artifact ofthe semiclassical approximation. This review summarizes progress on all thesefronts.",Quantitative approaches to information recovery from black holes,Information loss paradox in black hole quantum evolution,0.375,0.5946035575013605,0
  We show in a diagrammatic and regularization independent analysis that thequadratic contribu- tion to the beta function which has been conjectured torender quantum electrodynamics asymp- totically free near the Planck scale hasits origin in a surface term. Such surface term is intrinsically arbitrarilyvalued and it is argued to vanish in a consistent treatment of the model.,"Quantum gravitational contributions to the beta function of quantum
  electrodynamics",The beta function and the surface term,0.3529411764705882,0.3367765041827165,0
"  At I/ITSEC 2019, the authors presented a fully-automated workflow to segment3D photogrammetric point-clouds/meshes and extract object information,including individual tree locations and ground materials (Chen et al., 2019).The ultimate goal is to create realistic virtual environments and provide thenecessary information for simulation. We tested the generalizability of thepreviously proposed framework using a database created under the U.S. Army'sOne World Terrain (OWT) project with a variety of landscapes (i.e., variousbuildings styles, types of vegetation, and urban density) and different dataqualities (i.e., flight altitudes and overlap between images). Although thedatabase is considerably larger than existing databases, it remains unknownwhether deep-learning algorithms have truly achieved their full potential interms of accuracy, as sizable data sets for training and validation arecurrently lacking. Obtaining large annotated 3D point-cloud databases istime-consuming and labor-intensive, not only from a data annotation perspectivein which the data must be manually labeled by well-trained personnel, but alsofrom a raw data collection and processing perspective. Furthermore, it isgenerally difficult for segmentation models to differentiate objects, such asbuildings and tree masses, and these types of scenarios do not always exist inthe collected data set. Thus, the objective of this study is to investigateusing synthetic photogrammetric data to substitute real-world data in trainingdeep-learning algorithms. We have investigated methods for generating syntheticUAV-based photogrammetric data to provide a sufficiently sized database fortraining a deep-learning algorithm with the ability to enlarge the data sizefor scenarios in which deep-learning models have difficulties.","Generating synthetic photogrammetric data for training deep learning
  based 3D point cloud segmentation models",A Novel Approach to 3D Photogrammetric Segmentation,0.19047619047619047,0.22616792214653433,0
"  A scroll wave in a sufficiently thin layer of an excitable medium withnegative filament tension can be stable nevertheless due to filament rigidity.Above a certain critical thickness of the medium, such scroll wave will have atendency to deform into a buckled, precessing state. Experimentally this willbe seen as meandering of the spiral wave on the surface, the amplitude of whichgrows with the thickness of the layer, until a break-up to scroll waveturbulence happens. We present a simplified theory for this phenomenon andillustrate it with numerical examples.",Buckling of scroll waves,A simplified theory for scroll wave turbulence,0.36363636363636365,0.6147881529512643,0
  The Roper resonance is considered as a mixed state of a three-quark coreconfiguration and a hadron molecular component N+sigma. Based on this ansatz westudy electroproduction of the Roper resonance. The strong and electromagneticcouplings induced by the quark core are calculated in the 3P0 model. Thecontribution of the vector meson cloud to the electromagnetic transition isgiven in the framework of the VMD model. Results are compared with the recentJLab electroproduction data.,"Electroproduction of the Roper resonance on the proton: the role of the
  three-quark core and the molecular N-sigma component",Electroproduction of the Roper resonance in the 3P0 model,0.4,0.15377854660688903,0
"  The spatial distribution of sources of gamma-ray bursts (GRB) with known redshifts is analyzed by the conditional density and pairwise distance methods.The sample of GRB is based on data from the Swift mission and contains fluxes,coordinates, and red shifts for 384 GRB sources. Selection effects that distortthe true source distribution are taken into account by comparing the observeddistribution with fractal and uniform model catalogs. The Malmqvist effect ismodeled using an approximation for the visible luminosity function of the GRB.The case of absorption in the galactic plane is also examined.This approachmakes it possible to study the spatial structure of the entire sample at onetime without artificial truncations. The estimated fractal dimensionality is$D=2.55\pm0.06$ on scales of $2\div6$ Gpc.",Spatial Distribution of Gamma-Ray Burst Sources,"Spatial Structure of Gamma-Ray Bursts with Redshift
  Selection",0.6250000000000001,0.48109772909788073,0
"  Several works have shown unconditional hardness (via integrality gaps) ofcomputing equilibria using strong hierarchies of convex relaxations. Suchresults however only apply to the problem of computing equilibria that optimizea certain objective function and not to the (arguably more fundamental) task offinding \emph{any} equilibrium.  We present an algorithmic model based on the sum-of-squares (SoS) hierarchythat allows escaping this inherent limitation of integrality gaps. In thismodel, algorithms access the input game only through a relaxed solution to thenatural SoS relaxation for computing equilibria. They can then adaptivelyconstruct a list of candidate solutions and invoke a verification oracle tocheck if any candidate on the list is a solution. This model captures mostwell-studied approximation algorithms such as those for Max-Cut, Sparsest Cut,and Unique-Games.  The state-of-the-art algorithms for computing exact and approximateequilibria in two-player, n-strategy games are captured in this model andrequire that at least one of i) size (~ running time) of the SoS relaxation orii) the size of the list of candidates, be at least $2^{\Omega(n)}$ and$n^{\Omega(\log{(n)})}$ respectively. Our main result shows a lower bound thatmatches these upper bound up to constant factors in the exponent.  This can be interpreted as an unconditional confirmation, in our restrictedalgorithmic framework, of Rubinstein's recent conditional hardness \cite{Rub}for computing approximate equilibria.  Our proof strategy involves constructing a family of games that all share acommon sum-of-squares solution but every (approximate) equilibrium of one gameis far from every (approximate) equilibrium of any other game in the family.","Sum-of-Squares meets Nash: Optimal Lower Bounds for Finding any
  Equilibrium",Unconditional Hardness for Computing Equilibria,0.11764705882352941,0.24601580968354606,0
"  Sufficient data presence is one of the key preconditions for applying metricsin practice. Based on both Altmetric.com data and Mendeley data collected up to2019, this paper presents a state-of-the-art analysis of the presence of 12kinds of altmetric events for nearly 12.3 million Web of Science publicationspublished between 2012 and 2018. Results show that even though an upward trendof data presence can be observed over time, except for Mendeley readers andTwitter mentions, the overall presence of most altmetric data is still low. Themajority of altmetric events go to publications in the fields of Biomedical andHealth Sciences, Social Sciences and Humanities, and Life and Earth Sciences.As to research topics, the level of attention received by research topicsvaries across altmetric data, and specific altmetric data show differentpreferences for research topics, on the basis of which a framework foridentifying hot research topics is proposed and applied to detect researchtopics with higher levels of attention garnered on certain altmetric datasource. Twitter mentions and policy document citations were selected as twoexamples to identify hot research topics of interest of Twitter users andpolicy-makers, respectively, shedding light on the potential of altmetric datain monitoring research trends of specific social attention.","An extensive analysis of the presence of altmetric data for Web of
  Science publications across subject fields and research topics",The presence of altmetric events in Web of Science publications,0.5333333333333333,0.13976396370981378,0
"  We consider the numerical approximations of a two-phase hydrodynamics coupledphase-field model that incorporates the variable densities, viscosities andmoving contact line boundary conditions. The model is a nonlinear, coupledsystem that consists of incompressible Navier--Stokes equations with thegeneralized Navier boundary condition, and the Cahn--Hilliard equations withmoving contact line boundary conditions. By some subtle explicit--implicittreatments to nonlinear terms, we develop two efficient, unconditionally energystable numerical schemes, in particular, a linear decoupled energy stablescheme for the system with static contact line condition, and a nonlinearenergy stable scheme for the system with dynamic contact line condition. Anefficient spectral-Galerkin spatial discretization is implemented to verify theaccuracy and efficiency of proposed schemes. Various numerical results showthat the proposed schemes are efficient and accurate.","Numerical Approximations for a Phase-Field Moving Contact Line Model
  with Variable Densities and Viscosities",Efficient and Energy Stable Numerical Schemes for a Two-Phase Hydrod,0.30769230769230765,0.3077772945160715,0
"  Tic-Tac-Toe game can be played by two players where the square block (3 x 3)can be filled with a cross (X) or a circle (O). The game will toggle betweenthe players by giving the chance for each player to mark their move. When oneof the players make a combination of 3 same markers in a horizontal, verticalor diagonal line the program will display which player has won, whether X or O.In this paper, we implement a 3x3 tic-tac-toe game in LabVIEW. The game isdesigned so that two players can play tic-tac-toe using LabVIEW software. Theprogram will contain a display function and a select function to place thesymbol as well as toggle between the symbols allowing each player a turn toplay the game. The program will update after each player makes their move andcheck for the conditions of game as it goes on. Overall program works withoutany bugs and is able to use",Implementation of Tic-Tac-Toe Game in LabVIEW,Tic-Tac-Toe Game in LabVIEW,0.8571428571428571,0.6065306597126334,0
"  We show the $H^{1}$ scattering for a one dimensional nonlinear Schr\""odingerequation with a non-negative, repulsive potential $V$ such that $V,xV\inW^{1,1}$, and a mass-supercritical non-linearity. We follow the approach ofconcentration-compacity/rigidity first introduced by Kenig and Merle.",Scattering for NLS with a potential on the line,"$H^{1}$ scattering for a nonlinear Schr\""oding equation with a
 ",0.39999999999999997,0.45180100180492244,0
"  BIRDS stands for ""Bioinformatics and Information Retrieval Data Structuresanalysis and design"" and is a 4-year project (2016--2019) that has receivedfunding from the European Union's Horizon 2020 research and innovationprogramme under the Marie Sklodowska-Curie grant agreement No 690941.  The overall goal of BIRDS is to establish a long term international networkinvolving leading researchers in the development of efficient data structuresin the fields of Bioinformatics and Information Retrieval, to strengthen thepartnership through the exchange of knowledge and expertise, and to developintegrated approaches to improve current approaches in both fields. Theresearch will address challenges in storing, processing, indexing, searchingand navigating genome-scale data by designing new algorithms and datastructures for sequence analysis, networks representation or compressing andindexing repetitive data.  BIRDS project is carried out by 7 research institutions from Australia(University of Melbourne), Chile (University of Chile and University ofConcepci\'on), Finland (University of Helsinki), Japan (Kyushu University),Portugal (Instituto de Engenharia de Sistemas e Computadores,Investiga\c{c}\~ao e Desenvolvimento em Lisboa, INESC-ID), and Spain(University of A Coru\~na), and a Spanish SME (Enxenio S.L.). It is coordinatedby the University of A Coru\~na (Spain).","About BIRDS project (Bioinformatics and Information Retrieval Data
  Structures Analysis and Design)","BIRDS: A long term international network for efficient data structures
  analysis and design",0.48000000000000004,0.5266403878479265,0
"  We present a computational microscopy analysis (targeted molecular dynamicssimulations) of the structure and performance of conductive metal organicframework (MOF) electrodes in supercapacitors with room temperature ionicliquids. The molecular modeling predicts the characteristic shapes of thepotential dependence of electrode capacitance, relying on the structure of MOFelectrodes and particularly how ions transport and reside in MOFs underpolarization. Transmission line model was adopted to characterize the chargingdynamics process and build up a bridge to evaluate the capacitive performanceof practical supercapacitor devices at macroscale from the simulation-obtaineddata at nanoscale. Such nanoscale-to-macroscale analysis demonstrates thepotential of MOF supercapacitors for achieving unprecedentedly high volumetricenergy and power densities. The investigation gives molecular insights into thepreferred structures of MOF for achieving these results, which could provide ablueprint for future experimental characterization of these new systems.","Molecular understanding of charge storage and charging dynamics in
  supercapacitors with MOF electrodes and ionic liquid electrolytes","Molecular modeling of conductive metal organicframework electrodes in
  supercapacitors",0.30769230769230765,0.21104245852031664,0
"  The stress-driven motion of dislocations in crystalline solids, and thus theensuing plastic deformation process, is greatly influenced by the presence orabsence of various point-like defects such as precipitates or solute atoms.These defects act as obstacles for dislocation motion and hence affect themechanical properties of the material. Here we combine molecular dynamicsstudies with three-dimensional discrete dislocation dynamics simulations inorder to model the interaction between different kinds of precipitates and a$\frac{1}{2}\langle 1 1 1\rangle$ $\{1 1 0\}$ edge dislocation in BCC iron. Wehave implemented immobile spherical precipitates into the ParaDis discretedislocation dynamics code, with the dislocations interacting with theprecipitates via a Gaussian potential, generating a normal force acting on thedislocation segments. The parameters used in the discrete dislocation dynamicssimulations for the precipitate potential, the dislocation mobility, shearmodulus and dislocation core energy are obtained from molecular dynamicssimulations. We compare the critical stresses needed to unpin the dislocationfrom the precipitate in molecular dynamics and discrete dislocation dynamicssimulations in order to fit the two methods together, and discuss the varietyof the relevant pinning/depinning mechanisms.","Multi-scale modeling of dislocation-precipitate interactions in Fe: from
  molecular dynamics to discrete dislocations","Dynamical dynamics of the dislocation from spherical precipitates in
  ParaDis:",0.32,0.5891510462454596,0
"  We consider an SOS (solid-on-solid) model, with spin values from the set ofall integers, on a Cayley tree of order k and are interested intranslation-invariant gradient Gibbs measures (GGMs) of the model. Such ameasure corresponds to a boundary law (a function defined on vertices of theCayley tree) satisfying a functional equation. In the ferromagnetic SOS case onthe binary tree we find up to five solutions to a class of 4-periodic boundarylaw equations (in particular, some 2-periodic ones). We show that theseboundary laws define up to four distinct GGMs. Moreover, we construct some3-periodic boundary laws on the Cayley tree of arbitrary order k, which defineGGMs different from the 4-periodic ones.","Gradient Gibbs measures for the SOS model with countable values on a
  Cayley tree",Boundary laws for ferromagnetic SOS models on Cayley trees,0.5217391304347826,0.4684677063277009,0
"  We use diagrammatic many-body perturbation theory in combination withlow-momentum interactions derived from chiral effective field theory toconstruct effective shell-model transition operators for the neutrinolessdouble-beta decay of 76Ge and 82Se. We include all unfolded diagrams to first-and second-order in the interaction and all singly folded diagrams that can beconstructed from them. The resulting effective operator, which accounts forphysics outside the shell-model space, increases the nuclear matrix element byabout 20% in 76Ge and 30% in 82Se.",Effective double-beta-decay operator for 76Ge and 82Se,"Effective shell-model transition operators for neutrinoless double-beta decay
  of 76",0.380952380952381,0.668740304976422,0
"  This article studies the problem of approximating functions belonging to aHilbert space $H_d$ with an isotropic or anisotropic Gaussian reproducingkernel, $$ K_d(\bx,\bt) =\exp\left(-\sum_{\ell=1}^d\gamma_\ell^2(x_\ell-t_\ell)^2\right) \ \ \ \mbox{forall}\ \ \bx,\bt\in\reals^d. $$ The isotropic case corresponds to using the sameshape parameters for all coordinates, namely $\gamma_\ell=\gamma>0$ for all$\ell$, whereas the anisotropic case corresponds to varying shape parameters$\gamma_\ell$. We are especially interested in moderate to large $d$.","Rate of Convergence and Tractability of the Radial Function
  Approximation Problem","Approximating functions belonging to Hilbert spaces with an isotropic or anisotropic
 ",0.09090909090909091,0.0,0
"  We consider consecutive random subdivision of polygons described as follows.Given an initial convex polygon with $d\ge 3$ edges, we choose a point atrandom on each edge, such that the proportions in which these points divideedges are i.i.d. copies of some random variable $\xi$. These new points form anew (smaller) polygon. By repeatedly implementing this procedure we obtain asequence of random polygons. The aim of this paper is to show that under verymild non-degenerateness conditions on $\xi$, the shapes of these polygonseventually become ""flat"" The convergence rate to flatness is also investigated;in particular, in the case of triangles ($d=3$), we show how to calculate theexact value of the rate of convergence, connected to Lyapunov exponents. Usingthe theory of products of random matrices our paper greatly generalizes theresults of Volkov (2013) which are achieved mostly by using ad hoc methods.",A universal result for consecutive random subdivision of polygons,On the convergence rate of random polygons,0.25,0.6080253214198359,0
"  (Abridged) We present the angular power spectra derived from the 7-year mapsand discuss the cosmological conclusions that can be inferred from WMAP dataalone. The third acoustic peak in the TT spectrum is now well measured by WMAP.In the context of a flat LambdaCDM model, this improvement allows us to placetighter constraints on the matter density from WMAP data alone, and on theepoch of matter-radiation equality, The temperature-polarization (TE) spectrumis detected in the 7-year data with a significance of 20 sigma, compared to 13sigma with the 5-year data. The low-l EE spectrum, a measure of the opticaldepth due to reionization, is detected at 5.5 sigma significance when averagedover l = 2-7. The BB spectrum, an important probe of gravitational waves frominflation, remains consistent with zero. The upper limit on tensor modes frompolarization data alone is a factor of 2 lower with the 7-year data than it wasusing the 5-year data (Komatsu et al. 2010). We test the parameter recoveryprocess for bias and find that the scalar spectral index, ns, is biased high,but only by 0.09 sigma, while the remaining parameters are biased by < 0.15sigma. The improvement in the third peak measurement leads to tighter lowerlimits from WMAP on the number of relativistic degrees of freedom (e.g.,neutrinos) in the early universe: Neff > 2.7 (95% CL). Also, using WMAP dataalone, the primordial helium mass fraction is found to be YHe = 0.28+0.14-0.15,and with data from higher-resolution CMB experiments included, we now establishthe existence of pre-stellar helium at > 3 sigma (Komatsu et al. 2010).","Seven-Year Wilkinson Microwave Anisotropy Probe (WMAP) Observations:
  Power Spectra and WMAP-Derived Parameters",The third acoustic peak in the TT spectrum from WMAP data,0.08,0.0,0
"  Subjectivity detection is the task of identifying objective and subjectivesentences. Objective sentences are those which do not exhibit any sentiment.So, it is desired for a sentiment analysis engine to find and separate theobjective sentences for further analysis, e.g., polarity detection. Insubjective sentences, opinions can often be expressed on one or multipletopics. Aspect extraction is a subtask of sentiment analysis that consists inidentifying opinion targets in opinionated text, i.e., in detecting thespecific aspects of a product or service the opinion holder is either praisingor complaining about.",Basic tasks of sentiment analysis,Aspect extraction for opinion detection,0.0,0.0,0
"  We investigate a simple 5D extension of the Minimal Supersymmetric (SUSY)Standard Model (SM) that is combined with the bulk matter Randall-Sundrum (RS)model, which gives a natural explanation the Yukawa coupling hierarchy. In thismodel, matter and gauge superfields reside in the 5D bulk while a SUSY breakingsector and the Higgs doublet superfields are localized on the infrared brane.The Yukawa coupling hierarchy in SM can be naturally explained through thewavefunction localization of the matter superfields. While sparticles obtaintheir flavor-blind soft SUSY breaking masses dominantly from thegaugino-mediated SUSY breaking, flavor-violating soft terms arise through thegravity-mediated SUSY breaking which are controlled by the wavefunctionlocalization of the matter superfields. This structure of the model allows usto predict the sparticle mass spectrum including flavor-violating terms. Wefirst explicitly determine the 5D disposition of matter superfields from thelow energy experimental data on SM fermion masses, CKM matrix and the neutrinooscillation parameters. Then, we calculate particle mass spectra and estimatethe effects of the flavor-violating soft terms, which should be compared withthe current experimental constraints. With gravitino being the lightestsparticle (LSP), the next-to-LSP, which is long-lived, is predicted most likelyto be either singlet smuon-like or selectron-like. The model can be tested atcollider experiments through flavor-violating processes involving sparticles.The flavor structure among sparticle, once observed, gives us a clue to deepunderstanding of the origin of Yukawa coupling hierarchy.",Gaugino Mediation Combined with the Bulk Matter Randall-Sundrum Model,The Yukawa Coupling Hierarchy in Minimal Supersymmetric Model,0.22222222222222224,0.5247357977607321,0
  We consider the sizing of network buffers in 802.11 based networks. Wirelessnetworks face a number of fundamental issues that do not arise in wirednetworks. We demonstrate that the use of fixed size buffers in 802.11 networksinevitably leads to either undesirable channel under-utilization or unnecessaryhigh delays. We present two novel dynamic buffer sizing algorithms that achievehigh throughput while maintaining low delay across a wide range of networkconditions. Experimental measurements demonstrate the utility of the proposedalgorithms in a production WLAN and a lab testbed.,Buffer Sizing for 802.11 Based Networks,Dynamic Buffer Sizes in 802.11 Networks,0.7142857142857143,0.8408964152537145,0
"  We address one of the main challenges towards autonomous quadrotor flight incomplex environments, which is flight through narrow gaps. While previous worksrelied on off-board localization systems or on accurate prior knowledge of thegap position and orientation, we rely solely on onboard sensing and computingand estimate the full state by fusing gap detection from a single onboardcamera with an IMU. This problem is challenging for two reasons: (i) thequadrotor pose uncertainty with respect to the gap increases quadratically withthe distance from the gap; (ii) the quadrotor has to actively control itsorientation towards the gap to enable state estimation (i.e., active vision).We solve this problem by generating a trajectory that considers geometric,dynamic, and perception constraints: during the approach maneuver, thequadrotor always faces the gap to allow state estimation, while respecting thevehicle dynamics; during the traverse through the gap, the distance of thequadrotor to the edges of the gap is maximized. Furthermore, we replan thetrajectory during its execution to cope with the varying uncertainty of thestate estimate. We successfully evaluate and demonstrate the proposed approachin many real experiments. To the best of our knowledge, this is the first workthat addresses and achieves autonomous, aggressive flight through narrow gapsusing only onboard sensing and computing and without prior knowledge of thepose of the gap.","Aggressive Quadrotor Flight through Narrow Gaps with Onboard Sensing and
  Computing using Active Vision",Autonomous Quadrotor Flight Through Narrow Gaps,0.5,0.18942307125336327,0
"  In this paper, a new hybrid algorithm which combines both of token-based andcharacter-based approaches is presented. The basic Levenshtein approach hasbeen extended to token-based distance metric. The distance metric is enhancedto set the proper granularity level behavior of the algorithm. It smoothly mapsa threshold of misspellings differences at the character level, and theimportance of token level errors in terms of token's position and frequency.Using a large Arabic dataset, the experimental results show that the proposedalgorithm overcomes successfully many types of errors such as: typographicalerrors, omission or insertion of middle name components, omission ofnon-significant popular name components, and different writing styles charactervariations. When compared the results with other classical algorithms, usingthe same dataset, the proposed algorithm was found to increase the minimumsuccess level of best tested algorithms, while achieving higher upper limits .",A Hybrid Algorithm for Matching Arabic Names,A Hybrid Algorithm for Cross-Distance Distance Metric,0.5333333333333333,0.41113361690051975,0
"  Segmentation of retinal vessels from retinal fundus images is the key step inthe automatic retinal image analysis. In this paper, we propose a newunsupervised automatic method to segment the retinal vessels from retinalfundus images. Contrast enhancement and illumination correction are carried outthrough a series of image processing steps followed by adaptive histogramequalization and anisotropic diffusion filtering. This image is then convertedto a gray scale using weighted scaling. The vessel edges are enhanced byboosting the detail curvelet coefficients. Optic disk pixels are removed beforeapplying fuzzy C-mean classification to avoid the misclassification.Morphological operations and connected component analysis are applied to obtainthe segmented retinal vessels. The performance of the proposed method isevaluated using DRIVE database to be able to compare with other state-of-artsupervised and unsupervised methods. The overall segmentation accuracy of theproposed method is 95.18% which outperforms the other algorithms.",Automatic Segmentation of Retinal Vasculature,"Segmentation of Retinal Vessels from Retinal Fundus Images using
  Adaptive Hist",0.37499999999999994,0.27901593935858265,0
"  The memory model for RISC-V, a newly developed open source ISA, has not beenfinalized yet and thus, offers an opportunity to evaluate existing memorymodels. We believe RISC-V should not adopt the memory models of POWER or ARM,because their axiomatic and operational definitions are too complicated. Wepropose two new weak memory models: WMM and WMM-S, which balance definitionalsimplicity and implementation flexibility differently. Both allow allinstruction reorderings except overtaking of loads by a store. We show thatthis restriction has little impact on performance and it considerablysimplifies operational definitions. It also rules out the out-of-thin-airproblem that plagues many definitions. WMM is simple (it is similar to theAlpha memory model), but it disallows behaviors arising due to shared storebuffers and shared write-through caches (which are seen in POWER processors).WMM-S, on the other hand, is more complex and allows these behaviors. We givethe operational definitions of both models using Instantaneous InstructionExecution (I2E), which has been used in the definitions of SC and TSO. We alsoshow how both models can be implemented using conventional cache-coherentmemory systems and out-of-order processors, and encompasses the behaviors ofmost known optimizations.","Weak Memory Models: Balancing Definitional Simplicity and Implementation
  Flexibility",A Review of Weak Memory Models for RISC-V,0.3333333333333333,0.38363982298032945,0
"  Large-scale data collection by means of wireless sensor network andinternet-of-things technology poses various challenges in view of thelimitations in transmission, computation, and energy resources of theassociated wireless devices. Compressive data gathering based on compressedsensing has been proven a well-suited solution to the problem. Existing designsexploit the spatiotemporal correlations among data collected by a specificsensing modality. However, many applications, such as environmental monitoring,involve collecting heterogeneous data that are intrinsically correlated. Inthis study, we propose to leverage the correlation from multiple heterogeneoussignals when recovering the data from compressive measurements. To this end, wepropose a novel recovery algorithm---built upon belief-propagationprinciples---that leverages correlated information from multiple heterogeneoussignals. To efficiently capture the statistical dependencies among diversesensor data, the proposed algorithm uses the statistical model of copulafunctions. Experiments with heterogeneous air-pollution sensor measurementsshow that the proposed design provides significant performance improvementsagainst state-of-the-art compressive data gathering and recovery schemes thatuse classical compressed sensing, compressed sensing with side information, anddistributed compressed sensing.","Heterogeneous Networked Data Recovery from Compressive Measurements
  Using a Copula Prior","A Belief-Propagation-Based Recovery Algorithm for Compressive
  Data Gathering",0.1904761904761905,0.5378329261427206,0
"  In this note, analysis of time delay systems using Lambert W functionapproach is reassessed. A common canonical form of time delay systems isdefined. We extended the recent results of [6] for second order into nth ordersystem. The eigenvalues of a time delay system are either real or complexconjugate pairs and therefore, the whole eigenspectrum can be associated withonly two real branches of the Lambert W function. A new class of time delaysystems is characterized to extend the applicability of the above said method.A state variable transformation is used to transform the proposed class ofsystems into the common canonical form. Moreover, this approach has beenexploited to design a controller which places a subset of eigenvalues atdesired locations. Stability is analyesed by the help of Nyquist plot. Theapproach is validated through an example.",Analysis of higher order time delay systems using Lambert W function,A New Class of Time Delay Systems Using Lambert W Function,0.7272727272727273,0.4063798282013443,0
"  A time-dependent Hermite-Galerkin spectral method (THGSM) is investigated inthis paper for the nonlinear convection-diffusion equations in the unboundeddomains. The time-dependent scaling factor and translating factor areintroduced in the definition of the generalized Hermite functions (GHF). As aconsequence, the THGSM based on these GHF has many advantages, not only intheorethical proofs, but also in numerical implementations. The stability andspectral convergence of our proposed method have been established in thispaper. The Korteweg-de Vries-Burgers (KdVB) equation and its special cases,including the heat equation and the Burgers' equation, as the examples, havebeen numerically solved by our method. The numerical results are presented, andit surpasses the existing methods in accuracy. Our theoretical proof of thespectral convergence has been supported by the numerical results.",Time-dependent Hermite-Galerkin spectral method and its applications,"Time-dependent Hermite-Galerkin spectral method for the nonlinear
  convection",0.631578947368421,0.345720784641941,0
"  Many natural language processing (NLP) applications require the computationof similarities between pairs of syntactic or semantic trees. Many researchershave used tree edit distance for this task, but this technique suffers from thedrawback that it deals with single node operations only. We have extended thestandard tree edit distance algorithm to deal with subtree transformationoperations as well as single nodes. The extended algorithm with subtreeoperations, TED+ST, is more effective and flexible than the standard algorithm,especially for applications that pay attention to relations among nodes (e.g.in linguistic trees, deleting a modifier subtree should be cheaper than the sumof deleting its components individually). We describe the use of TED+ST forchecking entailment between two Arabic text snippets. The preliminary resultsof using TED+ST were encouraging when compared with two string-based approachesand with the standard algorithm.","Natural Language Inference for Arabic Using Extended Tree Edit Distance
  with Subtrees","Toward Extending the Tree Edit Distance Algorithm for Arabic Text
  Fragmentation",0.34782608695652173,0.32035587991208064,0
"  Starting from a finite family of continuously differentiable positivedefinite functions, we study conditions under which a function obtained bymax-min combinations is a Lyapunov function, establishing stability for twokinds of nonlinear dynamical systems: a) Differential inclusions where theset-valued right-hand-side comprises the convex hull of a finite number ofvector fields, and b) Autonomous switched systems with a state-dependentswitching signal. We investigate generalized notions of directional derivativesfor these max-min functions, and use them in deriving stability conditions withvarious degrees of conservatism, where more conservative conditions arenumerically more tractable. The proposed constructions also provide nonconvexLyapunov functions, which are shown to be useful for systems withstate-dependent switching that do not admit a convex Lyapunov function. Severalexamples are included to illustrate the results.","Max-Min Lyapunov Functions for Switched Systems and Related Differential
  Inclusions","Stability conditions for nonlinear dynamical systems with
  convex Lyapunov functions",0.1904761904761905,0.668740304976422,0
"  In a recent paper by A. Chambolle et al. [Geometric properties of solutionsto the total variation denoising problem. Inverse Problems 33, 2017] it wasproven that if the subgradient of the total variation at the noise free data isnot empty, the level-sets of the total variation denoised solutions converge tothe level-sets of the noise free data with respect to the Hausdorff distance.The condition on the subgradient corresponds to the source condition introducedby Burger and Osher [Convergence rates of convex variational regularization.Inverse Problems 20, 2004], who proved convergence rates results with respectto the Bregman distance under this condition. We generalize the result ofChambolle et al. to total variation regularization of general linear inverseproblems under such a source condition. As particular applications we presentdenoising in bounded and unbounded, convex and non convex domains, deblurringand inversion of the circular Radon transform. In all these examples theconvergence result applies. Moreover, we illustrate the convergence behaviorthrough numerical examples.","A note on convergence of solutions of total variation regularized linear
  inverse problems","Convergence rates of convex variational regularization of linear
  inverse problems",0.608695652173913,0.2543188384279892,0
"  Fine management of chiral processes on solid surfaces has progressed over theyears, yet still faces the need for the controlled and selective production ofadvanced chiral materials. Here, we report on the use of enantiomericallyenriched molecular building blocks to demonstrate the transmission of theirintrinsic chirality along a sequence of on-surface reactions. Triggered bythermal annealing, the on-surface reac-tions induced in this experiment involvefirstly the coupling of the chiral reactants into chiral polymers andsubsequently their transformation into planar prochiral graphene nanoribbons.Our study reveals that the axial chirality of the reactant is not onlytransferred to the polymers, but also to the planar chirality of the graphenenanoribbon end products. Such chirality transfer consequently allows, startingfrom ad-equate enantioenriched reactants, for the controlled production ofchiral and prochiral organic nanoarchi-tectures with pre-defined handedness.","Transferring Axial Molecular Chirality Through a Sequence of On-Surface
  Reactions",On-surface reac-tions of chiral and prochiral organic nanoribbons,0.1904761904761905,0.4630777161991027,0
"  Deep learning revolutionized data science, and recently its popularity hasgrown exponentially, as did the amount of papers employing deep networks.Vision tasks, such as human pose estimation, did not escape from this trend.There is a large number of deep models, where small changes in the networkarchitecture, or in the data pre-processing, together with the stochasticnature of the optimization procedures, produce notably different results,making extremely difficult to sift methods that significantly outperformothers. This situation motivates the current study, in which we perform asystematic evaluation and statistical analysis of vanilla deep regression, i.e.convolutional neural networks with a linear regression top layer. This is thefirst comprehensive analysis of deep regression techniques. We performexperiments on four vision problems, and report confidence intervals for themedian performance as well as the statistical significance of the results, ifany. Surprisingly, the variability due to different data pre-processingprocedures generally eclipses the variability due to modifications in thenetwork architecture. Our results reinforce the hypothesis according to which,in general, a general-purpose network (e.g. VGG-16 or ResNet-50) adequatelytuned can yield results close to the state-of-the-art without having to resortto more complex and ad-hoc regression models.",A Comprehensive Analysis of Deep Regression,A Statistical Analysis of Deep Regression Techniques,0.7692307692307692,0.4347208719449914,0
"  William Shakespeare is believed to be a significant author in the anonymousplay, The Reign of King Edward III, published in 1596. However, recently,Thomas Kyd, has been suggested as the primary author. Using a neurolinguisticsapproach to authorship identification we use a four-feature technique, RPAS, toconvert the 19 scenes in Edward III into a multi-dimensional vector. Threecomplementary analytical techniques are applied to cluster the data and reducesingle technique bias before an alternate method, seriation, is used to measurethe distances between clusters and test the strength of the connections. Wefind the multivariate techniques robust and are able to allocate up to 14scenes to Thomas Kyd, and further question if scenes long believed to beShakespeare's are not his.",Did William Shakespeare and Thomas Kyd Write Edward III?,RPIAS: A multi-feature approach to authorship identification,0.0,0.0,0
"  For many years, we have observed industry struggling in defining a highquality requirements engineering (RE) and researchers trying to understandindustrial expectations and problems. Although we are investigating thediscipline with a plethora of empirical studies, they still do not allow forempirical generalisations. To lay an empirical and externally valid foundationabout the state of the practice in RE, we aim at a series of open andreproducible surveys that allow us to steer future research in a problem-drivenmanner. We designed a globally distributed family of surveys in jointcollaborations with different researchers and completed the first run inGermany. The instrument is based on a theory in the form of a set of hypothesesinferred from our experiences and available studies. We test each hypothesis inour theory and identify further candidates to extend the theory by correlationand Grounded Theory analysis. In this article, we report on the design of thefamily of surveys, its underlying theory, and the full results obtained fromGermany with participants from 58 companies. The results reveal, for example, atendency to improve RE via internally defined qualitative methods rather thanrelying on normative approaches like CMMI. We also discovered various REproblems that are statistically significant in practice. For instance, we couldcorroborate communication flaws or moving targets as problems in practice. Ourresults are not yet fully representative but already give first insights intocurrent practices and problems in RE, and they allow us to draw lessons learntfor future replications. Our results obtained from this first run in Germanymake us confident that the survey design and instrument are well-suited to bereplicated and, thereby, to create a generalisable empirical basis of RE inpractice.","Naming the Pain in Requirements Engineering: A Design for a Global
  Family of Surveys and First Results from Germany",A Global Family of Surveys for High Quality Requirements Engineering,0.3448275862068966,0.12283995672519586,0
"  We revisit recent results from the area of collusion-resistant traitortracing, and show how they can be combined and improved to obtain moreefficient dynamic traitor tracing schemes. In particular, we show how thedynamic Tardos scheme of Laarhoven et al. can be combined with the optimizedscore functions of Oosterwijk et al. to trace coalitions much faster. If theattack strategy is known, in many cases the order of the code length goes downfrom quadratic to linear in the number of colluders, while if the attack is notknown, we show how the interleaving defense may be used to catch all colludersabout twice as fast as in the dynamic Tardos scheme. Some of these results alsoapply to the static traitor tracing setting where the attack strategy is knownin advance, and to group testing.","Dynamic Traitor Tracing Schemes, Revisited",A Review of Traitor Tracing in Dynamic Tardos Scheme,0.42857142857142855,0.45180100180492244,0
"  The m-Tamari lattice of F. Bergeron is an analogue of the clasical Tamariorder defined on objects counted by Fuss-Catalan numbers, such as m-Dyck pathsor (m+1)-ary trees. On another hand, the Tamari order is related to the productin the Loday-Ronco Hopf algebra of planar binary trees. We introduce newcombinatorial Hopf algebras based on (m+1)-ary trees, whose structure isdescribed by the m-Tamari lattices.  In the same way as planar binary trees can be interpreted as sylvesterclasses of permutations, we obtain (m+1)-ary trees as sylvester classes of whatwe call m-permutations. These objects are no longer in bijection withdecreasing (m+1)-ary trees, and a finer congruence, called metasylvester,allows us to build Hopf algebras based on these decreasing trees. At theopposite, a coarser congruence, called hyposylvester, leads to Hopf algebras ofgraded dimensions (m+1)^{n-1}, generalizing noncommutative symmetric functionsand quasi-symmetric functions in a natural way. Finally, the algebras of packedwords and parking functions also admit such m-analogues, and we present theirsubalgebras and quotients induced by the various congruences.","Hopf Algebras of m-permutations, (m+1)-ary trees, and m-parking
  functions",Hopf algebras based on (m+1)-ary trees,0.5714285714285714,0.4608636396914616,0
"  Machine learning software is increasingly being used to make decisions thataffect people's lives. But sometimes, the core part of this software (thelearned model), behaves in a biased manner that gives undue advantages to aspecific group of people (where those groups are determined by sex, race,etc.). This ""algorithmic discrimination"" in the AI software systems has becomea matter of serious concern in the machine learning and software engineeringcommunity. There have been works done to find ""algorithmic bias"" or ""ethicalbias"" in the software system. Once the bias is detected in the AI softwaresystem, the mitigation of bias is extremely important. In this work, wea)explain how ground-truth bias in training data affects machine learning modelfairness and how to find that bias in AI software,b)propose amethodFairwaywhich combines pre-processing and in-processing approach to removeethical bias from training data and trained model. Our results show that we canfind bias and mitigate bias in a learned model, without much damaging thepredictive performance of that model. We propose that (1) test-ing for bias and(2) bias mitigation should be a routine part of the machine learning softwaredevelopment life cycle. Fairway offers much support for these two purposes.",Fairway: A Way to Build Fair ML Software,Fairness in Machine Learning: A Case Study,0.13333333333333333,0.5329462628216854,0
"  In the symmetron mechanism, the fifth force mediated by a coupled scalarfield (the symmetron) is suppressed in high-density regions due to therestoration of symmetry in the symmetron potential. In this paper we study thebackground cosmology and large scale structure formation in the linearperturbation regime of the symmetron model. Analytic solutions to the symmetronin the cosmological background are found, which agree well with numericalresults. We discuss the effect of the symmetron perturbation on the growth ofmatter perturbation, in particular the implications of the brief period oftachyonic instability caused by the negative mass squared of the symmetronduring symmetry breaking. Our analysis and numerical results show that thisinstability has only very small effects on the growth of structures onsub-horizon scales, and even at horizon scales its influence is not as drasticas naively expected. The symmetron fifth force in the non-tachyonic regime doesaffect the formation of structure in a nontrivial way which could becosmologically observable.",Linear Growth of Structure in the Symmetron Model,Large scale structure formation in the symmetron model,0.625,0.43472087194499137,0
"  In this paper we consider second order optimality conditions for a bilinearoptimal control problem governed by a strongly continuous semigroup operator,the control entering linearly in the cost function. We derive first and secondorder optimality conditions, taking advantage of the Goh transform. We thenapply the results to the heat and wave equations.","Optimal control of infinite dimensional bilinear systems: Application to
  the heat and wave equations",Second order optimality conditions for bilinear optimal control problems,0.17391304347826086,0.3939328149130935,0
"  We consider a certain extension of the Einstein's elevator thought experimentby assuming that the elevator is charged and falls into an electromagneticfield. We argue, on grounds of the Equivalence Principle, that anobserver-dependent metric should exist, for which the geodesics coincide withthe trajectories of the charged body in the electromagnetic field. We give asolution to this problem by finding such a metric and hence we are able torecover the Lorentz-force law. Recovery of the leading terms of the radiationreaction force is also possible with this approach.",On the Equivalence Principle and Electrodynamics of Moving Bodies,Einstein's Elevator in an Electromagnetic Field,0.0,0.0,0
"  We give an algorithm for computing the V-saturation of any finitely-generatedsubmodule of a power of V[X], where V is a valuation domain. Our algorithm isbased on a notion of ""echelon form"" which ensures its correctness. This allowsus to compute a finite system of generators for the syzygy module of anyfinitely generated submodule of a power of V[X].","An algorithm for computing syzygies on $V[X]$ when $V$ is a valuation
  domain","A finite system of generators for the syzygy module of a power of
  V[",0.21428571428571427,0.6147881529512643,0
  Theoretical Raman line shape functions have been studied to take care ofquantum confinement effect and Fano effect individually and jointly. Thecharacteristics of various Raman line shapes have been studied in terms of thebroadening and asymmetry of Raman line shapes. It is shown that the asymmetryin the Raman line-shape function caused by these two effects individually doesnot add linearly to give asymmetry of line-shape generated by considering thecombined effect. This indicates existence of interplay between the two effects.The origin of interplay lies in the fact that Fano effect itself depends onquantum confinement effect and in turn provides an asymmetry. This can not beexplained by considering the two effects contribution independent of eachother.,"Interplay between Phonon Confinement and Fano Effect on Raman line shape
  for semiconductor nanostructures: Analytical study",Theoretical Raman Line Shape Functions,0.2857142857142857,0.07409853791557794,0
"  Automated random testing has shown to be an effective approach to findingfaults but still faces a major unsolved issue: how to generate test inputsdiverse enough to find many faults and find them quickly. Stateful testing, theautomated testing technique introduced in this article, generates new testcases that improve an existing test suite. The generated test cases aredesigned to violate the dynamically inferred contracts (invariants)characterizing the existing test suite. As a consequence, they are in a goodposition to detect new errors, and also to improve the accuracy of the inferredcontracts by discovering those that are unsound. Experiments on 13 datastructure classes totalling over 28,000 lines of code demonstrate theeffectiveness of stateful testing in improving over the results of longsessions of random testing: stateful testing found 68.4% new errors andimproved the accuracy of automatically inferred contracts to over 99%, withjust a 7% time overhead.",Stateful Testing: Finding More Errors in Code and Contracts,"Stateful Testing: Improving the accuracy of dynamically inferred
  contracts",0.3333333333333333,0.408248290463863,0
"  Five single-phase WB2- and MoB2-containing high-entropy borides (HEBs) havebeen made via reactive spark plasma sintering of elemental boron and metals. Alarge reactive driving force enables the full dissolution of 10-20 mol. % WB2to form dense, single-phase HEBs, including (Ti0.2Zr0.2Hf0.2Mo0.2W0.2)B2,(Ti0.2Ta0.2Cr0.2Mo0.2W0.2)B2, (Zr0.2Hf0.2Nb0.2Ta0.2W0.2)B2, and(Zr0.225Hf0.225Ta0.225Mo0.225W0.1)B2; the successful fabrication of suchsingle-phase WB2-containing HEBs has not been reported before. In theprocessing science, this result serves perhaps the best example demonstratingthat the phase formation in high-entropy ceramics can strongly depend on thekinetic route. A scientifically interesting finding is that HEBs containingsofter WB2 and/or MoB2 components are significantly harder than(Ti0.2Zr0.2Hf0.2Nb0.2Ta0.2)B2 (with harder binary boride components). Thisexemplifies that high-entropy ceramics can achieve unexpected properties.","Dissolving and Stabilizing Soft WB2 and MoB2 Phases into High-Entropy
  Borides via Boron-Metals Reactive Sintering to Attain Higher Hardness",Single-Phase Production of High-Entropy Borides in High-Energy Ceramics,0.25,0.10991464955045857,0
"  In this work, we study the fractal and multifractal properties of a family offractal networks introduced by Gallos {\it et al.} ({\it Proc. Natl. Acad. Sci.U.S.A.}, 2007, {\bf 104}: 7746). In this fractal network model, there is aparameter $e$ which is between $0$ and $1$, and allows for tuning the level offractality in the network. Here we examine the multifractal behavior of thesenetworks, dependence relationship of fractal dimension and the multifractalparameters on the parameter $e$. First, we find that the empirical fractaldimensions of these networks obtained by our program coincide with thetheoretical formula given by Song {\it et al.} ( {\it Nat. Phys}, 2006, {\bf2}: 275). Then from the shape of the $\tau(q)$ and $D(q)$ curves, we find theexistence of multifractality in these networks. Last, we find that there existsa linear relationship between the average information dimension $<D(1)>$ andthe parameter $e$.",Fractal and multifractal properties of a family of fractal networks,Fractal and multifractal properties of a family of offractal networks,0.9,0.7825422900366437,0
"  The field of Artificial Intelligence (AI) and, in particular, the MachineLearning area, counts on a wide range of performance metrics and benchmark datasets to assess the problem-solving effectiveness of its solutions. However, theappearance of research centres, projects or institutions addressing AIsolutions from a multidisciplinary and multi-stakeholder perspective suggests anew approach to assessment comprising ethical guidelines, reports or tools andframeworks to help both academia and business to move towards a responsibleconceptualisation of AI. They all highlight the relevance of three key aspects:(i) enhancing cooperation among the different stakeholders involved in thedesign, deployment and use of AI; (ii) promoting multidisciplinary dialogue,including different domains of expertise in this process; and (iii) fosteringpublic engagement to maximise a trusted relation with new technologies andpractitioners. In this paper, we introduce the Observatory on Society andArtificial Intelligence (OSAI), an initiative grew out of the project AI4EUaimed at stimulating reflection on a broad spectrum of issues of AI (ethical,legal, social, economic and cultural). In particular, we describe our work inprogress around OSAI and suggest how this and similar initiatives can promote awider appraisal of progress in AI. This will give us the opportunity to presentour vision and our modus operandi to enhance the implementation of these threefundamental dimensions.",Progressing Towards Responsible AI,"The Observatory on Society andArtificial Intelligence: A multidisciplinary and
  multi-st",0.0,0.0,0
"  The first purpose of our paper is to show how Hooley's celebrated methodleading to his conditional proof of the Artin conjecture on primitive roots canbe combined with the Hardy-Littlewood circle method. We do so by studying thenumber of representations of an odd integer as a sum of three primes, all ofwhich have prescribed primitive roots.  The second purpose is to analyse the singular series. In particular, usingresults of Lenstra, Stevenhagen and Moree, we provide a partial factorisationas an Euler product and prove that this does not extend to a completefactorisation.","Vinogradov's three primes theorem with primes having given primitive
  roots",Hooley's method leading to the Artin conjecture on primitive roots,0.2727272727272727,0.3860973950960897,0
"  We consider the ordering dynamics of the Ising model on a square latticewhere an additional fixed number of bonds connect any two sites chosenrandomly. The total number of shortcuts added is controlled by two parameters$p$ and $\alpha$. The structural properties of the network are investigatedwhich show that that the small world behaviour is obtained along the line$\alpha=\frac{\ln (N/2p)}{\ln N}$, which separates regions with ultra smallworld like behaviour and short ranged lattice like behaviour. We obtain a richphase diagram in the $p-\alpha$ plane showing the existence of different typesof active and absorbing states to which Ising model evolves and theirboundaries.","Active-absorbing phase transition and small world behaviour in Ising
  model on finite addition type networks in two dimensions",Order dynamics of Ising model on a square lattice,0.21428571428571427,0.12151662434083678,0
"  Using holography, we study the entanglement entropy of strongly coupled fieldtheories perturbed by operators that trigger an RG flow from a conformal fieldtheory in the ultraviolet (UV) to a new theory in the infrared (IR). Theholographic duals of such flows involve a geometry that has the UV and IRregions separated by a transitional structure in the form of a domain wall. Weaddress the question of how the geometric approach to computing theentanglement entropy organizes the field theory data, exposing key features asthe change in degrees of freedom across the flow, how the domain wall acts as aUV region for the IR theory, and a new area law controlled by the domain wall.Using a simple but robust model we uncover this organization, and expect muchof it to persist in a wide range of holographic RG flow examples. We test ourformulae in two known examples of RG flow in 3+1 and 2+1 dimensions thatconnect non-trivial fixed points.",Holographic Entanglement Entropy and Renormalization Group Flow,"Holography and the entanglement entropy of strongly coupled field
  theories",0.23529411764705882,0.5623413251903491,0
"  We study the Hamiltonian formulation of f(R) theories of gravity both inmetric and in Palatini formalism using their classical equivalence withBrans-Dicke theories with a non-trivial potential. The Palatini case, whichcorresponds to the w=-3/2 Brans-Dicke theory, requires special attentionbecause of new constraints associated with the scalar field, which isnon-dynamical. We derive, compare, and discuss the constraints and evolutionequations for the ww=-3/2 and w\neq -3/2 cases. Based on the properties of theconstraint and evolution equations, we find that, contrary to certain claims inthe literature, the Cauchy problem for the w=-3/2 case is well-formulated andthere is no reason to believe that it is not well-posed in general.",Hamiltonian Formulation of Palatini f(R) theories a la Brans-Dicke,Hamiltonian formulation of f(R) theories of gravity,0.631578947368421,0.41746352657471425,0
"  The geometric flow theory and its applications turned into one of the mostintensively developing branches of modern geometry. Here, a brief introductionto Finslerian Ricci flow and their self-similar solutions known as Riccisolitons are given and some recent results are presented. They are ageneralization of Einstein metrics and are previously developed by the presentauthors for Finsler manifolds. In the present work, it is shown that a completeshrinking Ricci soliton Finsler manifold has a finite fundamental group.",Complete Ricci solitons on Finsler manifolds,Finslerian Ricci flow and their self-similar solutions,0.14285714285714288,0.6147881529512643,0
"  The pseudoachromatic index of a graph is the maximum number of colors thatcan be assigned to its edges, such that each pair of different colors isincident to a common vertex. If for each vertex its incident edges havedifferent color, then this maximum is known as achromatic index. Both indiceshave been widely studied. A geometric graph is a graph drawn in the plane suchthat its vertices are points in general position, and its edges arestraight-line segments. In this paper we extend the notion of pseudoachromaticand achromatic indices for geometric graphs, and present results for completegeometric graphs. In particular, we show that for $n$ points in convex positionthe achromatic index and the pseudoachromatic index of the complete geometricgraph are $\lfloor \tfrac{n^2+n}{4} \rfloor$.",Geometric achromatic and pseudoachromatic indices,Pseudoachromatic and achromatic indices for complete geometric graphs,0.3076923076923077,0.7825422900366437,0
"  We prove the chain rule in the more general framework of the Wiener-Poissonspace, allowing us to obtain the so-called Nourdin-Peccati bound. From thisbound we obtain a second-order Poincare-type inequality that is useful in termsof computations. For completeness we survey these results on the Wiener space,the Poisson space, and the Wiener-Poisson space. We also give severalapplications to central limit theorems with relevant examples: linearfunctionals of Gaussian subordinated fields (where the subordinated field canbe processes like fractional Brownian motion or the solution of theOrnstein-Uhlenbeck SDE driven by fractional Brownian motion), Poissonfunctionals in the first Poisson chaos restricted to infinitely many \small""jumps (particularly fractional Levy processes) and the product of twoOrnstein-Uhlenbeck processes (one in the Wiener space and the other in thePoisson space). We also obtain bounds for their rate of convergence tonormality.","Normal Convergence Using Malliavin Calculus With Applications and
  Examples",Chain rule in the Wiener-Poisson space,0.0,0.0,0
"  We prove improved inapproximability results for hypergraph coloring using thelow-degree polynomial code (aka, the 'short code' of Barak et. al. [FOCS 2012])and the techniques proposed by Dinur and Guruswami [FOCS 2013] to incorporatethis code for inapproximability results. In particular, we provequasi-NP-hardness of the following problems on $n$-vertex hyper-graphs:  * Coloring a 2-colorable 8-uniform hypergraph with$2^{2^{\Omega(\sqrt{\log\log n})}}$ colors.  * Coloring a 4-colorable 4-uniform hypergraph with$2^{2^{\Omega(\sqrt{\log\log n})}}$ colors.  * Coloring a 3-colorable 3-uniform hypergraph with $(\logn)^{\Omega(1/\log\log\log n)}$ colors.  In each of these cases, the hardness results obtained are (at least)exponentially stronger than what was previously known for the respective cases.In fact, prior to this result, polylog n colors was the strongest quantitativebound on the number of colors ruled out by inapproximability results forO(1)-colorable hypergraphs.  The fundamental bottleneck in obtaining coloring inapproximability resultsusing the low- degree long code was a multipartite structural restriction inthe PCP construction of Dinur-Guruswami. We are able to get around thisrestriction by simulating the multipartite structure implicitly by queryingjust one partition (albeit requiring 8 queries), which yields our result for2-colorable 8-uniform hypergraphs. The result for 4-colorable 4-uniformhypergraphs is obtained via a 'query doubling' method. For 3-colorable3-uniform hypergraphs, we exploit the ternary domain to design a test with anadditive (as opposed to multiplicative) noise function, and analyze itsefficacy in killing high weight Fourier coefficients via the pseudorandomproperties of an associated quadratic form.","Super-polylogarithmic hypergraph coloring hardness via low-degree long
  codes",A note on inapproximability results for hypergraph coloring,0.22222222222222224,0.43472087194499137,0
"  In this paper, we propose quantum circuits for runtime assertions, which canbe used for both software debugging and error detection. Runtime assertion ischallenging in quantum computing for two key reasons. First, a quantum bit(qubit) cannot be copied, which is known as the non-cloning theorem. Second,when a qubit is measured, its superposition state collapses into a classicalstate, losing the inherent parallel information. In this paper, we overcomethese challenges with runtime computation through ancilla qubits, which areused to indirectly collect the information of the qubits of interest. We designquantum circuits to assert classical states, entanglement, and superpositionstates.",Quantum Circuits for Dynamic Runtime Assertions in Quantum Computation,Quantum circuits for runtime assertions,0.7142857142857143,0.35733817274964674,0
"  We propose moving all the $\gamma_{5}$ matrices to the rightmost positionbefore continuing the dimension, and show that this simple prescription willenable the dimension regularization scheme proposed by 't Hooft and Veltman tobe consistent with gauge invariance.","Gauge Invariant Treatment of $\gamma_{5}$ in the Scheme of 't Hooft and
  Veltman",On the dimension regularization of $\gamma_{5}$ matrices,0.2727272727272727,0.21938936848339244,0
"  This article is concerned with automating the decreasing diagrams techniqueof van Oostrom for establishing confluence of term rewrite systems. We studyabstract criteria that allow to lexicographically combine labelings to showlocal diagrams decreasing. This approach has two immediate benefits. First, itallows to use labelings for linear rewrite systems also for left-linear ones,provided some mild conditions are satisfied. Second, it admits an incrementalmethod for proving confluence which subsumes recent developments in automatingdecreasing diagrams. The techniques proposed in the article have beenimplemented and experimental results demonstrate how, e.g., the rule labelingbenefits from our contributions.",Labelings for Decreasing Diagrams,"Automating the decreasing diagrams technique for establishing confluence of
  term rewrite systems",0.25,0.537284965911771,0
"  We investigate quasi-Monte Carlo (QMC) integration over the $s$-dimensionalunit cube based on rank-1 lattice point sets in weighted non-periodic Sobolevspaces $\mathcal{H}(K_{\alpha,\boldsymbol{\gamma},s}^{\mathrm{sob}})$ and theirsubspaces of high order smoothness $\alpha>1$, where $\boldsymbol{\gamma}$denotes a set of the weights. A recent paper by Dick, Nuyens and Pillichshammerhas studied QMC integration in half-period cosine spaces with smoothnessparameter $\alpha>1/2$ consisting of non-periodic smooth functions, denoted by$\mathcal{H}(K_{\alpha,\boldsymbol{\gamma},s}^{\mathrm{cos}})$, and also in thesum of half-period cosine spaces and Korobov spaces with common parameter$\alpha$, denoted by$\mathcal{H}(K_{\alpha,\boldsymbol{\gamma},s}^{\mathrm{kor}+\mathrm{cos}})$.Motivated by the results shown there, we first study embeddings and normequivalences on those function spaces. In particular, for an integer $\alpha$,we provide their corresponding norm-equivalent subspaces of$\mathcal{H}(K_{\alpha,\boldsymbol{\gamma},s}^{\mathrm{sob}})$. This impliesthat$\mathcal{H}(K_{\alpha,\boldsymbol{\gamma},s}^{\mathrm{kor}+\mathrm{cos}})$ isstrictly smaller than$\mathcal{H}(K_{\alpha,\boldsymbol{\gamma},s}^{\mathrm{sob}})$ as sets for$\alpha \geq 2$, which solves an open problem by Dick, Nuyens andPillichshammer. Then we study the worst-case error of tent-transformed latticerules in $\mathcal{H}(K_{2,\boldsymbol{\gamma},s}^{\mathrm{sob}})$ and also theworst-case error of symmetrized lattice rules in an intermediate space between$\mathcal{H}(K_{\alpha,\boldsymbol{\gamma},s}^{\mathrm{kor}+\mathrm{cos}})$ and$\mathcal{H}(K_{\alpha,\boldsymbol{\gamma},s}^{\mathrm{sob}})$. We show thatthe almost optimal rate of convergence can be achieved for both cases, while aweak dependence of the worst-case error bound on the dimension can be obtainedfor the former case.",Lattice rules in non-periodic subspaces of Sobolev spaces,Quasi-Monte Carlo integration over the $s$-dimensional unit cube,0.0,0.0,0
"  The article describes the identification of hadronically decaying tau leptonsin ppbar collisions at 1.96 TeV collected by the DZero detector at the FermilabTevatron. After a brief description of the motivations and the challenges ofconsidering tau leptons in high energy hadronic collisions, details of the taureconstruction and identification will be discussed. The challenges associatedfor tau energy measurements in an hadronic environment will be presentedincluding approaches to deal with such measurements.",Identification of tau leptons at the DZero experiment,Tau leptons in ppbar collisions at 1.96 TeV,0.35294117647058826,0.7071067811865476,0
"  We present a short proof of the Church-Rosser property for thelambda-calculus enjoying two distinguishing features: Firstly, it employs theZ-property, resulting in a short and elegant proof; and secondly, it isformalized in the nominal higher-order logic available for the proof assistantIsabelle/HOL.","A Short Mechanized Proof of the Church-Rosser Theorem by the Z-property
  for the $\lambda\beta$-calculus in Nominal Isabelle",A short proof of the Church-Rosser property for the lambda-calculus,0.7272727272727273,0.19745987822060074,0
"  In order to identify potential hydrogen storage materials, worldwideattention has been focused on hydrides with high gravimetric and volumetriccapacity. Hydrogen is a unique element that possess positive, negative orneutral oxidation state in solids depending upon the chemical environment. Ifone can find hydrogen storage materials where hydrogen is present in bothnegative and positive oxidation state within the same structural framework thenone can accommodate hydrogen with high volume density. So, it is fundamentallyas well as technologically important to identify compounds in which hydrogen isin amphoteric nature and understand the necessary criteria for its origin. Theexperimental structural analysis of Cyclotriborazane and Diammonium dodecahydro-closo-dodecaborate insinuate the presence of hydrogen with anionic andcationic behavior within the same structure. In order to understand the role ofvan der Waals (vdW) interactions on structural parameters, we have considered12 different vdW corrected functionals and found that the optPBE-vdW functionalpredicts the equilibrium structural parameters reliably with less than 0.009 %accuracy. So, the optPBE-vdW functional is used to calculate charge density,electron localization function, total as well as the partial density of state,Bader and Born effective charge etc. We have observed that hydrogen isexhibiting amphoteric behavior with H closer to B in the negatively chargedstate and that neighboring to N is in a positively charged state.","Amphoteric behavior of hydrogen (H+1and H-1) in complex hydrides from
  van der Waals interaction included ab-initio calculation","The role of van der Waals interactions on the structural parameters of
  hydrogen storage materials",0.28571428571428575,0.23827376217791343,0
"  Since its recent introduction, the small-world effect has been identified inseveral important real-world systems. Frequently, it is a consequence of theexistence of a few long-range connections, which dominate the original regularstructure of the systems and implies each node to become accessible from othernodes after a small number of steps, typically of order $\ell \propto \log N$.However, this effect has been observed in pure-topological networks, where thenodes have no spatial coordinates. In this paper, we present an alalogue ofsmall-world effect observed in real-world transportation networks, where thenodes are embeded in a hree-dimensional space. Using the multidimensionalscaling method, we demonstrate how the addition of a few long-range connectionscan suubstantially reduce the travel time in transportation systems. Also, weinvestigated the importance of long-range connections when the systems areunder an attack process. Our findings are illustrated for two real-worldsystems, namely the London urban network (streets and underground) and the UShighways network enhanced by some of the main US airlines routes.",Long-Range Connections in Transportation Networks,Small-World Effect in Real-World Transportation Networks,0.42857142857142855,0.5623413251903491,0
"  The implementation of effective protected areas is one of the central goalsof modern conservation biology. In the context of fisheries management andmarine ecosystem conservation, marine reserves often play a significant role toachieve sustainable fisheries management. Consequently, a substantial number ofstudies have been conducted to establish broad rules for the creation of MPAs,or to test the effects of MPAs in specific regions. However, there still existmany challenges for implementing MPAs that are effective at meeting theirgoals. Deducing theoretical conditions guaranteeing that the introduction ofmarine reserves will increase fisheries yields in age-structured populationdynamics is one such challenge. To derive such conditions, a simplemathematical model is developed that follows an age-structured metapopulationdynamics of a sedentary species. The obtained results suggest that asufficiently high fishing mortality rate and moderate recruitment success of anindividual's eggs is a necessary for marine reserves to increase fisheriesyields. The numerical calculations were conducted with the parameters of redabalone (Haliotis rufescens) to visualize and to check validity of theanalytical results. They show good agreement with the analytical results, aswell as the results obtained in the previous works.","Simple rules for establishment of effective marine protected areas in an
  age-structured metapopulation","A simple mathematical model for the introduction of marine reserves
  to increase fishery yields",0.2857142857142857,0.6803749333171202,0
"  Vision-based vehicle detection approaches achieve incredible success inrecent years with the development of deep convolutional neural network (CNN).However, existing CNN based algorithms suffer from the problem that theconvolutional features are scale-sensitive in object detection task but it iscommon that traffic images and videos contain vehicles with a large variance ofscales. In this paper, we delve into the source of scale sensitivity, andreveal two key issues: 1) existing RoI pooling destroys the structure of smallscale objects, 2) the large intra-class distance for a large variance of scalesexceeds the representation capability of a single network. Based on thesefindings, we present a scale-insensitive convolutional neural network (SINet)for fast detecting vehicles with a large variance of scales. First, we presenta context-aware RoI pooling to maintain the contextual information and originalstructure of small scale objects. Second, we present a multi-branch decisionnetwork to minimize the intra-class distance of features. These lightweighttechniques bring zero extra time complexity but prominent detection accuracyimprovement. The proposed techniques can be equipped with any deep networkarchitectures and keep them trained end-to-end. Our SINet achievesstate-of-the-art performance in terms of accuracy and speed (up to 37 FPS) onthe KITTI benchmark and a new highway dataset, which contains a large varianceof scales and extremely small objects.","SINet: A Scale-insensitive Convolutional Neural Network for Fast Vehicle
  Detection",Scale-Insensitive Convolutional Neural Network for Vehicle Detection,0.8421052631578948,0.31850355294022703,0
"  In this paper a definition is given for an unbounded Toeplitz-like operatorwith rational symbol which has poles on the unit circle. It is shown that theoperator is Fredholm if and only if the symbol has no zeroes on the unitcircle, and a formula for the index is given as well. Finally, a matrixrepresentation of the operator is discussed.","A Toeplitz-like operator with rational symbol having poles on the unit
  circle I: Fredholm properties",On Unbounded Toeplitz-like Operators with Rational Symbol,0.5,0.23315591526465868,0
"  This paper proposes a technique for automatic face recognition usingintegrated multiple feature sets extracted from the significant blocks of agradient image. We discuss about the use of novel morphological, localdirectional pattern (LDP) and gray-level co-occurrence matrix GLCM basedfeature extraction technique to recognize human faces. Firstly, the newmorphological features i.e., features based on number of runs of pixels in fourdirections (N,NE,E,NW) are extracted, together with the GLCM based statisticalfeatures and LDP features that are less sensitive to the noise andnon-monotonic illumination changes, are extracted from the significant blocksof the gradient image. Then these features are concatenated together. Weintegrate the above mentioned methods to take full advantage of the threeapproaches. Extraction of the significant blocks from the absolute gradientimage and hence from the original image to extract pertinent information withthe idea of dimension reduction forms the basis of the work. The efficiency ofour method is demonstrated by the experiment on 1100 images from the FRAV2Dface database, 2200 images from the FERET database, where the images vary inpose, expression, illumination and scale and 400 images from the ORL facedatabase, where the images slightly vary in pose. Our method has shown 90.3%,93% and 98.75% recognition accuracy for the FRAV2D, FERET and the ORL databaserespectively.","An adaptive block based integrated LDP,GLCM,and Morphological features
  for Face Recognition",Automatic Face Recognition using GLCM Based Features,0.2,0.26380128150117166,0
"  In this paper, we investigate the algebraic properties of the expectationsemirings which are semiring version of the concept of trivial extension inring theory. We discuss ideals, primes, maximals and primary ideals of thesesemirings. We also discuss the distinguished elements such as the units,idempotents, and zero-divisors of the expectations semirings. Similar to theircounterparts in ring theory, we introduce pr\'{e}simplifiable, domainlike,clean, almost clean, and weakly clean semiring and see when an expectationsemiring is one of these semirings.",Algebraic properties of expectation semirings,The algebraic properties of expectation semirings,0.9090909090909091,0.5081327481546147,0
"  Consistent interactions that can be added to a free, Abelian gauge theorycomprising a BF model and a finite set of massless real scalar fields areconstructed from the deformation of the solution to the master equation basedon specific cohomological techniques. Under the hypotheses of analyticity inthe coupling constant, Lorentz covariance, spacetime locality, Poincareinvariance, supplemented with the requirement on the preservation of the numberof derivatives on each field with respect to the free theory, we obtain thatthe deformation procedure leads to two classes of gauge-invariant interactingtheories with a mass term for the BF vector field $A_{\mu }$ with U(1) gaugeinvariance. In order to derive this result we have not used the Higgs mechanismbased on spontaneous symmetry breaking.",Gauge-invariant massive BF models,Consistent interactions in Abelian gauge theory,0.1818181818181818,0.0,0
"  We address the issue of evaluating chiral effects (such as the newlydiscovered chiral separation) in hydrodynamic approximation. The main tool weuse is effective theory which defines interaction in terms of chemicalpotentials $\mu,\mu_5$. In the lowest order in $\mu,\mu_5$ we reproduce recentresults based on thermodynamic considerations. In higher orders the resultsdepend on details of infrared cutoff. Another point of our interest is analternative way of the anomaly matching through introduction of effectivescalar fields arising in the hydrodynamic approximation.",Notes on chiral hydrodynamics within effective theory approach,Chiral effects in hydrodynamic approximation,0.3076923076923077,0.0,0
"  This paper introduces a symbolic calculus to evaluate the output signals atthe target line(s) of quantum computing subcircuits using controlled negationsand controlled-Q gates, where Q represents the k-th root of [0 1; 1 0], theunitary matrix of NOT, and k is a power of two. The controlling signals areGF(2) expressions possibly including Boolean expressions. The method does notrequire operating with complex-valued matrices. The method may be used toverify the functionality and to check for possible minimization of a givenquantum computing circuit using target lines. The method does not apply for awhole circuit if there are interactions among target lines. In this case themethod applies for the independent subcircuits.",A symbolic calculus for a class of quantum computing circuits,"Symbolic Evaluation of Output Signals in Quantum Computing
  Subcircuits",0.4210526315789474,0.5166357204442371,0
"  A complex symplectic structure on a Lie algebra $\lie h$ is an integrablecomplex structure $J$ with a closed non-degenerate $(2,0)$-form. It isdetermined by $J$ and the real part $\Omega$ of the $(2,0)$-form. Suppose that$\lie h$ is a semi-direct product $\lie g\ltimes V$, and both $\lie g$ and $V$are Lagrangian with respect to $\Omega$ and totally real with respect to $J$.This note shows that $\lie g\ltimes V$ is its own weak mirror image in thesense that the associated differential Gerstenhaber algebras controlling theextended deformations of $\Omega$ and $J$ are isomorphic. The geometry of$(\Omega, J)$ on the semi-direct product $\lie g\ltimes V$ is also shown to beequivalent to that of a torsion-free flat symplectic connection on the Liealgebra $\lie g$. By further exploring a relation between $(J, \Omega)$ withhypersymplectic algebras, we find an inductive process to build families ofcomplex symplectic algebras of dimension $8n$ from the data of the$4n$-dimensional ones.",Weak Mirror Symmetry of Complex Symplectic Algebras,On the weak mirror image of complex symplectic algebras,0.75,0.5773502691896257,0
"  Current models for software components have made component-based softwareengineering practical. However, these models are limited in the sense thattheir support for the characterization/specification of design componentsprimarily deals with syntactic issues. To avoid mismatch and misuse ofcomponents, more comprehensive specification of software components isrequired, In this paper, we present a contract-based approach to analyze andmodel the both aspects (functional and non-functional) properties of designcomponents and their composition in order to detect and correct compositionerrors. This approach permits to characterize the structural, interface andbehavioural aspects of design component. To enable this we present a patterncontract language that captures the structural and behavioral requirementsassociated with a range of patterns, as well as the system properties that areguaranteed as a result. In addition, we propose the use of the LOTOS languageas an ADL for formalizing these aspects. We illustrate the approach by applyingit to a standard design","Rigorous Description Of Design Components Functionality: An Approach
  Based Contract",Contract-based Analysis of Software Components and their Composition,0.2105263157894737,0.4630777161991027,0
"  This paper presents a gender classification schema based on onlinehandwriting. Using samples acquired with a digital tablet that captures thedynamics of the writing, it classifies the writer as a male or a female. Themethod proposed is allographic, regarding strokes as the structural units ofhandwriting. Strokes performed while the writing device is not exerting anypressure on the writing surface, pen-up (in-air) strokes, are also taken intoaccount. The method is also text-dependent meaning that training and testing isdone with exactly the same text. Text-dependency allows classification beperformed with very small amounts of text. Experimentation, performed withsamples from the BiosecurID database, yields results that fall in the range ofthe classification averages expected from human judges. With only fourrepetitions of a single uppercase word, the average rate of well classifiedwriters is 68%; with sixteen words, the rate rises to an average 72.6%.Statistical analysis reveals that the aforementioned rates are highlysignificant. In order to explore the classification potential of the pen-upstrokes, these are also considered. Although in this case results are notconclusive, an outstanding average of 74% of well classified writers isobtained when information from pen-up strokes is combined with information frompen-down ones.","Gender classification by means of online uppercase handwriting: A
  text-dependent allographic approach",Gender Classification of Handwritten Writers Using Pen-up Strokes,0.27272727272727276,0.42888194248035344,0
"  The D0 collaboration has recently introduced new variables, a_T and phi* tomore accurately probe the low Q_T domain of Z boson production at hadroncolliders than had been previously possible through a direct study of the Q_Tdistribution. The comparison of such accurate data to precise theoreticalpredictions from QCD perturbation theory will yield important information onthe ability of resummed QCD predictions as well as parton shower models todescribe the low Q_T domain and should enable more stringent constraints onnon-perturbative effects. In the present paper we provide analyticalpredictions for the above mentioned variables, that contain resummation oflarge logarithms, including next-to-next-to leading logarithmic (NNLL) terms,supplemented by exact next-to-leading order calculations from MCFM.","QCD predictions for new variables to study dilepton transverse momenta
  at hadron colliders","A new approach to the low Q_T domain of Z boson production at hadron
",0.28571428571428575,0.38503228868787126,0
"  A correlation between the change in magnetic susceptibility({\Delta}\c{hi}exp) upon crystallization of Cu-Zr, Hf metallic glasses (MG)with their glass forming ability (GFA) observed recently is found to apply toCu-Ti and Zr-Ni alloys, too. In particular, a small {\Delta}\c{hi}exp , whichreflects similar electronic structures, ES, of glassy and correspondingcrystalline alloys, corresponds to high GFA. Here, we studied {\Delta}\c{hi}expin five Cu-Ti and four Cu-Zr and Ni-Zr MGs. The fully crystalline final stateof all alloys was verified from X-ray diffraction patterns. The variation ofGFA with composition in Cu-Ti, Cu-Zr and Cu-Hf MGs was established from thevariation of the corresponding critical casting thickness, dc. Due to theabsence of data for dc in Ni-Zr MGs their GFA was described by using empiricalcriteria, such as the reduced glass transition temperature. A very goodcorrelation between {\Delta}\c{hi}exp and dc (and/or other criteria for GFA)was observed for all alloys studied. The correlation between the ES and GFAshowed up best for Cu-Zr and NiZr2 alloys where direct data for the change inES ({\Delta}ES) upon crystallization are available. The applicability of the{\Delta}\c{hi}exp ({\Delta}ES) criterion for high GFA (which provides a simpleway to select the compositions with high GFA) to other metal-metal MGs(including ternary and multicomponent bulk MGs) is briefly discussed.","Electronic structure and glass forming ability in early and late
  transition metal alloys","The correlation between magnetic susceptibility and glass forming ability in
  Cu-Ti, Zr-",0.38461538461538464,0.2916755292171272,0
"  We consider an inverse scattering problem to identify the locations or shapesof unknown anomalies from scattering parameter data collected by a small numberof dipole antennas. Most of researches does not considered the influence ofdipole antennas but in the experimental simulation, they are significantlyaffect to the identification of anomalies. Moreover, opposite to thetheoretical results, it is impossible to handle scattering parameter data whenthe locations of the transducer and receiver are the same in real-worldapplication. Motivated by this, we design an imaging function with and withoutdiagonal elements of the so-called scattering matrix. This concept is based onthe Born approximation and the physical interpretation of the measurement datawhen the locations of the transducer and receiver are the same and different.We carefully explore the mathematical structures of traditional and proposedimaging functions by finding relationships with the infinite series of Besselfunctions of integer order. The explored structures reveal certain propertiesof imaging functions and show why the proposed method is better than thetraditional approach. We present the experimental results for small andextended anomalies using synthetic and real data at several angular frequenciesto demonstrate the effectiveness of our technique.",Real-time microwave imaging of unknown anomalies via scattering matrix,An inverse scattering problem with diagonal elements,0.11764705882352941,0.46199933699457096,0
"  The viscosity of dilute and semidilute unentangled DNA solutions, in steadysimple shear flow, has been measured across a range of temperatures andconcentrations. For polystyrene solutions, measurements of viscosity have beencarried out in the semidilute unentangled regime, while results of priorexperimental measurements in the dilute regime have been used for the purposeof data analysis, and for comparison with the behaviour of DNA solutions.Interpretation of the shear rate dependence of viscosity in terms of suitablydefined non-dimensional variables, is shown to lead to master plots,independent of temperature and concentration, in each of the two concentrationregimes. In the case of semidilute unentangled solutions, defining theWeissenberg number in terms of a concentration dependent large scale relaxationtime is found not to lead to data collapse across different concentrations. Onthe other hand, the use of an alternative relaxation time, with theconcentration dependence of a single correlation blob, suggests the existenceof universal shear thinning behaviour at large shear rates.",Shear thinning in dilute and semidilute solutions of polystyrene and DNA,Viscosity of dilute and semidilute unentangled DNA solutions,0.4210526315789474,0.2987789945544558,0
"  It is well-known that, in the basis where the charged-lepton mass matrix isdiagonal, there are seven cases of two texture zeros in Majorana neutrino massmatrices that are compatible with all experimental data. We show that two ofthese cases, namely B3 and B4 in the classification of Frampton, Glashow andMarfatia, are special in the sense that they automatically lead to near-maximalatmospheric neutrino mixing in the limit of a quasi-degenerate neutrino massspectrum. This property holds true irrespective of the values of the solar andreactor mixing angles because, for these two cases, in the limit of aquasi-degenerate spectrum, the second and third row of the lepton mixing matrixare, up to signs, approximately complex-conjugate to each other. Moreover, inthe same limit the aforementioned cases also develop a maximal CP-violatingCKM-type phase, provided the reactor mixing angle is not too small.","Maximal atmospheric neutrino mixing from texture zeros and
  quasi-degenerate neutrino masses",Near-maximal neutrino mixing in the limit of quasi-degenerate neutr,0.43478260869565216,0.36177396082048563,0
"  The Sunspot Number, created by R.Wolf in 1849, provides a direct long-termrecord of solar activity from 1700 to the present. In spite of its central rolein multiple studies of the solar dynamo and of the past Sun-Earth relations, itwas never submitted to a global critical revision. However, variousdiscrepancies with other solar indices recently motivated a full re-calibrationof this series. Based on various diagnostics and corrections established in theframework of several Sunspot Number Workshops and described in Clette et al.2014, we assembled all corrections in order to produce a new standard versionof this reference time series. In this paper, we explain the three maincorrections and the criteria used to choose a final optimal version of eachcorrection factor or function, given the available information and publishedanalyses. We then discuss the good agreement obtained with the Group sunspotNumber derived from a recent reconstruction. Among the implications emergingfrom this re-calibrated series, we also discuss the absence of a rising seculartrend in the newly-determined solar cycle amplitudes, also in relation withcontradictory indications derived from cosmogenic radionuclides. As conclusion,we introduce the new version management scheme now implemented at the WorldData Center - SILSO, which reflects a major conceptual transition: beyond there-scaled numbers, this first revision of the Sunspot Number also transformsthe former locked data archive into a living observational series open tofuture improvements.",The new Sunspot Number: assembling all corrections,The Sunspot Number: A New Version Management Scheme,0.39999999999999997,0.48109772909788073,0
"  We consider the cosmological evolution induced by the free energy F of a gasof maximally supersymmetric heterotic strings at finite temperature and weakcoupling in dimension D>=4. We show that F, which plays the role of aneffective potential, has minima associated to enhanced gauge symmetries, whereall internal moduli can be attracted and dynamically stabilized. Using the factthat the heterotic/type I S-duality remains valid at finite temperature and canbe applied at each instant of a quasi-static evolution, we find in the dualtype I cosmology that all internal NS-NS and RR moduli in the closed stringsector and the Wilson lines in the open string sector can be stabilized. Forthe special case of D=6, the internal volume modulus remains a flat direction,while the dilaton is stabilized. An essential role is played by light D-stringmodes wrapping the internal manifold and whose contribution to the free energycannot be omitted, even when the type I string is at weak coupling. As aresult, the order of magnitude of the internal radii expectation values on thetype I side is (lambda_I alpha')^{1/2}, where lambda_I is the ten-dimensionalstring coupling. The non-perturbative corrections to the type I free energy canalternatively be described as effects of ""thermal E1-instantons"", whoseworldsheets wrap the compact Euclidean time cycle.",Massless D-strings and moduli stabilization in type I cosmology,"Stabilization of the free energy of a gas of maximally supersymmetric
  heter",0.0909090909090909,0.0,0
"  In 1981, the idea of a superwind that ends the life of cool giant stars wasproposed. Extreme OH/IR-stars develop superwinds with the highest mass-lossrates known so far, up to a few 10^(-4) Msun/yr, informing our understanding ofthe maximum mass-loss rate achieved during the Asymptotic Giant Branch (AGB)phase. A condundrum arises whereby the observationally determined duration ofthe superwind phase is too short for these stars to become white dwarfs. Here,we report on the detection of spiral structures around two cornerstone extremeOH/IR-stars, OH26.5+0.6 and OH30.1-0.7, identifying them as wide binarysystems. Hydrodynamical simulations show that the companion's gravitationalattraction creates an equatorial density enhancement mimicking a short extremesuperwind phase, thereby solving the decades-old conundrum. This discoveryrestricts the maximum mass-loss rate of AGB stars around the single-scatteringradiation-pressure limit of a few 10^(-5) Msun/yr. This brings about crucialimplications for nucleosynthetic yields, planet survival, and the wind-drivingmechanism.","Reduction of the maximum mass-loss rate of OH/IR stars due to unnoticed
  binary interaction","The Asymptotic Giant Branch Phase: The New Discovery of Spiral
  Systems around Extreme",0.13793103448275862,0.4876485015882737,0
"  Discovering important genes that account for the phenotype of interest haslong been challenging in genomewide expression analysis. Analyses such as GeneSet Enrichment Analysis (GSEA) that incorporate pathway information have becomewidespread in hypothesis testing, but pathway-based approaches have beenlargely absent from regression methods due to the challenges of dealing withoverlapping pathways and the resulting lack of available software. The Rpackage grpreg is widely used to fit group lasso and other group-penalizedregression models; in this study, we develop an extension, grpregOverlap, toallow for overlapping group structure using the latent variable approachproposed by Jacob et al. (2009). We compare this approach to the ordinary lassoand to GSEA using both simulated and real data. We find that incorporation ofprior pathway information substantially improves the accuracy of geneexpression classifiers, and we shed light on several ways in whichhypothesis-testing approaches such as GSEA differ from regression approacheswith respect to the analysis of pathway data.","Overlapping group logistic regression with applications to genetic
  pathway selection","Grpreg Overlap: A latent variable approach to gene expression
  analysis",0.20000000000000004,0.5623413251903491,0
"  Most static 1D atmosphere models in the quiet Sun predict a rise of the gastemperature at chromospheric layers, but numerical simulations only yield anincrease in the brightness temperature. We investigate the thermal structure inthe solar chromosphere as derived from an LTE inversion of Ca II H spectra inQS and active regions. We investigate the temperature stratifications ondifferences between magnetic and field-free regions in the QS, and between QSand ARs. We determine the energy content of individual calcium bright grains(BGs). The rms temperature fluctuations are below 100 K in the photosphere and200-300 K in the chromosphere. The average temperature stratification in the QSdoes not exhibit a clear chromospheric temperature rise, opposite to the ARcase. We find an energy content of about 7*10E18 J for BGs that repeat with acadence of about 160 secs. The precursors of BGs have a vertical extent ofabout 200 km and a horizontal extent of about 1 Mm. The comparison of observedwith synthetic NLTE profiles confirms that the solar chromosphere in the QSoscillates between an atmosphere in radiative equilibrium and one with amoderate chromospheric temperature rise. Two-dimensional x-z temperature mapsexhibit nearly horizontal canopy-like structures with a few Mm extent aroundphotospheric magnetic field concentrations at a height of about 600 km. Thelarge difference between QS regions and ARs, and the better match of AR andnon-LTE reference spectra suggest that magnetic heating processes are moreimportant than commonly assumed. The temperature fluctuations in QS derived bythe LTE inversion do not suffice on average to maintain a stationarychromospheric temperature rise. The spatially and vertically resolvedinformation on the temperature structure allows one to investigate in detailthe topology and evolution of the thermal structure in the lower solaratmosphere.","The energy of waves in the photosphere and lower chromosphere: IV.
  Inversion results of Ca II H spectra",Thermal Structure of the Solar Chromosphere in the Quiet Sun,0.21428571428571427,0.19199242796476845,0
"  Purpose: Implanted fiducial markers are often used in radiotherapy tofacilitate accurate visualization and localization of tumors. Typically, suchmarkers are used to aid daily patient positioning and to verify the target'sposition during treatment. This work introduces a novel, automated method foridentifying fiducial markers in planar x-ray imaging.  Methods: In brief, the method consists of automated filtration andreconstruction steps that generate 3D templates of marker positions. Thenormalized cross-correlation was the used to identify fiducial markers inprojection images. To quantify the accuracy of the technique, a phantom studywas performed. 75 pre-treatment CBCT scans of 15 pancreatic cancer patientswere analyzed to test the automated technique under real life conditions,including several challenging scenarios for tracking fiducial markers.  Results: In phantom and patient studies, the method automatically trackedvisible marker clusters in 100% of projection images. For scans in which aphantom exhibited 0D, 1D, and 3D motion, the automated technique showed medianerrors of 39 $\mu$m, 53 $\mu$m, and 93 $\mu$m, respectively. Human precisionwas worse in comparison. Automated tracking was performed accurately despitethe presence of other metallic objects. Additionally, transient differences inthe cross-correlation score identified instances where markers disappeared fromview.  Conclusions: A novel, automated method for producing dynamic templates offiducial marker clusters has been developed. Production of these templatesautomatically provides measurements of tumor motion that occurred during theCBCT scan that was used to produce them. Additionally, using these templateswith intra-fractional images could potentially allow for more robust real-timetarget tracking in radiotherapy.","Automated target tracking in kilovoltage images using dynamic templates
  of fiducial marker clusters",Automatic Tracking of Densiducial Markers in Planar x-ray Imaging,0.2608695652173913,0.4402274324685413,0
"  Autonomous feeding is challenging because it requires manipulation of fooditems with various compliance, sizes, and shapes. To understand how humansmanipulate food items during feeding and to explore ways to adapt theirstrategies to robots, we collected a rich dataset of human trajectories byasking them to pick up food and feed it to a mannequin. From the analysis ofthe collected haptic and motion signals, we demonstrate that humans adapt theircontrol policies to accommodate to the compliance and shape of the food itembeing acquired. We propose a taxonomy of manipulation strategies for feeding tohighlight such policies. As a first step to generate compliance-dependentpolicies, we propose a set of classifiers for compliance-based foodcategorization from haptic and motion signals. We compare these humanmanipulation strategies with fixed position-control policies via a robot. Ouranalysis of success and failure cases of human and robot policies furtherhighlights the importance of adapting the policy to the compliance of a fooditem.",Towards Robotic Feeding: Role of Haptics in Fork-based Food Manipulation,Autonomous feeding with human control policies,0.11764705882352942,0.0,0
"  Reliably modeling normality and differentiating abnormal appearances fromnormal cases is a very appealing approach for detecting pathologies in medicalimages. A plethora of such unsupervised anomaly detection approaches has beenmade in the medical domain, based on statistical methods, content-basedretrieval, clustering and recently also deep learning. Previous approachestowards deep unsupervised anomaly detection model patches of normal anatomywith variants of Autoencoders or GANs, and detect anomalies either as outliersin the learned feature space or from large reconstruction errors. In contrastto these patch-based approaches, we show that deep spatial autoencoding modelscan be efficiently used to capture normal anatomical variability of entire 2Dbrain MR images. A variety of experiments on real MR data containing MS lesionscorroborates our hypothesis that we can detect and even delineate anomalies inbrain MR images by simply comparing input images to their reconstruction.Results show that constraints on the latent space and adversarial training canfurther improve the segmentation performance over standard deep representationlearning.","Deep Autoencoding Models for Unsupervised Anomaly Segmentation in Brain
  MR Images",Deep Unsupervised Anomaly Detection,0.39999999999999997,0.12287673380733738,0
"  Necessary and sufficient conditions are given for the asymptotic stabilityand instability of a two-dimensional incommensurate order autonomous linearsystem, which consists of a differential equation with a Caputo-type fractionalorder derivative and a classical first order differential equation. Theseconditions are expressed in terms of the elements of the system's matrix, aswell as of the fractional order of the Caputo derivative. In this setting, weobtain a generalization of the well known Routh-Hurwitz conditions. Thesetheoretical results are then applied to the analysis of a two-dimensionalfractional-order Morris-Lecar neuronal model, focusing on stability andinstability properties. This fractional order model is built up taking intoaccount the dimensional consistency of the resulting system of differentialequations. The occurrence of Hopf bifurcations is also discussed. Numericalsimulations exemplify the theoretical results, revealing rich spiking behavior.The obtained results are also compared to similar ones obtained for theclassical integer-order Morris-Lecar neuronal model.","Stability properties of a two-dimensional system involving one Caputo
  derivative and applications to the investigation of a fractional-order
  Morris-Lecar neuronal model","Asymptotic stability and instability of a two-dimensional incommensurate
  order",0.35294117647058826,0.09356330481602375,0
"  Classical correlations without predefined causal order arise from processeswhere parties manipulate random variables, and where the order of theseinteractions is not predefined. No assumption on the causal order of theparties is made, but the processes are restricted to be logically consistentunder any choice of the parties' operations. It is known that for three partiesor more, this set of processes is larger than the set of processes achievablein a predefined ordering of the parties. Here, we model all classical processeswithout predefined causal order geometrically and find that the set of suchprocesses forms a polytope. Additionally, we model a smaller polytope --- thedeterministic-extrema polytope --- where all extremal points representdeterministic processes. This polytope excludes probabilistic processes thatmust be --- quite unnaturally --- fine-tuned, because any variation of theweights in a decomposition into deterministic processes leads to a logicalinconsistency.","The space of logically consistent classical processes without causal
  order",Polytopes of classical processes without predefined causal order,0.6666666666666665,0.3746792881553041,0
"  Modern soft X-ray observatories can yield unique insights into time domainastrophysics, and a huge amount of information is stored - and largelyunexploited - in data archives. Like a treasure-hunt, the EXTraS projectharvested the hitherto unexplored temporal domain information buried in theserendipitous data collected by the European Photon Imaging Camera instrumentonboard the ESA XMM-Newton, in 16 years of observations. All results have beenreleased to the scientific community, together with new software analysistools. This paper presents the architecture of the EXTraS science gateway, thathas the goal to provide the software to the scientific community through a Webbased portal using the EGI Federated Cloud infrastructure. The main focus is onthe light software architecture of the portal and on the technological insightsfor an effective use of the EGI ecosystem.","A science gateway for Exploring the X-ray Transient and variable sky
  using EGI Federated Cloud",The EXTraS Science Gateway,0.2,0.0,0
"  A univariate Hawkes process is a simple point process that is self-excitingand has clustering effect. The intensity of this point process is given by thesum of a baseline intensity and another term that depends on the entire pasthistory of the point process. Hawkes process has wide applications in finance,neuroscience, social networks, criminology, seismology, and many other fields.In this paper, we prove a functional central limit theorem for stationaryHawkes processes in the asymptotic regime where the baseline intensity islarge. The limit is a non-Markovian Gaussian process with dependent increments.We use the resulting approximation to study an infinite-server queue withhigh-volume Hawkes traffic. We show that the queue length process can beapproximated by a Gaussian process, for which we compute explicitly thecovariance function and the steady-state distribution. We also extend ourresults to multivariate stationary Hawkes processes and establish limittheorems for infinite-server queues with multivariate Hawkes traffic.","Functional central limit theorems for stationary Hawkes processes and
  application to infinite-server queues",Functional central limit theorem for stationary Hawkes processes,0.7272727272727273,0.26763071425949514,0
"  We introduce machine learning models of quantum mechanical observables ofatoms in molecules. Instant out-of-sample predictions for proton and carbonnuclear chemical shifts, atomic core level excitations, and forces on atomsreach accuracies on par with density functional theory reference. Locality isexploited within non-linear regression via local atom-centered coordinatesystems. The approach is validated on a diverse set of 9k small organicmolecules. Linear scaling of computational cost in system size is demonstratedfor saturated polymers with up to sub-mesoscale lengths.",Machine Learning for Quantum Mechanical Properties of Atoms in Molecules,"Machine Learning of Atom-centered coordinates for atom-centered
  coordinates",0.4000000000000001,0.4026190971287384,0
